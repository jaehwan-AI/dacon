{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T08:38:12.959641Z",
     "start_time": "2020-08-18T08:38:09.558559Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, LSTM, concatenate, Dropout\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# seed\n",
    "import os\n",
    "seed = 123\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T08:38:14.426685Z",
     "start_time": "2020-08-18T08:38:12.959641Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T08:38:14.442467Z",
     "start_time": "2020-08-18T08:38:14.428723Z"
    }
   },
   "outputs": [],
   "source": [
    "image_generator = ImageDataGenerator(width_shift_range=0.1,\n",
    "                                     height_shift_range=0.1, \n",
    "                                     zoom_range=[0.8,1.2],\n",
    "                                     #brightness_range=[0.8,1.2], \n",
    "                                     shear_range=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T08:38:15.426689Z",
     "start_time": "2020-08-18T08:38:14.446447Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4096, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "x1 = train.drop(['id', 'digit', 'letter'], axis=1).values\n",
    "x1 = x1.reshape(-1, 28, 28, 1)\n",
    "x1 = x1/255\n",
    "x1_remake = []\n",
    "for i in range(x1.shape[0]):\n",
    "    num_aug = 0\n",
    "    tmp = x1[i]\n",
    "    tmp = tmp.reshape((1,) + tmp.shape)\n",
    "    for x_aug in image_generator.flow(tmp, batch_size = 1) :\n",
    "        if num_aug >= 1:\n",
    "            break\n",
    "        x1_remake.append(x_aug[0])\n",
    "        num_aug += 1\n",
    "x1_remake = np.array(x1_remake)\n",
    "\n",
    "x1_total = np.concatenate((x1, x1_remake), axis=0)\n",
    "print(x1_total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T08:38:15.441619Z",
     "start_time": "2020-08-18T08:38:15.429676Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4096, 10)\n"
     ]
    }
   ],
   "source": [
    "y1_data = train['digit']\n",
    "y1 = np.zeros((len(y1_data), len(y1_data.unique())))\n",
    "for i, digit in enumerate(y1_data):\n",
    "    y1[i, digit] = 1\n",
    "\n",
    "y1_remake = y1.copy()\n",
    "y1_total = np.concatenate((y1, y1_remake), axis=0)\n",
    "print(y1_total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T08:38:15.473596Z",
     "start_time": "2020-08-18T08:38:15.445604Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4096, 26)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1_let = train['letter'].values\n",
    "x1_let = x1_let[:, np.newaxis]\n",
    "en = OneHotEncoder()\n",
    "x1_let = en.fit_transform(x1_let).toarray()\n",
    "\n",
    "x1_remake_let = x1_let.copy()\n",
    "\n",
    "x1_letter_total = np.concatenate((x1_let, x1_remake_let), axis=0)\n",
    "x1_letter_total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T08:38:15.552539Z",
     "start_time": "2020-08-18T08:38:15.478854Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3276, 28, 28, 1)\n",
      "(820, 28, 28, 1)\n",
      "(3276, 10)\n",
      "(820, 10)\n",
      "(3276, 26)\n",
      "(820, 26)\n"
     ]
    }
   ],
   "source": [
    "x1_train, x1_val, y1_train, y1_val = train_test_split(x1_total, y1_total, test_size=0.2, shuffle=True, stratify=y1_total)\n",
    "\n",
    "print(x1_train.shape)\n",
    "print(x1_val.shape)\n",
    "print(y1_train.shape)\n",
    "print(y1_val.shape)\n",
    "\n",
    "x1_letter_train = x1_letter_total[:x1_train.shape[0],:]\n",
    "x1_letter_val = x1_letter_total[x1_train.shape[0]:,:]\n",
    "print(x1_letter_train.shape)\n",
    "print(x1_letter_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T08:38:15.568473Z",
     "start_time": "2020-08-18T08:38:15.556522Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3276, 28, 28)\n",
      "(820, 28, 28)\n",
      "(3276, 10)\n",
      "(820, 10)\n",
      "(3276, 26)\n",
      "(820, 26)\n"
     ]
    }
   ],
   "source": [
    "x2_train = np.reshape(x1_train, (x1_train.shape[0], x1_train.shape[1], x1_train.shape[2]))\n",
    "x2_val = np.reshape(x1_val, (x1_val.shape[0], x1_val.shape[1], x1_val.shape[2]))\n",
    "y2_train = y1_train.copy()\n",
    "y2_val = y1_val.copy()\n",
    "x2_letter_train = x1_letter_train.copy()\n",
    "x2_letter_val = x1_letter_val.copy()\n",
    "\n",
    "print(x2_train.shape)\n",
    "print(x2_val.shape)\n",
    "print(y2_train.shape)\n",
    "print(y2_val.shape)\n",
    "print(x2_letter_train.shape)\n",
    "print(x2_letter_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T08:38:17.379243Z",
     "start_time": "2020-08-18T08:38:15.572455Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 28, 28, 64)   320         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 28, 28, 64)   0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 14, 14, 64)   0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 14, 14, 64)   16448       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 14, 14, 64)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 28, 28)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 7, 7, 64)     0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 28, 512)      1107968     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 7, 7, 128)    32896       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 28, 512)      0           lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 7, 7, 128)    0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 28, 256)      787456      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 3, 3, 128)    0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 28, 256)      0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1152)         0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 26)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 128)          197120      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1178)         0           flatten[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 128)          0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 500)          589500      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 100)          12900       dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 26)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 500)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 126)          0           dense_2[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          50100       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 100)          12700       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 200)          0           dense_1[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 100)          20100       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 100)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 50)           5050        dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 50)           0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 10)           510         dropout_8[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,833,068\n",
      "Trainable params: 2,833,068\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input1 = Input(shape=(28,28,1))\n",
    "x1 = Conv2D(64, (2,2), activation='relu', padding='same')(input1)\n",
    "x1 = Dropout(0.2)(x1)\n",
    "x1 = MaxPooling2D((2,2))(x1)\n",
    "x1 = Conv2D(64, (2,2), activation='relu', padding='same')(x1)\n",
    "x1 = Dropout(0.2)(x1)\n",
    "x1 = MaxPooling2D((2,2))(x1)\n",
    "x1 = Conv2D(128, (2,2), activation='relu', padding='same')(x1)\n",
    "x1 = Dropout(0.2)(x1)\n",
    "x1 = MaxPooling2D((2,2))(x1)\n",
    "x1 = Flatten()(x1)\n",
    "\n",
    "input2 = Input(shape=(26,))\n",
    "merge1 = concatenate([x1, input2])\n",
    "\n",
    "x2 = Dense(500, activation='relu')(merge1)\n",
    "x2 = Dropout(0.2)(x2)\n",
    "x2 = Dense(100, activation='relu')(x2)\n",
    "\n",
    "input3 = Input(shape=(28,28))\n",
    "x3 = LSTM(512, activation='relu', return_sequences=True)(input3)\n",
    "x3 = Dropout(0.2)(x3)\n",
    "x3 = LSTM(256, activation='relu', return_sequences=True)(x3)\n",
    "x3 = Dropout(0.2)(x3)\n",
    "x3 = LSTM(128, activation='relu')(x3)\n",
    "x3 = Dropout(0.2)(x3)\n",
    "x3 = Dense(100, activation='relu')(x3)\n",
    "\n",
    "input4 = Input(shape=(26,))\n",
    "merge2 = concatenate([x3, input4])\n",
    "\n",
    "x4 = Dense(100, activation='relu')(merge2)\n",
    "\n",
    "merge = concatenate([x2, x4])\n",
    "\n",
    "x5 = Dense(100, activation='relu')(merge)\n",
    "x5 = Dropout(0.2)(x5)\n",
    "x5 = Dense(50, activation='relu')(x5)\n",
    "x5 = Dropout(0.2)(x5)\n",
    "outputs = Dense(10, activation='softmax')(x5)\n",
    "\n",
    "model = Model(inputs = [input1, input2, input3, input4], outputs = outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T08:52:29.284771Z",
     "start_time": "2020-08-18T08:40:08.361384Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3276 samples, validate on 820 samples\n",
      "Epoch 1/50\n",
      "3276/3276 [==============================] - 19s 6ms/step - loss: 2.2194 - acc: 0.1697 - val_loss: 2.2004 - val_acc: 0.1902\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.19024, saving model to ./models/01-0.1902.h5\n",
      "Epoch 2/50\n",
      "3276/3276 [==============================] - 14s 4ms/step - loss: 2.0132 - acc: 0.2552 - val_loss: 1.9845 - val_acc: 0.3427\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.19024 to 0.34268, saving model to ./models/02-0.3427.h5\n",
      "Epoch 3/50\n",
      "3276/3276 [==============================] - 15s 5ms/step - loss: 1.7747 - acc: 0.3599 - val_loss: 1.7686 - val_acc: 0.4037\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.34268 to 0.40366, saving model to ./models/03-0.4037.h5\n",
      "Epoch 4/50\n",
      "3276/3276 [==============================] - 14s 4ms/step - loss: 1.5710 - acc: 0.4545 - val_loss: 1.5832 - val_acc: 0.4793\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.40366 to 0.47927, saving model to ./models/04-0.4793.h5\n",
      "Epoch 5/50\n",
      "3276/3276 [==============================] - 15s 5ms/step - loss: 1.3955 - acc: 0.5281 - val_loss: 1.4255 - val_acc: 0.5220\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.47927 to 0.52195, saving model to ./models/05-0.5220.h5\n",
      "Epoch 6/50\n",
      "3276/3276 [==============================] - 15s 5ms/step - loss: 1.2690 - acc: 0.5693 - val_loss: 1.3794 - val_acc: 0.5378\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.52195 to 0.53780, saving model to ./models/06-0.5378.h5\n",
      "Epoch 7/50\n",
      "3276/3276 [==============================] - 15s 4ms/step - loss: 1.1992 - acc: 0.5952 - val_loss: 1.3765 - val_acc: 0.5427\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.53780 to 0.54268, saving model to ./models/07-0.5427.h5\n",
      "Epoch 8/50\n",
      "3276/3276 [==============================] - 15s 4ms/step - loss: 1.0950 - acc: 0.6343 - val_loss: 1.2171 - val_acc: 0.5793\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.54268 to 0.57927, saving model to ./models/08-0.5793.h5\n",
      "Epoch 9/50\n",
      "3276/3276 [==============================] - 15s 5ms/step - loss: 0.9758 - acc: 0.6725 - val_loss: 1.0700 - val_acc: 0.6463\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.57927 to 0.64634, saving model to ./models/09-0.6463.h5\n",
      "Epoch 10/50\n",
      "3276/3276 [==============================] - 14s 4ms/step - loss: 0.8734 - acc: 0.7125 - val_loss: 1.0977 - val_acc: 0.6268\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.64634\n",
      "Epoch 11/50\n",
      "3276/3276 [==============================] - 14s 4ms/step - loss: 0.8158 - acc: 0.7237 - val_loss: 1.0733 - val_acc: 0.6573\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.64634 to 0.65732, saving model to ./models/11-0.6573.h5\n",
      "Epoch 12/50\n",
      "3276/3276 [==============================] - 14s 4ms/step - loss: 0.7663 - acc: 0.7442 - val_loss: 1.0115 - val_acc: 0.6598\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.65732 to 0.65976, saving model to ./models/12-0.6598.h5\n",
      "Epoch 13/50\n",
      "3276/3276 [==============================] - 15s 5ms/step - loss: 0.7085 - acc: 0.7643 - val_loss: 1.0338 - val_acc: 0.6415\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.65976\n",
      "Epoch 14/50\n",
      "3276/3276 [==============================] - 15s 5ms/step - loss: 0.6342 - acc: 0.7833 - val_loss: 0.9415 - val_acc: 0.7012\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.65976 to 0.70122, saving model to ./models/14-0.7012.h5\n",
      "Epoch 15/50\n",
      "3276/3276 [==============================] - 14s 4ms/step - loss: 0.5586 - acc: 0.8156 - val_loss: 0.9073 - val_acc: 0.6988\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.70122\n",
      "Epoch 16/50\n",
      "3276/3276 [==============================] - 14s 4ms/step - loss: 0.5150 - acc: 0.8321 - val_loss: 0.9653 - val_acc: 0.6732\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.70122\n",
      "Epoch 17/50\n",
      "3276/3276 [==============================] - 14s 4ms/step - loss: 0.4870 - acc: 0.8355 - val_loss: 0.8998 - val_acc: 0.6963\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.70122\n",
      "Epoch 18/50\n",
      "3276/3276 [==============================] - 14s 4ms/step - loss: 0.4405 - acc: 0.8422 - val_loss: 0.9285 - val_acc: 0.6902\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.70122\n",
      "Epoch 19/50\n",
      "3276/3276 [==============================] - 15s 4ms/step - loss: 0.4108 - acc: 0.8590 - val_loss: 0.8815 - val_acc: 0.7073\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.70122 to 0.70732, saving model to ./models/19-0.7073.h5\n",
      "Epoch 20/50\n",
      "3276/3276 [==============================] - 15s 5ms/step - loss: 0.3577 - acc: 0.8791 - val_loss: 0.8738 - val_acc: 0.6963\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.70732\n",
      "Epoch 21/50\n",
      "3276/3276 [==============================] - 15s 5ms/step - loss: 0.3115 - acc: 0.9029 - val_loss: 0.8764 - val_acc: 0.7024\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.70732\n",
      "Epoch 22/50\n",
      "3276/3276 [==============================] - 15s 4ms/step - loss: 0.2973 - acc: 0.9029 - val_loss: 0.8633 - val_acc: 0.7134\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.70732 to 0.71341, saving model to ./models/22-0.7134.h5\n",
      "Epoch 23/50\n",
      "3276/3276 [==============================] - 14s 4ms/step - loss: 0.3130 - acc: 0.8999 - val_loss: 0.9214 - val_acc: 0.7061\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.71341\n",
      "Epoch 24/50\n",
      "3276/3276 [==============================] - 14s 4ms/step - loss: 0.2847 - acc: 0.9048 - val_loss: 0.9188 - val_acc: 0.7024\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.71341\n",
      "Epoch 25/50\n",
      "3276/3276 [==============================] - 14s 4ms/step - loss: 0.2557 - acc: 0.9151 - val_loss: 0.9065 - val_acc: 0.7207\n",
      "\n",
      "Epoch 00025: val_acc improved from 0.71341 to 0.72073, saving model to ./models/25-0.7207.h5\n",
      "Epoch 26/50\n",
      "3276/3276 [==============================] - 14s 4ms/step - loss: 0.2215 - acc: 0.9307 - val_loss: 0.9599 - val_acc: 0.6927\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.72073\n",
      "Epoch 27/50\n",
      "3276/3276 [==============================] - 14s 4ms/step - loss: 0.1966 - acc: 0.9414 - val_loss: 0.9036 - val_acc: 0.7268\n",
      "\n",
      "Epoch 00027: val_acc improved from 0.72073 to 0.72683, saving model to ./models/27-0.7268.h5\n",
      "Epoch 28/50\n",
      "3276/3276 [==============================] - 15s 4ms/step - loss: 0.1809 - acc: 0.9429 - val_loss: 0.9912 - val_acc: 0.7085\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.72683\n",
      "Epoch 29/50\n",
      "3276/3276 [==============================] - 14s 4ms/step - loss: 0.1691 - acc: 0.9466 - val_loss: 1.0118 - val_acc: 0.7134\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.72683\n",
      "Epoch 30/50\n",
      "3276/3276 [==============================] - 15s 4ms/step - loss: 0.1575 - acc: 0.9487 - val_loss: 1.0136 - val_acc: 0.7037\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.72683\n",
      "Epoch 31/50\n",
      "3276/3276 [==============================] - 15s 4ms/step - loss: 0.1861 - acc: 0.9432 - val_loss: 1.0278 - val_acc: 0.6951\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.72683\n",
      "Epoch 32/50\n",
      "3276/3276 [==============================] - 14s 4ms/step - loss: 0.1552 - acc: 0.9487 - val_loss: 0.9567 - val_acc: 0.7317\n",
      "\n",
      "Epoch 00032: val_acc improved from 0.72683 to 0.73171, saving model to ./models/32-0.7317.h5\n",
      "Epoch 33/50\n",
      "3276/3276 [==============================] - 14s 4ms/step - loss: 0.1272 - acc: 0.9573 - val_loss: 1.0209 - val_acc: 0.7110\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.73171\n",
      "Epoch 34/50\n",
      "3276/3276 [==============================] - 14s 4ms/step - loss: 0.1417 - acc: 0.9551 - val_loss: 0.9807 - val_acc: 0.7268\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.73171\n",
      "Epoch 35/50\n",
      "3276/3276 [==============================] - 14s 4ms/step - loss: 0.1309 - acc: 0.9615 - val_loss: 1.0223 - val_acc: 0.7183\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.73171\n",
      "Epoch 36/50\n",
      "3276/3276 [==============================] - 14s 4ms/step - loss: 0.1420 - acc: 0.9576 - val_loss: 1.0589 - val_acc: 0.7061\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.73171\n",
      "Epoch 37/50\n",
      "3276/3276 [==============================] - 14s 4ms/step - loss: 0.1184 - acc: 0.9634 - val_loss: 1.0429 - val_acc: 0.7171\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.73171\n",
      "Epoch 38/50\n",
      "3276/3276 [==============================] - 14s 4ms/step - loss: 0.1036 - acc: 0.9670 - val_loss: 1.0055 - val_acc: 0.7207\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.73171\n",
      "Epoch 39/50\n",
      "3276/3276 [==============================] - 14s 4ms/step - loss: 0.0787 - acc: 0.9774 - val_loss: 1.0599 - val_acc: 0.7293\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.73171\n",
      "Epoch 40/50\n",
      "3276/3276 [==============================] - 15s 4ms/step - loss: 0.1473 - acc: 0.9542 - val_loss: 1.0301 - val_acc: 0.7098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00040: val_acc did not improve from 0.73171\n",
      "Epoch 41/50\n",
      "3276/3276 [==============================] - 15s 5ms/step - loss: 0.0884 - acc: 0.9762 - val_loss: 1.0103 - val_acc: 0.7280\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.73171\n",
      "Epoch 42/50\n",
      "3276/3276 [==============================] - 15s 5ms/step - loss: 0.0866 - acc: 0.9753 - val_loss: 1.0538 - val_acc: 0.7207\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.73171\n",
      "Epoch 43/50\n",
      "3276/3276 [==============================] - 15s 4ms/step - loss: 0.0777 - acc: 0.9777 - val_loss: 1.1627 - val_acc: 0.7146\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.73171\n",
      "Epoch 44/50\n",
      "3276/3276 [==============================] - 15s 4ms/step - loss: 0.0850 - acc: 0.9737 - val_loss: 1.0638 - val_acc: 0.7317\n",
      "\n",
      "Epoch 00044: val_acc improved from 0.73171 to 0.73171, saving model to ./models/44-0.7317.h5\n",
      "Epoch 45/50\n",
      "3276/3276 [==============================] - 14s 4ms/step - loss: 0.0896 - acc: 0.9722 - val_loss: 1.0437 - val_acc: 0.7317\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.73171\n",
      "Epoch 46/50\n",
      "3276/3276 [==============================] - 14s 4ms/step - loss: 0.1004 - acc: 0.9679 - val_loss: 1.0687 - val_acc: 0.7098\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.73171\n",
      "Epoch 47/50\n",
      "3276/3276 [==============================] - 15s 5ms/step - loss: 0.0959 - acc: 0.9734 - val_loss: 1.0582 - val_acc: 0.7146\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.73171\n",
      "Epoch 48/50\n",
      "3276/3276 [==============================] - 15s 5ms/step - loss: 0.0675 - acc: 0.9789 - val_loss: 1.1319 - val_acc: 0.7122\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.73171\n",
      "Epoch 49/50\n",
      "3276/3276 [==============================] - 15s 4ms/step - loss: 0.0831 - acc: 0.9750 - val_loss: 1.1952 - val_acc: 0.7037\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.73171\n",
      "Epoch 50/50\n",
      "3276/3276 [==============================] - 15s 4ms/step - loss: 0.0646 - acc: 0.9799 - val_loss: 1.0991 - val_acc: 0.7268\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.73171\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam', metrics = ['accuracy'], loss = 'categorical_crossentropy') \n",
    "              #loss_weights = [0.8, 0.2])\n",
    "history = model.fit([x1_train, x1_letter_train, x2_train, x2_letter_train], y1_train,\n",
    "                    validation_data=([x1_val, x1_letter_val, x2_val, x2_letter_val], y1_val), \n",
    "                    batch_size=64, epochs=50, verbose=1, \n",
    "                    callbacks = [ModelCheckpoint('./models/{epoch:02d}-{val_acc:.4f}.h5',\n",
    "                    monitor='val_acc', verbose=1, save_best_only=True, mode='auto')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T08:38:17.534513Z",
     "start_time": "2020-08-18T08:38:09.578Z"
    }
   },
   "outputs": [],
   "source": [
    "#from tensorflow.keras.models import load_model\n",
    "#best_model = load_model('./models/46-0.7463.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T08:56:59.456515Z",
     "start_time": "2020-08-18T08:55:42.841448Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 9 2 ... 6 8 0]\n"
     ]
    }
   ],
   "source": [
    "x1_test = test.drop(['id', 'letter'], axis=1).values\n",
    "x1_test = x1_test.reshape(-1, 28, 28, 1)\n",
    "x1_test = x1_test/255\n",
    "\n",
    "x2_test = test.drop(['id', 'letter'], axis=1).values\n",
    "x2_test = x2_test.reshape(-1, 28, 28)\n",
    "x2_test = x2_test/255\n",
    "\n",
    "x1_letter_test = test['letter'].values\n",
    "x1_letter_test = x1_letter_test[:, np.newaxis]\n",
    "en = OneHotEncoder()\n",
    "x1_letter_test = en.fit_transform(x1_letter_test).toarray()\n",
    "\n",
    "x2_letter_test = x1_letter_test.copy()\n",
    "\n",
    "y1_test = model.predict([x1_test, x1_letter_test, x2_test, x2_letter_test])\n",
    "y_1 = np.argmax(y1_test, axis=1)\n",
    "#y_2 = np.argmax(y2_test, axis=1)\n",
    "print(y_1)\n",
    "#print(y_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T08:38:17.536504Z",
     "start_time": "2020-08-18T08:38:09.581Z"
    }
   },
   "outputs": [],
   "source": [
    "#submission = pd.read_csv('data/submission.csv')\n",
    "#submission['digit'] = y_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T08:38:17.536504Z",
     "start_time": "2020-08-18T08:38:09.582Z"
    }
   },
   "outputs": [],
   "source": [
    "#submission.to_csv('data/submission(val7463).csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T08:38:17.538495Z",
     "start_time": "2020-08-18T08:38:09.584Z"
    }
   },
   "outputs": [],
   "source": [
    "#submission['digit'] = y_2\n",
    "#submission.to_csv('data/submission2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

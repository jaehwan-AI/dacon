{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T05:34:21.807533Z",
     "start_time": "2020-08-18T05:34:19.031564Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, LSTM, concatenate, Dropout\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# seed\n",
    "import os\n",
    "seed = 123\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T05:34:22.890615Z",
     "start_time": "2020-08-18T05:34:21.808540Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T05:34:22.895541Z",
     "start_time": "2020-08-18T05:34:22.891543Z"
    }
   },
   "outputs": [],
   "source": [
    "image_generator = ImageDataGenerator(width_shift_range=0.1,\n",
    "                                     height_shift_range=0.1, \n",
    "                                     zoom_range=[0.8,1.2],\n",
    "                                     brightness_range=[0.9,1.1], \n",
    "                                     shear_range=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T05:34:24.123278Z",
     "start_time": "2020-08-18T05:34:22.897542Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4096, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "x = train.drop(['id', 'digit', 'letter'], axis=1).values\n",
    "x = x.reshape(-1, 28, 28, 1)\n",
    "x = x/255\n",
    "x_remake = []\n",
    "for i in range(x.shape[0]):\n",
    "    num_aug = 0\n",
    "    tmp = x[i]\n",
    "    tmp = tmp.reshape((1,) + tmp.shape)\n",
    "    for x_aug in image_generator.flow(tmp, batch_size = 1) :\n",
    "        if num_aug >= 1:\n",
    "            break\n",
    "        x_remake.append(x_aug[0])\n",
    "        num_aug += 1\n",
    "x_remake = np.array(x_remake)\n",
    "\n",
    "x_total = np.concatenate((x, x_remake), axis=0)\n",
    "print(x_total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T05:34:24.132735Z",
     "start_time": "2020-08-18T05:34:24.125280Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4096, 10)\n"
     ]
    }
   ],
   "source": [
    "y_data = train['digit']\n",
    "y = np.zeros((len(y_data), len(y_data.unique())))\n",
    "for i, digit in enumerate(y_data):\n",
    "    y[i, digit] = 1\n",
    "\n",
    "y_remake = y.copy()\n",
    "y_total = np.concatenate((y, y_remake), axis=0)\n",
    "print(y_total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T05:34:24.152937Z",
     "start_time": "2020-08-18T05:34:24.134787Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4096, 26)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_let = train['letter'].values\n",
    "x_let = x_let[:, np.newaxis]\n",
    "en = OneHotEncoder()\n",
    "x_let = en.fit_transform(x_let).toarray()\n",
    "\n",
    "x_remake_let = x_let.copy()\n",
    "\n",
    "x_letter_total = np.concatenate((x_let, x_remake_let), axis=0)\n",
    "x_letter_total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T05:34:24.214027Z",
     "start_time": "2020-08-18T05:34:24.154935Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3276, 28, 28, 1)\n",
      "(820, 28, 28, 1)\n",
      "(3276, 10)\n",
      "(820, 10)\n",
      "(3276, 26)\n",
      "(820, 26)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_total, y_total, test_size=0.2, shuffle=True, stratify=y_total)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)\n",
    "\n",
    "x_letter_train = x_letter_total[:x_train.shape[0],:]\n",
    "x_letter_val = x_letter_total[x_train.shape[0]:,:]\n",
    "print(x_letter_train.shape)\n",
    "print(x_letter_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T05:34:24.407947Z",
     "start_time": "2020-08-18T05:34:24.215935Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input1 (InputLayer)             [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 28, 28, 64)   640         input1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 28, 28, 64)   0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 14, 14, 64)   0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 14, 14, 128)  32896       pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 14, 14, 128)  0           conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool2 (MaxPooling2D)            (None, 7, 7, 128)    0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3 (Conv2D)                  (None, 7, 7, 256)    131328      pool2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 7, 7, 256)    0           conv3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (MaxPooling2D)            (None, 3, 3, 256)    0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 2304)         0           pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input2 (InputLayer)             [(None, 26)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge (Concatenate)             (None, 2330)         0           flat1[0][0]                      \n",
      "                                                                 input2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "hidden1 (Dense)                 (None, 500)          1165500     merge[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 500)          0           hidden1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "hidden2 (Dense)                 (None, 100)          50100       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 100)          0           hidden2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "hidden3 (Dense)                 (None, 50)           5050        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 10)           510         hidden3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,386,024\n",
      "Trainable params: 1,386,024\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input1 = Input(shape=(28,28,1), name='input1')\n",
    "x1 = Conv2D(64, (3,3), activation='relu', padding='same', name='conv1')(input1)\n",
    "x1 = Dropout(0.3)(x1)\n",
    "x1 = MaxPooling2D((2,2), name='pool1')(x1)\n",
    "x1 = Conv2D(128, (2,2), activation='relu', padding='same', name='conv2')(x1)\n",
    "x1 = Dropout(0.3)(x1)\n",
    "x1 = MaxPooling2D((2,2), name='pool2')(x1)\n",
    "x1 = Conv2D(256, (2,2), activation='relu', padding='same', name='conv3')(x1)\n",
    "x1 = Dropout(0.3)(x1)\n",
    "x1 = MaxPooling2D((2,2), name='pool3')(x1)\n",
    "x1 = Flatten(name='flat1')(x1)\n",
    "\n",
    "input2 = Input(shape=(26,), name='input2')\n",
    "merge = concatenate([x1, input2], name='merge')\n",
    "\n",
    "x2 = Dense(500, activation='relu', name='hidden1')(merge)\n",
    "x2 = Dropout(0.3)(x2)\n",
    "x2 = Dense(100, activation='relu', name='hidden2')(x2)\n",
    "x2 = Dropout(0.3)(x2)\n",
    "x2 = Dense(50, activation='relu', name='hidden3')(x2)\n",
    "outputs = Dense(10, activation='softmax', name='output')(x2)\n",
    "\n",
    "model = Model(inputs = [input1, input2], outputs = outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T05:46:15.484477Z",
     "start_time": "2020-08-18T05:34:24.408937Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3276 samples, validate on 820 samples\n",
      "Epoch 1/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 4.6902 - accuracy: 0.1020\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.10488, saving model to ./models/01-0.1049.h5\n",
      "3276/3276 [==============================] - 8s 3ms/sample - loss: 4.6812 - accuracy: 0.1016 - val_loss: 2.3005 - val_accuracy: 0.1049\n",
      "Epoch 2/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 2.3164 - accuracy: 0.1078\n",
      "Epoch 00002: val_accuracy improved from 0.10488 to 0.11585, saving model to ./models/02-0.1159.h5\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 2.3163 - accuracy: 0.1084 - val_loss: 2.3011 - val_accuracy: 0.1159\n",
      "Epoch 3/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 2.3065 - accuracy: 0.1131\n",
      "Epoch 00003: val_accuracy improved from 0.11585 to 0.11829, saving model to ./models/03-0.1183.h5\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 2.3065 - accuracy: 0.1136 - val_loss: 2.3008 - val_accuracy: 0.1183\n",
      "Epoch 4/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 2.2987 - accuracy: 0.1140\n",
      "Epoch 00004: val_accuracy improved from 0.11829 to 0.12317, saving model to ./models/04-0.1232.h5\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 2.2986 - accuracy: 0.1136 - val_loss: 2.2996 - val_accuracy: 0.1232\n",
      "Epoch 5/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 2.2995 - accuracy: 0.1204\n",
      "Epoch 00005: val_accuracy did not improve from 0.12317\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 2.2994 - accuracy: 0.1203 - val_loss: 2.2996 - val_accuracy: 0.1232\n",
      "Epoch 6/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 2.2903 - accuracy: 0.1244\n",
      "Epoch 00006: val_accuracy improved from 0.12317 to 0.12439, saving model to ./models/06-0.1244.h5\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 2.2902 - accuracy: 0.1242 - val_loss: 2.2984 - val_accuracy: 0.1244\n",
      "Epoch 7/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 2.2964 - accuracy: 0.1170\n",
      "Epoch 00007: val_accuracy did not improve from 0.12439\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 2.2970 - accuracy: 0.1166 - val_loss: 2.2949 - val_accuracy: 0.1110\n",
      "Epoch 8/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 2.2883 - accuracy: 0.1225\n",
      "Epoch 00008: val_accuracy did not improve from 0.12439\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 2.2885 - accuracy: 0.1221 - val_loss: 2.2960 - val_accuracy: 0.1110\n",
      "Epoch 9/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 2.2859 - accuracy: 0.1229\n",
      "Epoch 00009: val_accuracy did not improve from 0.12439\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 2.2861 - accuracy: 0.1224 - val_loss: 2.2975 - val_accuracy: 0.1146\n",
      "Epoch 10/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 2.2800 - accuracy: 0.1339\n",
      "Epoch 00010: val_accuracy did not improve from 0.12439\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 2.2799 - accuracy: 0.1337 - val_loss: 2.2943 - val_accuracy: 0.1146\n",
      "Epoch 11/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 2.2660 - accuracy: 0.1461\n",
      "Epoch 00011: val_accuracy improved from 0.12439 to 0.13171, saving model to ./models/11-0.1317.h5\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 2.2659 - accuracy: 0.1471 - val_loss: 2.2893 - val_accuracy: 0.1317\n",
      "Epoch 12/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 2.2504 - accuracy: 0.1639\n",
      "Epoch 00012: val_accuracy improved from 0.13171 to 0.15122, saving model to ./models/12-0.1512.h5\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 2.2501 - accuracy: 0.1642 - val_loss: 2.2799 - val_accuracy: 0.1512\n",
      "Epoch 13/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 2.2094 - accuracy: 0.1817\n",
      "Epoch 00013: val_accuracy improved from 0.15122 to 0.18780, saving model to ./models/13-0.1878.h5\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 2.2093 - accuracy: 0.1816 - val_loss: 2.2342 - val_accuracy: 0.1878\n",
      "Epoch 14/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 2.1127 - accuracy: 0.2169\n",
      "Epoch 00014: val_accuracy improved from 0.18780 to 0.20854, saving model to ./models/14-0.2085.h5\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 2.1126 - accuracy: 0.2170 - val_loss: 2.1580 - val_accuracy: 0.2085\n",
      "Epoch 15/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 2.0294 - accuracy: 0.2570\n",
      "Epoch 00015: val_accuracy improved from 0.20854 to 0.26707, saving model to ./models/15-0.2671.h5\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 2.0296 - accuracy: 0.2567 - val_loss: 2.0925 - val_accuracy: 0.2671\n",
      "Epoch 16/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 1.9808 - accuracy: 0.2733\n",
      "Epoch 00016: val_accuracy improved from 0.26707 to 0.27561, saving model to ./models/16-0.2756.h5\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 1.9802 - accuracy: 0.2735 - val_loss: 2.0335 - val_accuracy: 0.2756\n",
      "Epoch 17/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 1.9069 - accuracy: 0.3143\n",
      "Epoch 00017: val_accuracy improved from 0.27561 to 0.28415, saving model to ./models/17-0.2841.h5\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 1.9074 - accuracy: 0.3138 - val_loss: 2.0582 - val_accuracy: 0.2841\n",
      "Epoch 18/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 1.8725 - accuracy: 0.3232\n",
      "Epoch 00018: val_accuracy improved from 0.28415 to 0.32439, saving model to ./models/18-0.3244.h5\n",
      "3276/3276 [==============================] - 8s 2ms/sample - loss: 1.8735 - accuracy: 0.3223 - val_loss: 1.9392 - val_accuracy: 0.3244\n",
      "Epoch 19/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 1.8104 - accuracy: 0.3385\n",
      "Epoch 00019: val_accuracy improved from 0.32439 to 0.33171, saving model to ./models/19-0.3317.h5\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 1.8115 - accuracy: 0.3379 - val_loss: 1.9076 - val_accuracy: 0.3317\n",
      "Epoch 20/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 1.8008 - accuracy: 0.3493\n",
      "Epoch 00020: val_accuracy improved from 0.33171 to 0.35488, saving model to ./models/20-0.3549.h5\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 1.8004 - accuracy: 0.3492 - val_loss: 1.8773 - val_accuracy: 0.3549\n",
      "Epoch 21/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 1.7336 - accuracy: 0.3698\n",
      "Epoch 00021: val_accuracy did not improve from 0.35488\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 1.7348 - accuracy: 0.3690 - val_loss: 1.8672 - val_accuracy: 0.3293\n",
      "Epoch 22/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 1.6918 - accuracy: 0.3811\n",
      "Epoch 00022: val_accuracy did not improve from 0.35488\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 1.6935 - accuracy: 0.3803 - val_loss: 1.8319 - val_accuracy: 0.3549\n",
      "Epoch 23/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 1.6523 - accuracy: 0.3980\n",
      "Epoch 00023: val_accuracy improved from 0.35488 to 0.37439, saving model to ./models/23-0.3744.h5\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 1.6532 - accuracy: 0.3980 - val_loss: 1.7777 - val_accuracy: 0.3744\n",
      "Epoch 24/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 1.6243 - accuracy: 0.4124\n",
      "Epoch 00024: val_accuracy improved from 0.37439 to 0.39146, saving model to ./models/24-0.3915.h5\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 1.6223 - accuracy: 0.4133 - val_loss: 1.7681 - val_accuracy: 0.3915\n",
      "Epoch 25/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 1.6073 - accuracy: 0.4237\n",
      "Epoch 00025: val_accuracy improved from 0.39146 to 0.39756, saving model to ./models/25-0.3976.h5\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 1.6084 - accuracy: 0.4234 - val_loss: 1.7495 - val_accuracy: 0.3976\n",
      "Epoch 26/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 1.5610 - accuracy: 0.4436\n",
      "Epoch 00026: val_accuracy did not improve from 0.39756\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 1.5610 - accuracy: 0.4438 - val_loss: 1.7004 - val_accuracy: 0.3976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 1.5524 - accuracy: 0.4452\n",
      "Epoch 00027: val_accuracy improved from 0.39756 to 0.41707, saving model to ./models/27-0.4171.h5\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 1.5521 - accuracy: 0.4454 - val_loss: 1.6674 - val_accuracy: 0.4171\n",
      "Epoch 28/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 1.5145 - accuracy: 0.4593\n",
      "Epoch 00028: val_accuracy improved from 0.41707 to 0.43171, saving model to ./models/28-0.4317.h5\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 1.5160 - accuracy: 0.4585 - val_loss: 1.6399 - val_accuracy: 0.4317\n",
      "Epoch 29/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 1.4633 - accuracy: 0.4847\n",
      "Epoch 00029: val_accuracy did not improve from 0.43171\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 1.4630 - accuracy: 0.4847 - val_loss: 1.6524 - val_accuracy: 0.4305\n",
      "Epoch 30/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 1.4396 - accuracy: 0.4899\n",
      "Epoch 00030: val_accuracy improved from 0.43171 to 0.44268, saving model to ./models/30-0.4427.h5\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 1.4394 - accuracy: 0.4899 - val_loss: 1.6101 - val_accuracy: 0.4427\n",
      "Epoch 31/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 1.4318 - accuracy: 0.4930\n",
      "Epoch 00031: val_accuracy improved from 0.44268 to 0.44878, saving model to ./models/31-0.4488.h5\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 1.4308 - accuracy: 0.4939 - val_loss: 1.5723 - val_accuracy: 0.4488\n",
      "Epoch 32/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 1.4212 - accuracy: 0.5055\n",
      "Epoch 00032: val_accuracy improved from 0.44878 to 0.47805, saving model to ./models/32-0.4780.h5\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 1.4205 - accuracy: 0.5058 - val_loss: 1.5587 - val_accuracy: 0.4780\n",
      "Epoch 33/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 1.3949 - accuracy: 0.5175\n",
      "Epoch 00033: val_accuracy did not improve from 0.47805\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 1.3946 - accuracy: 0.5177 - val_loss: 1.5942 - val_accuracy: 0.4671\n",
      "Epoch 34/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 1.3745 - accuracy: 0.5172\n",
      "Epoch 00034: val_accuracy did not improve from 0.47805\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 1.3759 - accuracy: 0.5159 - val_loss: 1.5673 - val_accuracy: 0.4732\n",
      "Epoch 35/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 1.3450 - accuracy: 0.5294\n",
      "Epoch 00035: val_accuracy improved from 0.47805 to 0.49146, saving model to ./models/35-0.4915.h5\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 1.3453 - accuracy: 0.5290 - val_loss: 1.5140 - val_accuracy: 0.4915\n",
      "Epoch 36/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 1.3143 - accuracy: 0.5389\n",
      "Epoch 00036: val_accuracy improved from 0.49146 to 0.51341, saving model to ./models/36-0.5134.h5\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 1.3140 - accuracy: 0.5388 - val_loss: 1.5055 - val_accuracy: 0.5134\n",
      "Epoch 37/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 1.2947 - accuracy: 0.5450\n",
      "Epoch 00037: val_accuracy did not improve from 0.51341\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 1.2947 - accuracy: 0.5452 - val_loss: 1.4924 - val_accuracy: 0.5098\n",
      "Epoch 38/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 1.2885 - accuracy: 0.5518\n",
      "Epoch 00038: val_accuracy did not improve from 0.51341\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 1.2865 - accuracy: 0.5528 - val_loss: 1.4821 - val_accuracy: 0.5024\n",
      "Epoch 39/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 1.2581 - accuracy: 0.5662\n",
      "Epoch 00039: val_accuracy did not improve from 0.51341\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 1.2591 - accuracy: 0.5659 - val_loss: 1.4854 - val_accuracy: 0.5000\n",
      "Epoch 40/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 1.2439 - accuracy: 0.5640\n",
      "Epoch 00040: val_accuracy did not improve from 0.51341\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 1.2419 - accuracy: 0.5647 - val_loss: 1.4929 - val_accuracy: 0.4939\n",
      "Epoch 41/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 1.2183 - accuracy: 0.5809\n",
      "Epoch 00041: val_accuracy did not improve from 0.51341\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 1.2186 - accuracy: 0.5806 - val_loss: 1.4355 - val_accuracy: 0.5134\n",
      "Epoch 42/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 1.1831 - accuracy: 0.5858\n",
      "Epoch 00042: val_accuracy did not improve from 0.51341\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 1.1830 - accuracy: 0.5855 - val_loss: 1.4445 - val_accuracy: 0.5012\n",
      "Epoch 43/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 1.1821 - accuracy: 0.5916\n",
      "Epoch 00043: val_accuracy improved from 0.51341 to 0.51707, saving model to ./models/43-0.5171.h5\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 1.1821 - accuracy: 0.5916 - val_loss: 1.4333 - val_accuracy: 0.5171\n",
      "Epoch 44/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 1.1523 - accuracy: 0.6045\n",
      "Epoch 00044: val_accuracy improved from 0.51707 to 0.53537, saving model to ./models/44-0.5354.h5\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 1.1522 - accuracy: 0.6038 - val_loss: 1.3993 - val_accuracy: 0.5354\n",
      "Epoch 45/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 1.1198 - accuracy: 0.6201\n",
      "Epoch 00045: val_accuracy did not improve from 0.53537\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 1.1180 - accuracy: 0.6206 - val_loss: 1.4338 - val_accuracy: 0.5220\n",
      "Epoch 46/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 1.1071 - accuracy: 0.6222\n",
      "Epoch 00046: val_accuracy did not improve from 0.53537\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 1.1064 - accuracy: 0.6227 - val_loss: 1.3864 - val_accuracy: 0.5256\n",
      "Epoch 47/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 1.1099 - accuracy: 0.6180\n",
      "Epoch 00047: val_accuracy did not improve from 0.53537\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 1.1107 - accuracy: 0.6172 - val_loss: 1.4330 - val_accuracy: 0.5110\n",
      "Epoch 48/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 1.0892 - accuracy: 0.6287\n",
      "Epoch 00048: val_accuracy did not improve from 0.53537\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 1.0907 - accuracy: 0.6282 - val_loss: 1.3880 - val_accuracy: 0.5280\n",
      "Epoch 49/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 1.0835 - accuracy: 0.6357\n",
      "Epoch 00049: val_accuracy improved from 0.53537 to 0.53659, saving model to ./models/49-0.5366.h5\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 1.0829 - accuracy: 0.6358 - val_loss: 1.3638 - val_accuracy: 0.5366\n",
      "Epoch 50/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 1.0797 - accuracy: 0.6229\n",
      "Epoch 00050: val_accuracy improved from 0.53659 to 0.54146, saving model to ./models/50-0.5415.h5\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 1.0781 - accuracy: 0.6230 - val_loss: 1.3615 - val_accuracy: 0.5415\n",
      "Epoch 51/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 1.0596 - accuracy: 0.6327\n",
      "Epoch 00051: val_accuracy improved from 0.54146 to 0.55000, saving model to ./models/51-0.5500.h5\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 1.0587 - accuracy: 0.6331 - val_loss: 1.3591 - val_accuracy: 0.5500\n",
      "Epoch 52/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 1.0130 - accuracy: 0.6520\n",
      "Epoch 00052: val_accuracy did not improve from 0.55000\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 1.0131 - accuracy: 0.6517 - val_loss: 1.3646 - val_accuracy: 0.5220\n",
      "Epoch 53/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 1.0205 - accuracy: 0.6648\n",
      "Epoch 00053: val_accuracy did not improve from 0.55000\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 1.0225 - accuracy: 0.6639 - val_loss: 1.3971 - val_accuracy: 0.5256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.9648 - accuracy: 0.6648\n",
      "Epoch 00054: val_accuracy did not improve from 0.55000\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 0.9651 - accuracy: 0.6651 - val_loss: 1.3357 - val_accuracy: 0.5366\n",
      "Epoch 55/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.9736 - accuracy: 0.6651\n",
      "Epoch 00055: val_accuracy improved from 0.55000 to 0.55488, saving model to ./models/55-0.5549.h5\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 0.9728 - accuracy: 0.6658 - val_loss: 1.3516 - val_accuracy: 0.5549\n",
      "Epoch 56/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.9409 - accuracy: 0.6746\n",
      "Epoch 00056: val_accuracy improved from 0.55488 to 0.55732, saving model to ./models/56-0.5573.h5\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 0.9410 - accuracy: 0.6743 - val_loss: 1.3128 - val_accuracy: 0.5573\n",
      "Epoch 57/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.9096 - accuracy: 0.6909\n",
      "Epoch 00057: val_accuracy did not improve from 0.55732\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 0.9084 - accuracy: 0.6914 - val_loss: 1.3691 - val_accuracy: 0.5366\n",
      "Epoch 58/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.8852 - accuracy: 0.6988\n",
      "Epoch 00058: val_accuracy did not improve from 0.55732\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 0.8866 - accuracy: 0.6987 - val_loss: 1.3361 - val_accuracy: 0.5463\n",
      "Epoch 59/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.8954 - accuracy: 0.6936\n",
      "Epoch 00059: val_accuracy did not improve from 0.55732\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 0.8956 - accuracy: 0.6938 - val_loss: 1.3215 - val_accuracy: 0.5549\n",
      "Epoch 60/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.8962 - accuracy: 0.6970\n",
      "Epoch 00060: val_accuracy did not improve from 0.55732\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 0.8974 - accuracy: 0.6966 - val_loss: 1.3696 - val_accuracy: 0.5378\n",
      "Epoch 61/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.8515 - accuracy: 0.7132\n",
      "Epoch 00061: val_accuracy did not improve from 0.55732\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 0.8506 - accuracy: 0.7134 - val_loss: 1.3190 - val_accuracy: 0.5549\n",
      "Epoch 62/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.8394 - accuracy: 0.7151\n",
      "Epoch 00062: val_accuracy improved from 0.55732 to 0.57073, saving model to ./models/62-0.5707.h5\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 0.8407 - accuracy: 0.7149 - val_loss: 1.2711 - val_accuracy: 0.5707\n",
      "Epoch 63/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.8281 - accuracy: 0.7188\n",
      "Epoch 00063: val_accuracy did not improve from 0.57073\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 0.8301 - accuracy: 0.7179 - val_loss: 1.3233 - val_accuracy: 0.5561\n",
      "Epoch 64/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.7892 - accuracy: 0.7350\n",
      "Epoch 00064: val_accuracy did not improve from 0.57073\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 0.7904 - accuracy: 0.7344 - val_loss: 1.3146 - val_accuracy: 0.5671\n",
      "Epoch 65/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.8383 - accuracy: 0.7224\n",
      "Epoch 00065: val_accuracy did not improve from 0.57073\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 0.8366 - accuracy: 0.7231 - val_loss: 1.2838 - val_accuracy: 0.5634\n",
      "Epoch 66/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.7843 - accuracy: 0.7335\n",
      "Epoch 00066: val_accuracy improved from 0.57073 to 0.57195, saving model to ./models/66-0.5720.h5\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 0.7830 - accuracy: 0.7338 - val_loss: 1.2940 - val_accuracy: 0.5720\n",
      "Epoch 67/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.7360 - accuracy: 0.7518\n",
      "Epoch 00067: val_accuracy did not improve from 0.57195\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 0.7365 - accuracy: 0.7521 - val_loss: 1.3056 - val_accuracy: 0.5549\n",
      "Epoch 68/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.7523 - accuracy: 0.7567\n",
      "Epoch 00068: val_accuracy did not improve from 0.57195\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 0.7536 - accuracy: 0.7561 - val_loss: 1.2730 - val_accuracy: 0.5707\n",
      "Epoch 69/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.7001 - accuracy: 0.7659\n",
      "Epoch 00069: val_accuracy improved from 0.57195 to 0.59268, saving model to ./models/69-0.5927.h5\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 0.7000 - accuracy: 0.7659 - val_loss: 1.2437 - val_accuracy: 0.5927\n",
      "Epoch 70/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.7224 - accuracy: 0.7583\n",
      "Epoch 00070: val_accuracy did not improve from 0.59268\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 0.7234 - accuracy: 0.7582 - val_loss: 1.2913 - val_accuracy: 0.5671\n",
      "Epoch 71/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.7350 - accuracy: 0.7583\n",
      "Epoch 00071: val_accuracy did not improve from 0.59268\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 0.7371 - accuracy: 0.7579 - val_loss: 1.2626 - val_accuracy: 0.5793\n",
      "Epoch 72/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.7800 - accuracy: 0.7399\n",
      "Epoch 00072: val_accuracy did not improve from 0.59268\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 0.7801 - accuracy: 0.7399 - val_loss: 1.2886 - val_accuracy: 0.5646\n",
      "Epoch 73/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.6785 - accuracy: 0.7708\n",
      "Epoch 00073: val_accuracy did not improve from 0.59268\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 0.6797 - accuracy: 0.7708 - val_loss: 1.2921 - val_accuracy: 0.5793\n",
      "Epoch 74/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.6826 - accuracy: 0.7782\n",
      "Epoch 00074: val_accuracy did not improve from 0.59268\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 0.6827 - accuracy: 0.7781 - val_loss: 1.2389 - val_accuracy: 0.5927\n",
      "Epoch 75/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.7078 - accuracy: 0.7718\n",
      "Epoch 00075: val_accuracy did not improve from 0.59268\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 0.7101 - accuracy: 0.7711 - val_loss: 1.3442 - val_accuracy: 0.5622\n",
      "Epoch 76/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.6789 - accuracy: 0.7788\n",
      "Epoch 00076: val_accuracy did not improve from 0.59268\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 0.6793 - accuracy: 0.7784 - val_loss: 1.2777 - val_accuracy: 0.5537\n",
      "Epoch 77/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.6202 - accuracy: 0.7944\n",
      "Epoch 00077: val_accuracy did not improve from 0.59268\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 0.6215 - accuracy: 0.7943 - val_loss: 1.3189 - val_accuracy: 0.5646\n",
      "Epoch 78/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.6849 - accuracy: 0.7776\n",
      "Epoch 00078: val_accuracy did not improve from 0.59268\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 0.6841 - accuracy: 0.7778 - val_loss: 1.3626 - val_accuracy: 0.5451\n",
      "Epoch 79/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.6228 - accuracy: 0.7929\n",
      "Epoch 00079: val_accuracy did not improve from 0.59268\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 0.6231 - accuracy: 0.7927 - val_loss: 1.3005 - val_accuracy: 0.5793\n",
      "Epoch 80/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.5913 - accuracy: 0.8091\n",
      "Epoch 00080: val_accuracy did not improve from 0.59268\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 0.5921 - accuracy: 0.8092 - val_loss: 1.2994 - val_accuracy: 0.5695\n",
      "Epoch 81/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.5857 - accuracy: 0.8082\n",
      "Epoch 00081: val_accuracy did not improve from 0.59268\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 0.5869 - accuracy: 0.8083 - val_loss: 1.3215 - val_accuracy: 0.5720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.6090 - accuracy: 0.7929\n",
      "Epoch 00082: val_accuracy did not improve from 0.59268\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 0.6087 - accuracy: 0.7927 - val_loss: 1.3378 - val_accuracy: 0.5598\n",
      "Epoch 83/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.5990 - accuracy: 0.8002\n",
      "Epoch 00083: val_accuracy did not improve from 0.59268\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 0.5997 - accuracy: 0.7998 - val_loss: 1.2866 - val_accuracy: 0.5817\n",
      "Epoch 84/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.5748 - accuracy: 0.8067\n",
      "Epoch 00084: val_accuracy did not improve from 0.59268\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 0.5780 - accuracy: 0.8065 - val_loss: 1.2946 - val_accuracy: 0.5707\n",
      "Epoch 85/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.6898 - accuracy: 0.7754\n",
      "Epoch 00085: val_accuracy did not improve from 0.59268\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 0.6898 - accuracy: 0.7753 - val_loss: 1.2926 - val_accuracy: 0.5829\n",
      "Epoch 86/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.5601 - accuracy: 0.8061\n",
      "Epoch 00086: val_accuracy did not improve from 0.59268\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 0.5594 - accuracy: 0.8062 - val_loss: 1.3091 - val_accuracy: 0.5829\n",
      "Epoch 87/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.5573 - accuracy: 0.8192\n",
      "Epoch 00087: val_accuracy improved from 0.59268 to 0.60122, saving model to ./models/87-0.6012.h5\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 0.5557 - accuracy: 0.8199 - val_loss: 1.3133 - val_accuracy: 0.6012\n",
      "Epoch 88/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.5604 - accuracy: 0.8146\n",
      "Epoch 00088: val_accuracy did not improve from 0.60122\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 0.5614 - accuracy: 0.8144 - val_loss: 1.2742 - val_accuracy: 0.5976\n",
      "Epoch 89/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.5096 - accuracy: 0.8352\n",
      "Epoch 00089: val_accuracy did not improve from 0.60122\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 0.5084 - accuracy: 0.8355 - val_loss: 1.2861 - val_accuracy: 0.5963\n",
      "Epoch 90/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.4692 - accuracy: 0.8425\n",
      "Epoch 00090: val_accuracy did not improve from 0.60122\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 0.4692 - accuracy: 0.8425 - val_loss: 1.2815 - val_accuracy: 0.5890\n",
      "Epoch 91/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.4997 - accuracy: 0.8413\n",
      "Epoch 00091: val_accuracy did not improve from 0.60122\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 0.5009 - accuracy: 0.8407 - val_loss: 1.3318 - val_accuracy: 0.5768\n",
      "Epoch 92/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.5305 - accuracy: 0.8260\n",
      "Epoch 00092: val_accuracy did not improve from 0.60122\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 0.5293 - accuracy: 0.8266 - val_loss: 1.2881 - val_accuracy: 0.5902\n",
      "Epoch 93/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.4588 - accuracy: 0.8413\n",
      "Epoch 00093: val_accuracy improved from 0.60122 to 0.60488, saving model to ./models/93-0.6049.h5\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 0.4611 - accuracy: 0.8407 - val_loss: 1.2979 - val_accuracy: 0.6049\n",
      "Epoch 94/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.4631 - accuracy: 0.8477\n",
      "Epoch 00094: val_accuracy did not improve from 0.60488\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 0.4625 - accuracy: 0.8480 - val_loss: 1.3252 - val_accuracy: 0.5817\n",
      "Epoch 95/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.4592 - accuracy: 0.8499\n",
      "Epoch 00095: val_accuracy did not improve from 0.60488\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 0.4625 - accuracy: 0.8495 - val_loss: 1.2942 - val_accuracy: 0.5866\n",
      "Epoch 96/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.4835 - accuracy: 0.8471\n",
      "Epoch 00096: val_accuracy did not improve from 0.60488\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 0.4831 - accuracy: 0.8468 - val_loss: 1.2773 - val_accuracy: 0.5720\n",
      "Epoch 97/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.4629 - accuracy: 0.8536\n",
      "Epoch 00097: val_accuracy did not improve from 0.60488\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 0.4619 - accuracy: 0.8538 - val_loss: 1.2876 - val_accuracy: 0.5878\n",
      "Epoch 98/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.4737 - accuracy: 0.8459\n",
      "Epoch 00098: val_accuracy did not improve from 0.60488\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 0.4727 - accuracy: 0.8462 - val_loss: 1.3324 - val_accuracy: 0.5854\n",
      "Epoch 99/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.4572 - accuracy: 0.8529\n",
      "Epoch 00099: val_accuracy did not improve from 0.60488\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 0.4572 - accuracy: 0.8529 - val_loss: 1.3169 - val_accuracy: 0.5866\n",
      "Epoch 100/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.3858 - accuracy: 0.8775\n",
      "Epoch 00100: val_accuracy did not improve from 0.60488\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 0.3866 - accuracy: 0.8773 - val_loss: 1.2948 - val_accuracy: 0.5939\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam', metrics = ['accuracy'], loss = 'categorical_crossentropy')\n",
    "history = model.fit([x_train, x_letter_train], y_train, validation_data=([x_val, x_letter_val], y_val), \n",
    "                    batch_size=64, epochs=100, verbose=1, \n",
    "                    callbacks = [ModelCheckpoint('./models/{epoch:02d}-{val_accuracy:.4f}.h5',\n",
    "                    monitor='val_accuracy', verbose=1, save_best_only=True, mode='auto')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T05:46:15.639233Z",
     "start_time": "2020-08-18T05:46:15.485479Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20480, 28, 28, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = test.drop(['id', 'letter'], axis=1).values\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test/255\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T05:46:15.643254Z",
     "start_time": "2020-08-18T05:46:15.640233Z"
    }
   },
   "outputs": [],
   "source": [
    "#prediction = np.argmax(model.predict(x_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T05:46:15.657258Z",
     "start_time": "2020-08-18T05:46:15.644234Z"
    }
   },
   "outputs": [],
   "source": [
    "#submission = pd.read_csv('data/submission.csv')\n",
    "#submission['digit'] = np.argmax(model.predict(x_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T05:46:15.665240Z",
     "start_time": "2020-08-18T05:46:15.658231Z"
    }
   },
   "outputs": [],
   "source": [
    "#submission.to_csv('data/submission1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T10:46:55.355621Z",
     "start_time": "2020-08-20T10:46:49.821294Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.layers import concatenate, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# seed\n",
    "import os\n",
    "seed = 123\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T11:01:49.911053Z",
     "start_time": "2020-08-20T11:01:48.291952Z"
    }
   },
   "outputs": [],
   "source": [
    "train = np.load('data/train.npy', allow_pickle = 'True')\n",
    "test = np.load('data/test.npy', allow_pickle = 'True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T11:01:49.920013Z",
     "start_time": "2020-08-20T11:01:49.912926Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2048, 28, 28, 1)\n",
      "(2048, 1)\n",
      "(2048, 1)\n"
     ]
    }
   ],
   "source": [
    "x = train[:,2:]\n",
    "x = np.reshape(x, (-1, 28, 28, 1))\n",
    "x_letter = train[:,1]\n",
    "x_letter = np.reshape(x_letter, (-1, 1))\n",
    "y = train[:,0]\n",
    "y = np.reshape(y, (-1, 1))\n",
    "\n",
    "print(x.shape)\n",
    "print(x_letter.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T11:01:50.627656Z",
     "start_time": "2020-08-20T11:01:50.624752Z"
    }
   },
   "outputs": [],
   "source": [
    "image_generator = ImageDataGenerator(width_shift_range=0.1,\n",
    "                                     height_shift_range=0.1, \n",
    "                                     zoom_range=[0.8,1.2],\n",
    "                                     shear_range=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T11:01:53.250203Z",
     "start_time": "2020-08-20T11:01:51.014202Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6144, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "x_total = x.copy()\n",
    "\n",
    "def augment(x):\n",
    "    aug_list = []\n",
    "    for i in range(x.shape[0]):\n",
    "        num_aug = 0\n",
    "        tmp = x[i]\n",
    "        tmp = tmp.reshape((1,) + tmp.shape)\n",
    "        for x_aug in image_generator.flow(tmp, batch_size = 1) :\n",
    "            if num_aug >= 1:\n",
    "                break\n",
    "            aug_list.append(x_aug[0])\n",
    "            num_aug += 1\n",
    "    aug_list = np.array(aug_list)\n",
    "    return aug_list\n",
    "\n",
    "n = 2\n",
    "for i in range(n):\n",
    "    arr = augment(x)\n",
    "    x_total = np.concatenate((x_total, arr), axis=0)\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "print(x_total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T11:01:58.267241Z",
     "start_time": "2020-08-20T11:01:58.257831Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6144, 10)\n"
     ]
    }
   ],
   "source": [
    "y_total = y.copy()\n",
    "for i in range(n):\n",
    "    arr = y.copy()\n",
    "    y_total = np.concatenate((y_total, arr), axis=0)\n",
    "\n",
    "en = OneHotEncoder()\n",
    "y = en.fit_transform(y).toarray()\n",
    "\n",
    "print(y_total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T11:01:54.386676Z",
     "start_time": "2020-08-20T11:01:54.378598Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6144, 26)\n"
     ]
    }
   ],
   "source": [
    "x_letter_total = x_letter.copy()\n",
    "for i in range(n):\n",
    "    arr = x_letter.copy()\n",
    "    x_letter_total = np.concatenate((x_letter_total, arr), axis=0)\n",
    "\n",
    "en = OneHotEncoder()\n",
    "x_letter_total = en.fit_transform(x_letter_total).toarray()\n",
    "    \n",
    "print(x_letter_total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_train, x1_val, y1_train, y1_val = train_test_split(x_total, y_total, test_size=0.2, shuffle=True, stratify=y_total)\n",
    "\n",
    "print(x1_train.shape)\n",
    "print(x1_val.shape)\n",
    "print(y1_train.shape)\n",
    "print(y1_val.shape)\n",
    "\n",
    "x1_letter_train = x_letter_total[:x1_train.shape[0],:]\n",
    "x1_letter_val = x_letter_total[x1_train.shape[0]:,:]\n",
    "print(x1_letter_train.shape)\n",
    "print(x1_letter_val.shape)\n",
    "\n",
    "input1 = Input(shape=(28,28,1))\n",
    "x1 = Conv2D(64, (3,3), activation='relu', padding='same')(input1)\n",
    "x1 = Dropout(0.3)(x1)\n",
    "x1 = MaxPooling2D((2,2))(x1)\n",
    "x1 = Conv2D(64, (2,2), activation='relu', padding='same')(x1)\n",
    "x1 = Dropout(0.3)(x1)\n",
    "x1 = MaxPooling2D((2,2))(x1)\n",
    "x1 = Conv2D(128, (2,2), activation='relu', padding='same')(x1)\n",
    "x1 = Dropout(0.3)(x1)\n",
    "x1 = MaxPooling2D((2,2))(x1)\n",
    "x1 = Flatten()(x1)\n",
    "\n",
    "input2 = Input(shape=(26,))\n",
    "merge = concatenate([x1, input2])\n",
    "\n",
    "x2 = Dense(500, activation='relu')(merge)\n",
    "x2 = Dropout(0.3)(x2)\n",
    "x2 = Dense(100, activation='relu')(x2)\n",
    "x2 = Dropout(0.3)(x2)\n",
    "x2 = Dense(50, activation='relu')(x2)\n",
    "outputs = Dense(10, activation='softmax')(x2)\n",
    "\n",
    "model = Model(inputs = [input1, input2], outputs = outputs)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer = 'adam', metrics = ['accuracy'], loss = 'categorical_crossentropy')\n",
    "\n",
    "cp = ModelCheckpoint('./models/{epoch:02d}-{val_accuracy:.4f}.h5', monitor='val_loss',\n",
    "                     save_best_only=True, mode='min')\n",
    "\n",
    "history = model.fit([x1_train, x1_letter_train], y1_train,\n",
    "                    validation_data=([x1_val, x1_letter_val], y1_val), \n",
    "                    batch_size=64, epochs=50, verbose=1, callbacks = [cp])\n",
    "\n",
    "x_test = test.drop(['id', 'letter'], axis=1).values\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test/255\n",
    "\n",
    "x_letter_test = test['letter'].values\n",
    "x_letter_test = x_letter_test[:, np.newaxis]\n",
    "en = OneHotEncoder()\n",
    "x_letter_test = en.fit_transform(x_letter_test).toarray()\n",
    "\n",
    "submission = pd.read_csv('data/submission.csv')\n",
    "submission['digit'] = np.argmax(best_model.predict([x_test, x_letter_test]), axis=1)\n",
    "submission.to_csv('data/submission(CNN).csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T07:08:17.466788Z",
     "start_time": "2020-08-21T07:08:14.780860Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.layers import concatenate, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# seed\n",
    "import os\n",
    "seed = 123\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T07:08:19.096462Z",
     "start_time": "2020-08-21T07:08:17.468793Z"
    }
   },
   "outputs": [],
   "source": [
    "train = np.load('data/train.npy', allow_pickle = 'True')\n",
    "test = np.load('data/test.npy', allow_pickle = 'True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T07:08:19.112396Z",
     "start_time": "2020-08-21T07:08:19.098454Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2048, 28, 28, 1)\n",
      "(2048, 26)\n",
      "(2048, 10)\n"
     ]
    }
   ],
   "source": [
    "x = train[:,2:]\n",
    "x = np.reshape(x, (-1, 28, 28, 1))\n",
    "\n",
    "x_letter = train[:,1]\n",
    "x_letter = np.reshape(x_letter, (-1, 1))\n",
    "en = OneHotEncoder()\n",
    "x_letter = en.fit_transform(x_letter).toarray()\n",
    "\n",
    "y = train[:,0]\n",
    "y = np.reshape(y, (-1, 1))\n",
    "en = OneHotEncoder()\n",
    "y = en.fit_transform(y).toarray()\n",
    "\n",
    "print(x.shape)\n",
    "print(x_letter.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T07:08:19.128327Z",
     "start_time": "2020-08-21T07:08:19.113392Z"
    }
   },
   "outputs": [],
   "source": [
    "image_generator = ImageDataGenerator(width_shift_range=0.1,\n",
    "                                     height_shift_range=0.1, \n",
    "                                     zoom_range=[0.8,1.2],\n",
    "                                     shear_range=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T07:08:21.675117Z",
     "start_time": "2020-08-21T07:08:19.130324Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6144, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "x_total = x.copy()\n",
    "def augment(x):\n",
    "    aug_list = []\n",
    "    for i in range(x.shape[0]):\n",
    "        num_aug = 0\n",
    "        tmp = x[i]\n",
    "        tmp = tmp.reshape((1,) + tmp.shape)\n",
    "        for x_aug in image_generator.flow(tmp, batch_size = 1) :\n",
    "            if num_aug >= 1:\n",
    "                break\n",
    "            aug_list.append(x_aug[0])\n",
    "            num_aug += 1\n",
    "    aug_list = np.array(aug_list)\n",
    "    return aug_list\n",
    "\n",
    "n = 2\n",
    "for i in range(n):\n",
    "    arr = augment(x)\n",
    "    x_total = np.concatenate((x_total, arr), axis=0)\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "print(x_total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T07:08:21.691011Z",
     "start_time": "2020-08-21T07:08:21.679064Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6144, 10)\n"
     ]
    }
   ],
   "source": [
    "y_total = y.copy()\n",
    "for i in range(n):\n",
    "    arr = y.copy()\n",
    "    y_total = np.concatenate((y_total, arr), axis=0)\n",
    "\n",
    "print(y_total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T07:08:21.708281Z",
     "start_time": "2020-08-21T07:08:21.695996Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6144, 26)\n"
     ]
    }
   ],
   "source": [
    "x_letter_total = x_letter.copy()\n",
    "for i in range(n):\n",
    "    arr = x_letter.copy()\n",
    "    x_letter_total = np.concatenate((x_letter_total, arr), axis=0)\n",
    "    \n",
    "print(x_letter_total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T07:08:21.751882Z",
     "start_time": "2020-08-21T07:08:21.710597Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4915, 28, 28, 1)\n",
      "(1229, 28, 28, 1)\n",
      "(4915, 10)\n",
      "(1229, 10)\n",
      "(4915, 26)\n",
      "(1229, 26)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_total, y_total, test_size=0.2, shuffle=True)#, stratify=y_total)\n",
    "x_letter_train = x_letter_total[:x_train.shape[0],:]\n",
    "x_letter_val = x_letter_total[x_train.shape[0]:,:]\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)\n",
    "print(x_letter_train.shape)\n",
    "print(x_letter_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T07:08:22.025753Z",
     "start_time": "2020-08-21T07:08:21.754870Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 28, 28, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 64)        16448     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 64)        16448     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 7, 7, 128)         32896     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 7, 7, 64)          32832     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 136,842\n",
      "Trainable params: 136,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input1 = Input(shape=(28,28,1))\n",
    "x1 = Conv2D(64, (3,3), activation='relu', padding='same')(input1)\n",
    "x1 = Conv2D(64, (3,3), activation='relu', padding='same')(x1)\n",
    "x1 = Dropout(0.3)(x1)\n",
    "x1 = MaxPooling2D((2,2))(x1)\n",
    "x1 = Conv2D(64, (2,2), activation='relu', padding='same')(x1)\n",
    "x1 = Conv2D(64, (2,2), activation='relu', padding='same')(x1)\n",
    "x1 = Dropout(0.3)(x1)\n",
    "x1 = MaxPooling2D((2,2))(x1)\n",
    "x1 = Conv2D(128, (2,2), activation='relu', padding='same')(x1)\n",
    "x1 = Conv2D(64, (2,2), activation='relu', padding='same')(x1)\n",
    "x1 = Dropout(0.3)(x1)\n",
    "x1 = GlobalAveragePooling2D()(x1)\n",
    "outputs = Dense(10, activation='softmax')(x1)\n",
    "#x1 = MaxPooling2D((2,2))(x1)\n",
    "#x1 = Flatten()(x1)\n",
    "\n",
    "#input2 = Input(shape=(26,))\n",
    "#x2 = Dense(50, activation='relu')(input2)\n",
    "#x2 = Dropout(0.3)(x2)\n",
    "\n",
    "#merge = concatenate([x1, input2])\n",
    "\n",
    "#x2 = Dense(500, activation='relu')(merge)\n",
    "#x2 = Dropout(0.3)(x2)\n",
    "#x2 = Dense(100, activation='relu')(x1)\n",
    "#x2 = Dropout(0.3)(x2)\n",
    "#x2 = Dense(50, activation='relu')(x2)\n",
    "#x2 = Dropout(0.3)(x2)\n",
    "#outputs = Dense(10, activation='softmax')(x2)\n",
    "\n",
    "model = Model(inputs = input1, outputs = outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T07:11:33.053817Z",
     "start_time": "2020-08-21T07:08:22.027803Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4915 samples, validate on 1229 samples\n",
      "Epoch 1/100\n",
      "4915/4915 [==============================] - 5s 1ms/step - loss: 2.4303 - acc: 0.1127 - val_loss: 2.2954 - val_acc: 0.1147\n",
      "Epoch 2/100\n",
      "4915/4915 [==============================] - 2s 389us/step - loss: 2.2761 - acc: 0.1392 - val_loss: 2.2670 - val_acc: 0.1440\n",
      "Epoch 3/100\n",
      "4915/4915 [==============================] - 2s 374us/step - loss: 2.2081 - acc: 0.1780 - val_loss: 2.2175 - val_acc: 0.2018\n",
      "Epoch 4/100\n",
      "4915/4915 [==============================] - 2s 371us/step - loss: 2.1509 - acc: 0.2155 - val_loss: 2.1258 - val_acc: 0.2669\n",
      "Epoch 5/100\n",
      "4915/4915 [==============================] - 2s 379us/step - loss: 1.9556 - acc: 0.3003 - val_loss: 1.9760 - val_acc: 0.3491\n",
      "Epoch 6/100\n",
      "4915/4915 [==============================] - 2s 374us/step - loss: 1.7936 - acc: 0.3672 - val_loss: 1.7417 - val_acc: 0.4028\n",
      "Epoch 7/100\n",
      "4915/4915 [==============================] - 2s 369us/step - loss: 1.6323 - acc: 0.4238 - val_loss: 1.7406 - val_acc: 0.4133\n",
      "Epoch 8/100\n",
      "4915/4915 [==============================] - 2s 377us/step - loss: 1.4662 - acc: 0.4889 - val_loss: 1.6207 - val_acc: 0.4963\n",
      "Epoch 9/100\n",
      "4915/4915 [==============================] - 2s 376us/step - loss: 1.3506 - acc: 0.5300 - val_loss: 1.3897 - val_acc: 0.5679\n",
      "Epoch 10/100\n",
      "4915/4915 [==============================] - 2s 375us/step - loss: 1.2151 - acc: 0.5788 - val_loss: 1.3241 - val_acc: 0.5761\n",
      "Epoch 11/100\n",
      "4915/4915 [==============================] - 2s 371us/step - loss: 1.1565 - acc: 0.6022 - val_loss: 1.3524 - val_acc: 0.5801\n",
      "Epoch 12/100\n",
      "4915/4915 [==============================] - 2s 383us/step - loss: 1.1118 - acc: 0.6157 - val_loss: 1.2004 - val_acc: 0.6282\n",
      "Epoch 13/100\n",
      "4915/4915 [==============================] - 2s 373us/step - loss: 0.9887 - acc: 0.6570 - val_loss: 1.2406 - val_acc: 0.6176\n",
      "Epoch 14/100\n",
      "4915/4915 [==============================] - 2s 383us/step - loss: 0.9292 - acc: 0.6814 - val_loss: 1.0846 - val_acc: 0.6713\n",
      "Epoch 15/100\n",
      "4915/4915 [==============================] - 2s 372us/step - loss: 0.8632 - acc: 0.6920 - val_loss: 1.1666 - val_acc: 0.6387\n",
      "Epoch 16/100\n",
      "4915/4915 [==============================] - 2s 374us/step - loss: 0.8503 - acc: 0.7074 - val_loss: 1.0247 - val_acc: 0.6762\n",
      "Epoch 17/100\n",
      "4915/4915 [==============================] - 2s 376us/step - loss: 0.7975 - acc: 0.7237 - val_loss: 0.9086 - val_acc: 0.7095\n",
      "Epoch 18/100\n",
      "4915/4915 [==============================] - 2s 374us/step - loss: 0.7509 - acc: 0.7432 - val_loss: 0.9505 - val_acc: 0.7006\n",
      "Epoch 19/100\n",
      "4915/4915 [==============================] - 2s 371us/step - loss: 0.7256 - acc: 0.7479 - val_loss: 0.8439 - val_acc: 0.7290\n",
      "Epoch 20/100\n",
      "4915/4915 [==============================] - 2s 372us/step - loss: 0.6582 - acc: 0.7762 - val_loss: 0.8670 - val_acc: 0.7201\n",
      "Epoch 21/100\n",
      "4915/4915 [==============================] - 2s 381us/step - loss: 0.6436 - acc: 0.7738 - val_loss: 0.8646 - val_acc: 0.7404\n",
      "Epoch 22/100\n",
      "4915/4915 [==============================] - 2s 375us/step - loss: 0.6017 - acc: 0.7919 - val_loss: 0.7683 - val_acc: 0.7632\n",
      "Epoch 23/100\n",
      "4915/4915 [==============================] - 2s 370us/step - loss: 0.5596 - acc: 0.8043 - val_loss: 0.7849 - val_acc: 0.7469\n",
      "Epoch 24/100\n",
      "4915/4915 [==============================] - 2s 376us/step - loss: 0.5235 - acc: 0.8151 - val_loss: 0.7354 - val_acc: 0.7657\n",
      "Epoch 25/100\n",
      "4915/4915 [==============================] - 2s 375us/step - loss: 0.5382 - acc: 0.8175 - val_loss: 0.8198 - val_acc: 0.7388\n",
      "Epoch 26/100\n",
      "4915/4915 [==============================] - 2s 371us/step - loss: 0.4762 - acc: 0.8315 - val_loss: 0.7407 - val_acc: 0.7657\n",
      "Epoch 27/100\n",
      "4915/4915 [==============================] - 2s 374us/step - loss: 0.4323 - acc: 0.8468 - val_loss: 0.6515 - val_acc: 0.7811\n",
      "Epoch 28/100\n",
      "4915/4915 [==============================] - 2s 378us/step - loss: 0.4639 - acc: 0.8415 - val_loss: 0.6908 - val_acc: 0.7787\n",
      "Epoch 29/100\n",
      "4915/4915 [==============================] - 2s 377us/step - loss: 0.4135 - acc: 0.8562 - val_loss: 0.6019 - val_acc: 0.8072\n",
      "Epoch 30/100\n",
      "4915/4915 [==============================] - 2s 371us/step - loss: 0.3748 - acc: 0.8696 - val_loss: 0.6995 - val_acc: 0.7592\n",
      "Epoch 31/100\n",
      "4915/4915 [==============================] - 2s 371us/step - loss: 0.3819 - acc: 0.8651 - val_loss: 0.6162 - val_acc: 0.7950\n",
      "Epoch 32/100\n",
      "4915/4915 [==============================] - 2s 380us/step - loss: 0.3507 - acc: 0.8775 - val_loss: 0.6685 - val_acc: 0.7819\n",
      "Epoch 33/100\n",
      "4915/4915 [==============================] - 2s 379us/step - loss: 0.3286 - acc: 0.8820 - val_loss: 0.5866 - val_acc: 0.8088\n",
      "Epoch 34/100\n",
      "4915/4915 [==============================] - 2s 378us/step - loss: 0.3260 - acc: 0.8855 - val_loss: 0.6825 - val_acc: 0.7860\n",
      "Epoch 35/100\n",
      "4915/4915 [==============================] - 2s 373us/step - loss: 0.3035 - acc: 0.8962 - val_loss: 0.7173 - val_acc: 0.7779\n",
      "Epoch 36/100\n",
      "4915/4915 [==============================] - 2s 371us/step - loss: 0.3412 - acc: 0.8783 - val_loss: 0.6671 - val_acc: 0.7909\n",
      "Epoch 37/100\n",
      "4915/4915 [==============================] - 2s 371us/step - loss: 0.2970 - acc: 0.8920 - val_loss: 0.5722 - val_acc: 0.8145\n",
      "Epoch 38/100\n",
      "4915/4915 [==============================] - 2s 377us/step - loss: 0.2920 - acc: 0.9021 - val_loss: 0.6645 - val_acc: 0.7909\n",
      "Epoch 39/100\n",
      "4915/4915 [==============================] - 2s 372us/step - loss: 0.2794 - acc: 0.9015 - val_loss: 0.5684 - val_acc: 0.8234\n",
      "Epoch 40/100\n",
      "4915/4915 [==============================] - 2s 373us/step - loss: 0.2412 - acc: 0.9168 - val_loss: 0.5628 - val_acc: 0.8259\n",
      "Epoch 41/100\n",
      "4915/4915 [==============================] - 2s 378us/step - loss: 0.2498 - acc: 0.9133 - val_loss: 0.5395 - val_acc: 0.8242\n",
      "Epoch 42/100\n",
      "4915/4915 [==============================] - 2s 375us/step - loss: 0.2327 - acc: 0.9172 - val_loss: 0.5791 - val_acc: 0.8234\n",
      "Epoch 43/100\n",
      "4915/4915 [==============================] - 2s 363us/step - loss: 0.2563 - acc: 0.9119 - val_loss: 0.6029 - val_acc: 0.7974\n",
      "Epoch 44/100\n",
      "4915/4915 [==============================] - 2s 365us/step - loss: 0.2285 - acc: 0.9202 - val_loss: 0.6481 - val_acc: 0.7884\n",
      "Epoch 45/100\n",
      "4915/4915 [==============================] - 2s 372us/step - loss: 0.2295 - acc: 0.9243 - val_loss: 0.5100 - val_acc: 0.8299\n",
      "Epoch 46/100\n",
      "4915/4915 [==============================] - 2s 369us/step - loss: 0.1827 - acc: 0.9390 - val_loss: 0.5481 - val_acc: 0.8283\n",
      "Epoch 47/100\n",
      "4915/4915 [==============================] - 2s 374us/step - loss: 0.2215 - acc: 0.9247 - val_loss: 0.5531 - val_acc: 0.8226\n",
      "Epoch 48/100\n",
      "4915/4915 [==============================] - 2s 369us/step - loss: 0.1912 - acc: 0.9373 - val_loss: 0.5510 - val_acc: 0.8226\n",
      "Epoch 49/100\n",
      "4915/4915 [==============================] - 2s 375us/step - loss: 0.2068 - acc: 0.9257 - val_loss: 0.4777 - val_acc: 0.8430\n",
      "Epoch 50/100\n",
      "4915/4915 [==============================] - 2s 373us/step - loss: 0.2058 - acc: 0.9337 - val_loss: 0.5832 - val_acc: 0.8039\n",
      "Epoch 51/100\n",
      "4915/4915 [==============================] - 2s 379us/step - loss: 0.1869 - acc: 0.9339 - val_loss: 0.5371 - val_acc: 0.8234\n",
      "Epoch 52/100\n",
      "4915/4915 [==============================] - 2s 369us/step - loss: 0.1771 - acc: 0.9355 - val_loss: 0.5040 - val_acc: 0.8356\n",
      "Epoch 53/100\n",
      "4915/4915 [==============================] - 2s 377us/step - loss: 0.1763 - acc: 0.9396 - val_loss: 0.4901 - val_acc: 0.8405\n",
      "Epoch 54/100\n",
      "4915/4915 [==============================] - 2s 370us/step - loss: 0.1684 - acc: 0.9410 - val_loss: 0.4828 - val_acc: 0.8470\n",
      "Epoch 55/100\n",
      "4915/4915 [==============================] - 2s 372us/step - loss: 0.1565 - acc: 0.9473 - val_loss: 0.4729 - val_acc: 0.8454\n",
      "Epoch 56/100\n",
      "4915/4915 [==============================] - 2s 376us/step - loss: 0.1565 - acc: 0.9465 - val_loss: 0.5610 - val_acc: 0.8161\n",
      "Epoch 57/100\n",
      "4915/4915 [==============================] - 2s 360us/step - loss: 0.1556 - acc: 0.9428 - val_loss: 0.4427 - val_acc: 0.8544\n",
      "Epoch 58/100\n",
      "4915/4915 [==============================] - 2s 372us/step - loss: 0.1788 - acc: 0.9386 - val_loss: 0.4850 - val_acc: 0.8446\n",
      "Epoch 59/100\n",
      "4915/4915 [==============================] - 2s 378us/step - loss: 0.1327 - acc: 0.9536 - val_loss: 0.4713 - val_acc: 0.8487\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4915/4915 [==============================] - 2s 374us/step - loss: 0.1232 - acc: 0.9563 - val_loss: 0.5149 - val_acc: 0.8381\n",
      "Epoch 61/100\n",
      "4915/4915 [==============================] - 2s 373us/step - loss: 0.1483 - acc: 0.9487 - val_loss: 0.4554 - val_acc: 0.8568\n",
      "Epoch 62/100\n",
      "4915/4915 [==============================] - 2s 376us/step - loss: 0.1413 - acc: 0.9491 - val_loss: 0.4969 - val_acc: 0.8430\n",
      "Epoch 63/100\n",
      "4915/4915 [==============================] - 2s 365us/step - loss: 0.1282 - acc: 0.9540 - val_loss: 0.4666 - val_acc: 0.8430\n",
      "Epoch 64/100\n",
      "4915/4915 [==============================] - 2s 377us/step - loss: 0.1212 - acc: 0.9573 - val_loss: 0.5567 - val_acc: 0.8251\n",
      "Epoch 65/100\n",
      "4915/4915 [==============================] - 2s 374us/step - loss: 0.1449 - acc: 0.9512 - val_loss: 0.5035 - val_acc: 0.8381\n",
      "Epoch 66/100\n",
      "4915/4915 [==============================] - 2s 372us/step - loss: 0.1343 - acc: 0.9534 - val_loss: 0.4778 - val_acc: 0.8552\n",
      "Epoch 67/100\n",
      "4915/4915 [==============================] - 2s 374us/step - loss: 0.1168 - acc: 0.9587 - val_loss: 0.4663 - val_acc: 0.8576\n",
      "Epoch 68/100\n",
      "4915/4915 [==============================] - 2s 371us/step - loss: 0.1215 - acc: 0.9544 - val_loss: 0.4634 - val_acc: 0.8478\n",
      "Epoch 69/100\n",
      "4915/4915 [==============================] - 2s 373us/step - loss: 0.1151 - acc: 0.9591 - val_loss: 0.5346 - val_acc: 0.8316\n",
      "Epoch 70/100\n",
      "4915/4915 [==============================] - 2s 375us/step - loss: 0.1278 - acc: 0.9540 - val_loss: 0.4913 - val_acc: 0.8340\n",
      "Epoch 71/100\n",
      "4915/4915 [==============================] - 2s 371us/step - loss: 0.1347 - acc: 0.9520 - val_loss: 0.4887 - val_acc: 0.8381\n",
      "Epoch 72/100\n",
      "4915/4915 [==============================] - 2s 374us/step - loss: 0.0845 - acc: 0.9705 - val_loss: 0.4614 - val_acc: 0.8552\n",
      "Epoch 73/100\n",
      "4915/4915 [==============================] - 2s 377us/step - loss: 0.1005 - acc: 0.9660 - val_loss: 0.5027 - val_acc: 0.8535\n",
      "Epoch 74/100\n",
      "4915/4915 [==============================] - 2s 376us/step - loss: 0.1404 - acc: 0.9522 - val_loss: 0.4896 - val_acc: 0.8487\n",
      "Epoch 75/100\n",
      "4915/4915 [==============================] - 2s 377us/step - loss: 0.1239 - acc: 0.9540 - val_loss: 0.4226 - val_acc: 0.8690\n",
      "Epoch 76/100\n",
      "4915/4915 [==============================] - 2s 374us/step - loss: 0.1239 - acc: 0.9558 - val_loss: 0.5512 - val_acc: 0.8348\n",
      "Epoch 77/100\n",
      "4915/4915 [==============================] - 2s 375us/step - loss: 0.1087 - acc: 0.9630 - val_loss: 0.5008 - val_acc: 0.8495\n",
      "Epoch 78/100\n",
      "4915/4915 [==============================] - 2s 376us/step - loss: 0.1203 - acc: 0.9581 - val_loss: 0.5880 - val_acc: 0.8112\n",
      "Epoch 79/100\n",
      "4915/4915 [==============================] - 2s 374us/step - loss: 0.1255 - acc: 0.9577 - val_loss: 0.5190 - val_acc: 0.8316\n",
      "Epoch 80/100\n",
      "4915/4915 [==============================] - 2s 365us/step - loss: 0.1059 - acc: 0.9646 - val_loss: 0.4245 - val_acc: 0.8617\n",
      "Epoch 81/100\n",
      "4915/4915 [==============================] - 2s 374us/step - loss: 0.1135 - acc: 0.9642 - val_loss: 0.5066 - val_acc: 0.8438\n",
      "Epoch 82/100\n",
      "4915/4915 [==============================] - 2s 372us/step - loss: 0.0978 - acc: 0.9654 - val_loss: 0.5011 - val_acc: 0.8438\n",
      "Epoch 83/100\n",
      "4915/4915 [==============================] - 2s 369us/step - loss: 0.1058 - acc: 0.9628 - val_loss: 0.4805 - val_acc: 0.8519\n",
      "Epoch 84/100\n",
      "4915/4915 [==============================] - 2s 375us/step - loss: 0.0865 - acc: 0.9687 - val_loss: 0.5038 - val_acc: 0.8421\n",
      "Epoch 85/100\n",
      "4915/4915 [==============================] - 2s 371us/step - loss: 0.0840 - acc: 0.9723 - val_loss: 0.4574 - val_acc: 0.8609\n",
      "Epoch 86/100\n",
      "4915/4915 [==============================] - 2s 379us/step - loss: 0.0974 - acc: 0.9666 - val_loss: 0.4475 - val_acc: 0.8552\n",
      "Epoch 87/100\n",
      "4915/4915 [==============================] - 2s 373us/step - loss: 0.0844 - acc: 0.9713 - val_loss: 0.4722 - val_acc: 0.8421\n",
      "Epoch 88/100\n",
      "4915/4915 [==============================] - 2s 376us/step - loss: 0.0982 - acc: 0.9693 - val_loss: 0.5147 - val_acc: 0.8495\n",
      "Epoch 89/100\n",
      "4915/4915 [==============================] - 2s 371us/step - loss: 0.1140 - acc: 0.9634 - val_loss: 0.4648 - val_acc: 0.8576\n",
      "Epoch 90/100\n",
      "4915/4915 [==============================] - 2s 371us/step - loss: 0.0953 - acc: 0.9652 - val_loss: 0.4628 - val_acc: 0.8560\n",
      "Epoch 91/100\n",
      "4915/4915 [==============================] - 2s 369us/step - loss: 0.1026 - acc: 0.9628 - val_loss: 0.4342 - val_acc: 0.8674\n",
      "Epoch 92/100\n",
      "4915/4915 [==============================] - 2s 374us/step - loss: 0.1108 - acc: 0.9617 - val_loss: 0.6177 - val_acc: 0.8177\n",
      "Epoch 93/100\n",
      "4915/4915 [==============================] - 2s 375us/step - loss: 0.0907 - acc: 0.9707 - val_loss: 0.4681 - val_acc: 0.8478\n",
      "Epoch 94/100\n",
      "4915/4915 [==============================] - 2s 384us/step - loss: 0.0981 - acc: 0.9683 - val_loss: 0.4084 - val_acc: 0.8771\n",
      "Epoch 95/100\n",
      "4915/4915 [==============================] - 2s 376us/step - loss: 0.0761 - acc: 0.9742 - val_loss: 0.5169 - val_acc: 0.8446\n",
      "Epoch 96/100\n",
      "4915/4915 [==============================] - 2s 382us/step - loss: 0.1163 - acc: 0.9634 - val_loss: 0.4436 - val_acc: 0.8657\n",
      "Epoch 97/100\n",
      "4915/4915 [==============================] - 2s 367us/step - loss: 0.1048 - acc: 0.9628 - val_loss: 0.4478 - val_acc: 0.8584\n",
      "Epoch 98/100\n",
      "4915/4915 [==============================] - 2s 379us/step - loss: 0.0833 - acc: 0.9695 - val_loss: 0.4778 - val_acc: 0.8470\n",
      "Epoch 99/100\n",
      "4915/4915 [==============================] - 2s 374us/step - loss: 0.0833 - acc: 0.9713 - val_loss: 0.4541 - val_acc: 0.8568\n",
      "Epoch 100/100\n",
      "4915/4915 [==============================] - 2s 374us/step - loss: 0.0724 - acc: 0.9742 - val_loss: 0.5273 - val_acc: 0.8470\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam', metrics = ['accuracy'], loss = 'categorical_crossentropy')\n",
    "\n",
    "#es = EarlyStopping(monitor='val_loss', patience=20, mode='min', verbose=1)\n",
    "cp = ModelCheckpoint('./models/{epoch:02d}-{val_acc:.4f}.h5', monitor='val_loss',\n",
    "                     save_best_only=True, mode='min')\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    validation_data=(x_val, y_val), \n",
    "                    batch_size=64, epochs=100, verbose=1, callbacks = [cp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T07:14:19.195916Z",
     "start_time": "2020-08-21T07:14:16.455097Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "best_model = load_model('models/noskipCNN_drop_global_submit.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T07:14:19.211895Z",
     "start_time": "2020-08-21T07:14:19.199915Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20480, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "x_test = test[:,1:]\n",
    "x_test = np.reshape(x_test, (-1, 28, 28, 1))\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T07:14:23.541849Z",
     "start_time": "2020-08-21T07:14:19.215839Z"
    }
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('data/submission.csv')\n",
    "submission['digit'] = np.argmax(best_model.predict(x_test), axis=1)\n",
    "submission.to_csv('data/submission_noskip(0821).csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T03:17:06.772758Z",
     "start_time": "2020-08-19T03:17:03.725468Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Activation\n",
    "from tensorflow.keras.layers import concatenate, Dropout, AveragePooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# seed\n",
    "import os\n",
    "seed = 123\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T03:17:08.243437Z",
     "start_time": "2020-08-19T03:17:06.775753Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T03:17:08.259130Z",
     "start_time": "2020-08-19T03:17:08.243437Z"
    }
   },
   "outputs": [],
   "source": [
    "image_generator = ImageDataGenerator(width_shift_range=0.1,\n",
    "                                     height_shift_range=0.1, \n",
    "                                     zoom_range=[0.8,1.2],\n",
    "                                     #brightness_range=[0.75,1.25], \n",
    "                                     shear_range=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T03:17:09.289789Z",
     "start_time": "2020-08-19T03:17:08.260032Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4096, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "x1 = train.drop(['id', 'digit', 'letter'], axis=1).values\n",
    "x1 = x1.reshape(-1, 28, 28, 1)\n",
    "x1 = x1/255\n",
    "x1_remake = []\n",
    "for i in range(x1.shape[0]):\n",
    "    num_aug = 0\n",
    "    tmp = x1[i]\n",
    "    tmp = tmp.reshape((1,) + tmp.shape)\n",
    "    for x_aug in image_generator.flow(tmp, batch_size = 1) :\n",
    "        if num_aug >= 1:\n",
    "            break\n",
    "        x1_remake.append(x_aug[0])\n",
    "        num_aug += 1\n",
    "x1_remake = np.array(x1_remake)\n",
    "\n",
    "x1_total = np.concatenate((x1, x1_remake), axis=0)\n",
    "print(x1_total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T03:17:09.322950Z",
     "start_time": "2020-08-19T03:17:09.294208Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4096, 10)\n"
     ]
    }
   ],
   "source": [
    "y1_data = train['digit']\n",
    "y1 = np.zeros((len(y1_data), len(y1_data.unique())))\n",
    "for i, digit in enumerate(y1_data):\n",
    "    y1[i, digit] = 1\n",
    "\n",
    "y1_remake = y1.copy()\n",
    "y1_total = np.concatenate((y1, y1_remake), axis=0)\n",
    "print(y1_total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T03:17:09.353985Z",
     "start_time": "2020-08-19T03:17:09.327141Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4096, 26)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1_let = train['letter'].values\n",
    "x1_let = x1_let[:, np.newaxis]\n",
    "en = OneHotEncoder()\n",
    "x1_let = en.fit_transform(x1_let).toarray()\n",
    "\n",
    "x1_remake_let = x1_let.copy()\n",
    "\n",
    "x1_letter_total = np.concatenate((x1_let, x1_remake_let), axis=0)\n",
    "x1_letter_total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T03:17:09.448418Z",
     "start_time": "2020-08-19T03:17:09.358011Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3276, 28, 28, 1)\n",
      "(820, 28, 28, 1)\n",
      "(3276, 10)\n",
      "(820, 10)\n",
      "(3276, 26)\n",
      "(820, 26)\n"
     ]
    }
   ],
   "source": [
    "x1_train, x1_val, y1_train, y1_val = train_test_split(x1_total, y1_total, test_size=0.2, shuffle=True, stratify=y1_total)\n",
    "\n",
    "print(x1_train.shape)\n",
    "print(x1_val.shape)\n",
    "print(y1_train.shape)\n",
    "print(y1_val.shape)\n",
    "\n",
    "x1_letter_train = x1_letter_total[:x1_train.shape[0],:]\n",
    "x1_letter_val = x1_letter_total[x1_train.shape[0]:,:]\n",
    "print(x1_letter_train.shape)\n",
    "print(x1_letter_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T03:17:09.464350Z",
     "start_time": "2020-08-19T03:17:09.452406Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3276, 28, 28)\n",
      "(820, 28, 28)\n",
      "(3276, 10)\n",
      "(820, 10)\n",
      "(3276, 26)\n",
      "(820, 26)\n"
     ]
    }
   ],
   "source": [
    "x2_train = np.reshape(x1_train, (x1_train.shape[0], x1_train.shape[1], x1_train.shape[2]))\n",
    "x2_val = np.reshape(x1_val, (x1_val.shape[0], x1_val.shape[1], x1_val.shape[2]))\n",
    "y2_train = y1_train.copy()\n",
    "y2_val = y1_val.copy()\n",
    "x2_letter_train = x1_letter_train.copy()\n",
    "x2_letter_val = x1_letter_val.copy()\n",
    "\n",
    "print(x2_train.shape)\n",
    "print(x2_val.shape)\n",
    "print(y2_train.shape)\n",
    "print(y2_val.shape)\n",
    "print(x2_letter_train.shape)\n",
    "print(x2_letter_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T03:17:09.496213Z",
     "start_time": "2020-08-19T03:17:09.470326Z"
    }
   },
   "outputs": [],
   "source": [
    "def Conv_block(x, growth_rate, activation='relu'):\n",
    "    x_l = BatchNormalization()(x)\n",
    "    x_l = Activation(activation)(x_l)\n",
    "    x_l = Conv2D(growth_rate*4, (1,1), padding='same', kernel_initializer='he_normal')(x_l)\n",
    "    \n",
    "    x_l = BatchNormalization()(x_l)\n",
    "    x_l = Activation(activation)(x_l)\n",
    "    x_l = Conv2D(growth_rate, (3,3), padding='same', kernel_initializer='he_normal')(x_l)\n",
    "    \n",
    "    x = concatenate([x, x_l])\n",
    "    return x\n",
    "\n",
    "def Dense_block(x, layers, growth_rate=32):\n",
    "    for i in range(layers):\n",
    "        x = Conv_block(x, growth_rate)\n",
    "    return x\n",
    "\n",
    "def Transition_layer(x, compression_factor=0.5, activation='relu'):\n",
    "    reduced_filters = int(tf.keras.backend.int_shape(x)[-1] * compression_factor)\n",
    "    \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activation)(x)\n",
    "    x = Conv2D(reduced_filters, (1,1), padding='same', kernel_initializer='he_normal')(x)\n",
    "    \n",
    "    x = AveragePooling2D((2,2), padding='same', strides=2)(x)\n",
    "    return x\n",
    "\n",
    "def DenseNet(model_input, classes, densenet_type='DenseNet-121'):\n",
    "    x = Conv2D(base_growth_rate*2, (7,7), padding='same', strides=2,\n",
    "               kernel_initializer='he_normal')(model_input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = MaxPooling2D((3,3), padding='same', strides=2)(x)\n",
    "    \n",
    "    x = Dense_block(x, layers_in_block[densenet_type][0], base_growth_rate)\n",
    "    x = Transition_layer(x, compression_factor=0.5)\n",
    "    x = Dense_block(x, layers_in_block[densenet_type][1], base_growth_rate)\n",
    "    #x = Transition_layer(x, compression_factor=0.5)\n",
    "    #x = Dense_block(x, layers_in_block[densenet_type][2], base_growth_rate)\n",
    "    #x = Transition_layer(x, compression_factor=0.5)\n",
    "    #x = Dense_block(x, layers_in_block[densenet_type][3], base_growth_rate)\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    model_output = Dense(classes, activation='softmax', kernel_initializer='he_normal')(x)\n",
    "    \n",
    "    model = Model(model_input, model_output, name=densenet_type)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T03:17:09.512145Z",
     "start_time": "2020-08-19T03:17:09.498204Z"
    }
   },
   "outputs": [],
   "source": [
    "def DenseNet_letter(model_input, letter, classes, densenet_type='DenseNet-121'):\n",
    "    x = Conv2D(base_growth_rate*2, (7,7), padding='same', strides=2,\n",
    "               kernel_initializer='he_normal')(model_input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = MaxPooling2D((3,3), padding='same', strides=2)(x)\n",
    "    \n",
    "    x = Dense_block(x, layers_in_block[densenet_type][0], base_growth_rate)\n",
    "    x = Transition_layer(x, compression_factor=0.5)\n",
    "    x = Dense_block(x, layers_in_block[densenet_type][1], base_growth_rate)\n",
    "    #x = Transition_layer(x, compression_factor=0.5)\n",
    "    #x = Dense_block(x, layers_in_block[densenet_type][2], base_growth_rate)\n",
    "    #x = Transition_layer(x, compression_factor=0.5)\n",
    "    #x = Dense_block(x, layers_in_block[densenet_type][3], base_growth_rate)\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    merge = concatenate([x, letter])\n",
    "    x1 = Dense(500, activation='relu')(merge)\n",
    "    x1 = Dropout(0.3)(x1)\n",
    "    \n",
    "    model_output = Dense(classes, activation='softmax', kernel_initializer='he_normal')(x1)\n",
    "    \n",
    "    model = Model(inputs = [model_input, letter], outputs = model_output, name=densenet_type)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T03:17:12.759141Z",
     "start_time": "2020-08-19T03:17:09.514138Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 14, 14, 64)   3200        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 14, 14, 64)   256         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 14, 14, 64)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 7, 7, 64)     0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 7, 7, 64)     256         max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 7, 7, 64)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 7, 7, 128)    8320        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 7, 7, 128)    512         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 7, 7, 128)    0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 7, 7, 32)     36896       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 7, 7, 96)     0           max_pooling2d[0][0]              \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 7, 7, 96)     384         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 7, 7, 96)     0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 7, 7, 128)    12416       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 7, 7, 128)    512         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 7, 7, 128)    0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 7, 7, 32)     36896       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7, 7, 128)    0           concatenate[0][0]                \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 7, 7, 128)    512         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 7, 7, 128)    0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 7, 7, 128)    16512       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 7, 7, 128)    512         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 7, 7, 128)    0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 7, 7, 32)     36896       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 7, 7, 160)    0           concatenate_1[0][0]              \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 7, 7, 160)    640         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 7, 7, 160)    0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 7, 7, 128)    20608       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 7, 7, 128)    512         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 7, 7, 128)    0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 7, 7, 32)     36896       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 7, 7, 192)    0           concatenate_2[0][0]              \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 7, 7, 192)    768         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 7, 7, 192)    0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 7, 7, 128)    24704       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 7, 7, 128)    512         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 7, 7, 128)    0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 7, 7, 32)     36896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 7, 7, 224)    0           concatenate_3[0][0]              \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 7, 7, 224)    896         concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 7, 7, 224)    0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 7, 7, 128)    28800       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 7, 7, 128)    512         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 7, 7, 128)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 7, 7, 32)     36896       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 7, 7, 256)    0           concatenate_4[0][0]              \n",
      "                                                                 conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 7, 7, 256)    1024        concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 7, 7, 256)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 7, 7, 128)    32896       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 4, 4, 128)    0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 4, 4, 128)    512         average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 4, 4, 128)    0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 4, 4, 128)    16512       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 4, 4, 128)    512         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 4, 4, 128)    0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 4, 4, 32)     36896       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 4, 4, 160)    0           average_pooling2d[0][0]          \n",
      "                                                                 conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 4, 4, 160)    640         concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 4, 4, 160)    0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 4, 4, 128)    20608       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 4, 4, 128)    512         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 4, 4, 128)    0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 4, 4, 32)     36896       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 4, 4, 192)    0           concatenate_6[0][0]              \n",
      "                                                                 conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 4, 4, 192)    768         concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 4, 4, 192)    0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 4, 4, 128)    24704       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 4, 4, 128)    512         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 4, 4, 128)    0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 4, 4, 32)     36896       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 4, 4, 224)    0           concatenate_7[0][0]              \n",
      "                                                                 conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 4, 4, 224)    896         concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 4, 4, 224)    0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 4, 4, 128)    28800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 4, 4, 128)    512         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 4, 4, 128)    0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 4, 4, 32)     36896       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 4, 4, 256)    0           concatenate_8[0][0]              \n",
      "                                                                 conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 4, 4, 256)    1024        concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 4, 4, 256)    0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 4, 4, 128)    32896       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 4, 4, 128)    512         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 4, 4, 128)    0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 4, 4, 32)     36896       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 4, 4, 288)    0           concatenate_9[0][0]              \n",
      "                                                                 conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 4, 4, 288)    1152        concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 4, 4, 288)    0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 4, 4, 128)    36992       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 4, 4, 128)    512         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 4, 4, 128)    0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 4, 4, 32)     36896       activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 4, 4, 320)    0           concatenate_10[0][0]             \n",
      "                                                                 conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 4, 4, 320)    1280        concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 4, 4, 320)    0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 4, 4, 128)    41088       activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 4, 4, 128)    512         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 4, 4, 128)    0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 4, 4, 32)     36896       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 4, 4, 352)    0           concatenate_11[0][0]             \n",
      "                                                                 conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 4, 4, 352)    1408        concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 4, 4, 352)    0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 4, 4, 128)    45184       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 4, 4, 128)    512         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 4, 4, 128)    0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 4, 4, 32)     36896       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 4, 4, 384)    0           concatenate_12[0][0]             \n",
      "                                                                 conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 4, 4, 384)    1536        concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 4, 4, 384)    0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 4, 4, 128)    49280       activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 4, 4, 128)    512         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 4, 4, 128)    0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 4, 4, 32)     36896       activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 4, 4, 416)    0           concatenate_13[0][0]             \n",
      "                                                                 conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 4, 4, 416)    1664        concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 4, 4, 416)    0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 4, 4, 128)    53376       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 4, 4, 128)    512         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 4, 4, 128)    0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 4, 4, 32)     36896       activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 4, 4, 448)    0           concatenate_14[0][0]             \n",
      "                                                                 conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 4, 4, 448)    1792        concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 4, 4, 448)    0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 4, 4, 128)    57472       activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 4, 4, 128)    512         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 4, 4, 128)    0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 4, 4, 32)     36896       activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 4, 4, 480)    0           concatenate_15[0][0]             \n",
      "                                                                 conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 4, 4, 480)    1920        concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 4, 4, 480)    0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 4, 4, 128)    61568       activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 4, 4, 128)    512         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 4, 4, 128)    0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 4, 4, 32)     36896       activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 4, 4, 512)    0           concatenate_16[0][0]             \n",
      "                                                                 conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 512)          0           concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           5130        global_average_pooling2d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 1,313,738\n",
      "Trainable params: 1,299,466\n",
      "Non-trainable params: 14,272\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "layers_in_block = {'DenseNet-121':[6, 12, 24, 16],\n",
    "                   'DenseNet-169':[6, 12, 32, 32],\n",
    "                   'DenseNet-201':[6, 12, 48, 32],\n",
    "                   'DenseNet-265':[6, 12, 64, 48]}\n",
    "\n",
    "base_growth_rate = 32\n",
    "\n",
    "model_input = Input(shape=(28,28,1))\n",
    "letter = Input(shape=(26,))\n",
    "classes = 10\n",
    "\n",
    "model = DenseNet(model_input, classes, 'DenseNet-121')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T03:23:03.977518Z",
     "start_time": "2020-08-19T03:17:12.759141Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3276 samples, validate on 820 samples\n",
      "Epoch 1/50\n",
      "3276/3276 [==============================] - 19s 6ms/step - loss: 2.1023 - acc: 0.2555 - val_loss: 2.2590 - val_acc: 0.1476\n",
      "Epoch 2/50\n",
      "3276/3276 [==============================] - 7s 2ms/step - loss: 1.4761 - acc: 0.4753 - val_loss: 2.5781 - val_acc: 0.1000\n",
      "Epoch 3/50\n",
      "3276/3276 [==============================] - 6s 2ms/step - loss: 1.0922 - acc: 0.6139 - val_loss: 2.9547 - val_acc: 0.1220\n",
      "Epoch 4/50\n",
      "3276/3276 [==============================] - 7s 2ms/step - loss: 0.8524 - acc: 0.7149 - val_loss: 4.0200 - val_acc: 0.1854\n",
      "Epoch 5/50\n",
      "3276/3276 [==============================] - 7s 2ms/step - loss: 0.6569 - acc: 0.7814 - val_loss: 2.8714 - val_acc: 0.2354\n",
      "Epoch 6/50\n",
      "3276/3276 [==============================] - 7s 2ms/step - loss: 0.4901 - acc: 0.8230 - val_loss: 2.5072 - val_acc: 0.3537\n",
      "Epoch 7/50\n",
      "3276/3276 [==============================] - 7s 2ms/step - loss: 0.3912 - acc: 0.8639 - val_loss: 2.1885 - val_acc: 0.4659\n",
      "Epoch 8/50\n",
      "3276/3276 [==============================] - 7s 2ms/step - loss: 0.2937 - acc: 0.9032 - val_loss: 2.5440 - val_acc: 0.4732\n",
      "Epoch 9/50\n",
      "3276/3276 [==============================] - 7s 2ms/step - loss: 0.3175 - acc: 0.8904 - val_loss: 2.9917 - val_acc: 0.4463\n",
      "Epoch 10/50\n",
      "3276/3276 [==============================] - 7s 2ms/step - loss: 0.2428 - acc: 0.9158 - val_loss: 2.9047 - val_acc: 0.5012\n",
      "Epoch 11/50\n",
      "3276/3276 [==============================] - 7s 2ms/step - loss: 0.1498 - acc: 0.9509 - val_loss: 2.4718 - val_acc: 0.5512\n",
      "Epoch 12/50\n",
      "3276/3276 [==============================] - 7s 2ms/step - loss: 0.1255 - acc: 0.9563 - val_loss: 2.1142 - val_acc: 0.5805\n",
      "Epoch 13/50\n",
      "3276/3276 [==============================] - 7s 2ms/step - loss: 0.1377 - acc: 0.9527 - val_loss: 1.9255 - val_acc: 0.5939\n",
      "Epoch 14/50\n",
      "3276/3276 [==============================] - 7s 2ms/step - loss: 0.0858 - acc: 0.9719 - val_loss: 2.3672 - val_acc: 0.5439\n",
      "Epoch 15/50\n",
      "3276/3276 [==============================] - 7s 2ms/step - loss: 0.0950 - acc: 0.9670 - val_loss: 2.5795 - val_acc: 0.5439\n",
      "Epoch 16/50\n",
      "3276/3276 [==============================] - 7s 2ms/step - loss: 0.3195 - acc: 0.8977 - val_loss: 2.2200 - val_acc: 0.5720\n",
      "Epoch 17/50\n",
      "3276/3276 [==============================] - 7s 2ms/step - loss: 0.1280 - acc: 0.9594 - val_loss: 2.4972 - val_acc: 0.5720\n",
      "Epoch 18/50\n",
      "3276/3276 [==============================] - 7s 2ms/step - loss: 0.0714 - acc: 0.9759 - val_loss: 2.6991 - val_acc: 0.5671\n",
      "Epoch 19/50\n",
      "3276/3276 [==============================] - 7s 2ms/step - loss: 0.0651 - acc: 0.9765 - val_loss: 2.6523 - val_acc: 0.5756\n",
      "Epoch 20/50\n",
      "3276/3276 [==============================] - 7s 2ms/step - loss: 0.1004 - acc: 0.9695 - val_loss: 2.5840 - val_acc: 0.5976\n",
      "Epoch 21/50\n",
      "3276/3276 [==============================] - 7s 2ms/step - loss: 0.0954 - acc: 0.9689 - val_loss: 1.8524 - val_acc: 0.6378\n",
      "Epoch 22/50\n",
      "3276/3276 [==============================] - 6s 2ms/step - loss: 0.0640 - acc: 0.9792 - val_loss: 2.2938 - val_acc: 0.6098\n",
      "Epoch 23/50\n",
      "3276/3276 [==============================] - 6s 2ms/step - loss: 0.1207 - acc: 0.9591 - val_loss: 5.1533 - val_acc: 0.3768\n",
      "Epoch 24/50\n",
      "3276/3276 [==============================] - 6s 2ms/step - loss: 0.0655 - acc: 0.9795 - val_loss: 1.9860 - val_acc: 0.6354\n",
      "Epoch 25/50\n",
      "3276/3276 [==============================] - 6s 2ms/step - loss: 0.0223 - acc: 0.9942 - val_loss: 1.7118 - val_acc: 0.6659\n",
      "Epoch 26/50\n",
      "3276/3276 [==============================] - 6s 2ms/step - loss: 0.0207 - acc: 0.9927 - val_loss: 2.1901 - val_acc: 0.6146\n",
      "Epoch 27/50\n",
      "3276/3276 [==============================] - 7s 2ms/step - loss: 0.1398 - acc: 0.9563 - val_loss: 2.9458 - val_acc: 0.5488\n",
      "Epoch 28/50\n",
      "3276/3276 [==============================] - 6s 2ms/step - loss: 0.1353 - acc: 0.9585 - val_loss: 2.1508 - val_acc: 0.6061\n",
      "Epoch 29/50\n",
      "3276/3276 [==============================] - 7s 2ms/step - loss: 0.1287 - acc: 0.9582 - val_loss: 2.4144 - val_acc: 0.5915\n",
      "Epoch 30/50\n",
      "3276/3276 [==============================] - 7s 2ms/step - loss: 0.0936 - acc: 0.9701 - val_loss: 2.4703 - val_acc: 0.5683\n",
      "Epoch 31/50\n",
      "3276/3276 [==============================] - 7s 2ms/step - loss: 0.0981 - acc: 0.9667 - val_loss: 2.3777 - val_acc: 0.5841\n",
      "Epoch 32/50\n",
      "3276/3276 [==============================] - 6s 2ms/step - loss: 0.0435 - acc: 0.9860 - val_loss: 2.6368 - val_acc: 0.5939\n",
      "Epoch 33/50\n",
      "3276/3276 [==============================] - 6s 2ms/step - loss: 0.0600 - acc: 0.9771 - val_loss: 2.2546 - val_acc: 0.5976\n",
      "Epoch 34/50\n",
      "3276/3276 [==============================] - 6s 2ms/step - loss: 0.0194 - acc: 0.9927 - val_loss: 2.5825 - val_acc: 0.6061\n",
      "Epoch 35/50\n",
      "3276/3276 [==============================] - 6s 2ms/step - loss: 0.0307 - acc: 0.9902 - val_loss: 1.7827 - val_acc: 0.6695\n",
      "Epoch 36/50\n",
      "3276/3276 [==============================] - 7s 2ms/step - loss: 0.0199 - acc: 0.9933 - val_loss: 1.9409 - val_acc: 0.6293\n",
      "Epoch 37/50\n",
      "3276/3276 [==============================] - 7s 2ms/step - loss: 0.0335 - acc: 0.9908 - val_loss: 2.7080 - val_acc: 0.5939\n",
      "Epoch 38/50\n",
      "3276/3276 [==============================] - 7s 2ms/step - loss: 0.0719 - acc: 0.9750 - val_loss: 3.2893 - val_acc: 0.5293\n",
      "Epoch 39/50\n",
      "3276/3276 [==============================] - 6s 2ms/step - loss: 0.1344 - acc: 0.9585 - val_loss: 2.9925 - val_acc: 0.5732\n",
      "Epoch 40/50\n",
      "3276/3276 [==============================] - 7s 2ms/step - loss: 0.1074 - acc: 0.9649 - val_loss: 3.2341 - val_acc: 0.5280\n",
      "Epoch 41/50\n",
      "3276/3276 [==============================] - 6s 2ms/step - loss: 0.0885 - acc: 0.9713 - val_loss: 2.1958 - val_acc: 0.6049\n",
      "Epoch 42/50\n",
      "3276/3276 [==============================] - 7s 2ms/step - loss: 0.0576 - acc: 0.9799 - val_loss: 2.4867 - val_acc: 0.6110\n",
      "Epoch 43/50\n",
      "3276/3276 [==============================] - 6s 2ms/step - loss: 0.1636 - acc: 0.9567 - val_loss: 2.7971 - val_acc: 0.5817\n",
      "Epoch 44/50\n",
      "3276/3276 [==============================] - 7s 2ms/step - loss: 0.1170 - acc: 0.9661 - val_loss: 2.1094 - val_acc: 0.6390\n",
      "Epoch 45/50\n",
      "3276/3276 [==============================] - 7s 2ms/step - loss: 0.0792 - acc: 0.9756 - val_loss: 2.4226 - val_acc: 0.5634\n",
      "Epoch 46/50\n",
      "3276/3276 [==============================] - 7s 2ms/step - loss: 0.0649 - acc: 0.9789 - val_loss: 2.7235 - val_acc: 0.5695\n",
      "Epoch 47/50\n",
      "3276/3276 [==============================] - 6s 2ms/step - loss: 0.0429 - acc: 0.9853 - val_loss: 3.5915 - val_acc: 0.5329\n",
      "Epoch 48/50\n",
      "3276/3276 [==============================] - 7s 2ms/step - loss: 0.1460 - acc: 0.9563 - val_loss: 1.9035 - val_acc: 0.6293\n",
      "Epoch 49/50\n",
      "3276/3276 [==============================] - 7s 2ms/step - loss: 0.1110 - acc: 0.9670 - val_loss: 1.9812 - val_acc: 0.6280\n",
      "Epoch 50/50\n",
      "3276/3276 [==============================] - 6s 2ms/step - loss: 0.1033 - acc: 0.9679 - val_loss: 1.7008 - val_acc: 0.6671\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x1_train, y1_train, validation_data=(x1_val, y1_val),\n",
    "                    batch_size=64, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T03:23:03.992910Z",
     "start_time": "2020-08-19T03:23:03.981956Z"
    }
   },
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor = 'val_loss', mode='min', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T03:24:15.400042Z",
     "start_time": "2020-08-19T03:23:53.387321Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 1 ... 6 1 0]\n"
     ]
    }
   ],
   "source": [
    "x1_test = test.drop(['id', 'letter'], axis=1).values\n",
    "x1_test = x1_test.reshape(-1, 28, 28, 1)\n",
    "x1_test = x1_test/255\n",
    "\n",
    "#x2_test = test.drop(['id', 'letter'], axis=1).values\n",
    "#x2_test = x2_test.reshape(-1, 28, 28)\n",
    "#x2_test = x2_test/255\n",
    "\n",
    "x1_letter_test = test['letter'].values\n",
    "x1_letter_test = x1_letter_test[:, np.newaxis]\n",
    "en = OneHotEncoder()\n",
    "x1_letter_test = en.fit_transform(x1_letter_test).toarray()\n",
    "\n",
    "#x2_letter_test = x1_letter_test.copy()\n",
    "\n",
    "y1_test = model.predict(x1_test)\n",
    "y_1 = np.argmax(y1_test, axis=1)\n",
    "print(y_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T03:23:04.328439Z",
     "start_time": "2020-08-19T03:17:03.741Z"
    }
   },
   "outputs": [],
   "source": [
    "#submission = pd.read_csv('data/submission.csv')\n",
    "#submission['digit'] = y_1\n",
    "#submission.to_csv('submission(val7646).csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

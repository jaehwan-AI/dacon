{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T07:53:12.268147Z",
     "start_time": "2020-08-18T07:53:06.851613Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, LSTM, concatenate, Dropout\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# seed\n",
    "import os\n",
    "seed = 123\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T07:53:13.311642Z",
     "start_time": "2020-08-18T07:53:12.270000Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T07:53:13.316896Z",
     "start_time": "2020-08-18T07:53:13.313640Z"
    }
   },
   "outputs": [],
   "source": [
    "image_generator = ImageDataGenerator(width_shift_range=0.1,\n",
    "                                     height_shift_range=0.1, \n",
    "                                     zoom_range=[0.8,1.2],\n",
    "                                     #brightness_range=[0.75,1.25], \n",
    "                                     shear_range=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T07:53:14.161681Z",
     "start_time": "2020-08-18T07:53:13.319643Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4096, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "x1 = train.drop(['id', 'digit', 'letter'], axis=1).values\n",
    "x1 = x1.reshape(-1, 28, 28, 1)\n",
    "x1 = x1/255\n",
    "x1_remake = []\n",
    "for i in range(x1.shape[0]):\n",
    "    num_aug = 0\n",
    "    tmp = x1[i]\n",
    "    tmp = tmp.reshape((1,) + tmp.shape)\n",
    "    for x_aug in image_generator.flow(tmp, batch_size = 1) :\n",
    "        if num_aug >= 1:\n",
    "            break\n",
    "        x1_remake.append(x_aug[0])\n",
    "        num_aug += 1\n",
    "x1_remake = np.array(x1_remake)\n",
    "\n",
    "x1_total = np.concatenate((x1, x1_remake), axis=0)\n",
    "print(x1_total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T07:53:14.172778Z",
     "start_time": "2020-08-18T07:53:14.163678Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4096, 10)\n"
     ]
    }
   ],
   "source": [
    "y1_data = train['digit']\n",
    "y1 = np.zeros((len(y1_data), len(y1_data.unique())))\n",
    "for i, digit in enumerate(y1_data):\n",
    "    y1[i, digit] = 1\n",
    "\n",
    "y1_remake = y1.copy()\n",
    "y1_total = np.concatenate((y1, y1_remake), axis=0)\n",
    "print(y1_total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T07:53:14.198210Z",
     "start_time": "2020-08-18T07:53:14.176239Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4096, 26)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1_let = train['letter'].values\n",
    "x1_let = x1_let[:, np.newaxis]\n",
    "en = OneHotEncoder()\n",
    "x1_let = en.fit_transform(x1_let).toarray()\n",
    "\n",
    "x1_remake_let = x1_let.copy()\n",
    "\n",
    "x1_letter_total = np.concatenate((x1_let, x1_remake_let), axis=0)\n",
    "x1_letter_total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T07:53:14.269201Z",
     "start_time": "2020-08-18T07:53:14.201191Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3276, 28, 28, 1)\n",
      "(820, 28, 28, 1)\n",
      "(3276, 10)\n",
      "(820, 10)\n",
      "(3276, 26)\n",
      "(820, 26)\n"
     ]
    }
   ],
   "source": [
    "x1_train, x1_val, y1_train, y1_val = train_test_split(x1_total, y1_total, test_size=0.2, shuffle=True, stratify=y1_total)\n",
    "\n",
    "print(x1_train.shape)\n",
    "print(x1_val.shape)\n",
    "print(y1_train.shape)\n",
    "print(y1_val.shape)\n",
    "\n",
    "x1_letter_train = x1_letter_total[:x1_train.shape[0],:]\n",
    "x1_letter_val = x1_letter_total[x1_train.shape[0]:,:]\n",
    "print(x1_letter_train.shape)\n",
    "print(x1_letter_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T07:53:14.282263Z",
     "start_time": "2020-08-18T07:53:14.271189Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3276, 28, 28)\n",
      "(820, 28, 28)\n",
      "(3276, 10)\n",
      "(820, 10)\n",
      "(3276, 26)\n",
      "(820, 26)\n"
     ]
    }
   ],
   "source": [
    "x2_train = np.reshape(x1_train, (x1_train.shape[0], x1_train.shape[1], x1_train.shape[2]))\n",
    "x2_val = np.reshape(x1_val, (x1_val.shape[0], x1_val.shape[1], x1_val.shape[2]))\n",
    "y2_train = y1_train.copy()\n",
    "y2_val = y1_val.copy()\n",
    "x2_letter_train = x1_letter_train.copy()\n",
    "x2_letter_val = x1_letter_val.copy()\n",
    "\n",
    "print(x2_train.shape)\n",
    "print(x2_val.shape)\n",
    "print(y2_train.shape)\n",
    "print(y2_val.shape)\n",
    "print(x2_letter_train.shape)\n",
    "print(x2_letter_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T07:53:14.911187Z",
     "start_time": "2020-08-18T07:53:14.283198Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 28, 28, 64)   320         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 28, 28, 64)   0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 14, 14, 64)   0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 14, 14, 64)   16448       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 14, 14, 64)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 28, 28)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 7, 7, 64)     0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 28, 512)      1107968     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 7, 7, 128)    32896       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 28, 512)      0           lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 7, 7, 128)    0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 28, 256)      787456      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 3, 3, 128)    0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 28, 256)      0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1152)         0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 26)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 128)          197120      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1178)         0           flatten[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 128)          0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 500)          589500      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 100)          12900       dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 26)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 500)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 126)          0           dense_2[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          50100       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 100)          12700       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 200)          0           dense_1[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 100)          20100       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 100)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 50)           5050        dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 50)           0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 50)           2550        dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 10)           510         dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 10)           510         dense_7[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,836,128\n",
      "Trainable params: 2,836,128\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input1 = Input(shape=(28,28,1))\n",
    "x1 = Conv2D(64, (2,2), activation='relu', padding='same')(input1)\n",
    "x1 = Dropout(0.2)(x1)\n",
    "x1 = MaxPooling2D((2,2))(x1)\n",
    "x1 = Conv2D(64, (2,2), activation='relu', padding='same')(x1)\n",
    "x1 = Dropout(0.2)(x1)\n",
    "x1 = MaxPooling2D((2,2))(x1)\n",
    "x1 = Conv2D(128, (2,2), activation='relu', padding='same')(x1)\n",
    "x1 = Dropout(0.2)(x1)\n",
    "x1 = MaxPooling2D((2,2))(x1)\n",
    "x1 = Flatten()(x1)\n",
    "\n",
    "input2 = Input(shape=(26,))\n",
    "merge1 = concatenate([x1, input2])\n",
    "\n",
    "x2 = Dense(500, activation='relu')(merge1)\n",
    "x2 = Dropout(0.2)(x2)\n",
    "x2 = Dense(100, activation='relu')(x2)\n",
    "\n",
    "input3 = Input(shape=(28,28))\n",
    "x3 = LSTM(512, activation='relu', return_sequences=True)(input3)\n",
    "x3 = Dropout(0.2)(x3)\n",
    "x3 = LSTM(256, activation='relu', return_sequences=True)(x3)\n",
    "x3 = Dropout(0.2)(x3)\n",
    "x3 = LSTM(128, activation='relu')(x3)\n",
    "x3 = Dropout(0.2)(x3)\n",
    "x3 = Dense(100, activation='relu')(x3)\n",
    "\n",
    "input4 = Input(shape=(26,))\n",
    "merge2 = concatenate([x3, input4])\n",
    "\n",
    "x4 = Dense(100, activation='relu')(merge2)\n",
    "\n",
    "merge = concatenate([x2, x4])\n",
    "\n",
    "x5 = Dense(100, activation='relu')(merge)\n",
    "x5 = Dropout(0.2)(x5)\n",
    "x5 = Dense(50, activation='relu')(x5)\n",
    "\n",
    "x5 = Dropout(0.2)(x5)\n",
    "output1 = Dense(10, activation='softmax')(x5)\n",
    "\n",
    "x6 = Dense(50, activation='relu')(x5)\n",
    "output2 = Dense(10, activation='softmax')(x6)\n",
    "\n",
    "model = Model(inputs = [input1, input2, input3, input4], outputs = [output1, output2])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T08:20:11.229304Z",
     "start_time": "2020-08-18T07:53:14.913187Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3276 samples, validate on 820 samples\n",
      "Epoch 1/50\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 2.3042 - dense_6_loss: 2.3041 - dense_8_loss: 2.3051 - dense_6_accuracy: 0.1112 - dense_8_accuracy: 0.1029\n",
      "Epoch 00001: val_dense_6_accuracy improved from -inf to 0.11220, saving model to ./models/01-0.1122.h5\n",
      "3276/3276 [==============================] - 35s 11ms/sample - loss: 2.3041 - dense_6_loss: 2.3037 - dense_8_loss: 2.3045 - dense_6_accuracy: 0.1117 - dense_8_accuracy: 0.1035 - val_loss: 2.2987 - val_dense_6_loss: 2.2985 - val_dense_8_loss: 2.3002 - val_dense_6_accuracy: 0.1122 - val_dense_8_accuracy: 0.1171\n",
      "Epoch 2/50\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 2.2382 - dense_6_loss: 2.2340 - dense_8_loss: 2.2759 - dense_6_accuracy: 0.1562 - dense_8_accuracy: 0.1290\n",
      "Epoch 00002: val_dense_6_accuracy improved from 0.11220 to 0.21463, saving model to ./models/02-0.2146.h5\n",
      "3276/3276 [==============================] - 30s 9ms/sample - loss: 2.2374 - dense_6_loss: 2.2299 - dense_8_loss: 2.2747 - dense_6_accuracy: 0.1569 - dense_8_accuracy: 0.1291 - val_loss: 2.2262 - val_dense_6_loss: 2.2160 - val_dense_8_loss: 2.2941 - val_dense_6_accuracy: 0.2146 - val_dense_8_accuracy: 0.1427\n",
      "Epoch 3/50\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 2.0088 - dense_6_loss: 2.0011 - dense_8_loss: 2.0777 - dense_6_accuracy: 0.2748 - dense_8_accuracy: 0.2365\n",
      "Epoch 00003: val_dense_6_accuracy improved from 0.21463 to 0.29390, saving model to ./models/03-0.2939.h5\n",
      "3276/3276 [==============================] - 31s 10ms/sample - loss: 2.0081 - dense_6_loss: 1.9977 - dense_8_loss: 2.0736 - dense_6_accuracy: 0.2753 - dense_8_accuracy: 0.2372 - val_loss: 1.9892 - val_dense_6_loss: 1.9802 - val_dense_8_loss: 2.0596 - val_dense_6_accuracy: 0.2939 - val_dense_8_accuracy: 0.2366\n",
      "Epoch 4/50\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 1.7580 - dense_6_loss: 1.7503 - dense_8_loss: 1.8273 - dense_6_accuracy: 0.3854 - dense_8_accuracy: 0.3514\n",
      "Epoch 00004: val_dense_6_accuracy improved from 0.29390 to 0.43659, saving model to ./models/04-0.4366.h5\n",
      "3276/3276 [==============================] - 31s 9ms/sample - loss: 1.7590 - dense_6_loss: 1.7555 - dense_8_loss: 1.8331 - dense_6_accuracy: 0.3852 - dense_8_accuracy: 0.3513 - val_loss: 1.6632 - val_dense_6_loss: 1.6550 - val_dense_8_loss: 1.7273 - val_dense_6_accuracy: 0.4366 - val_dense_8_accuracy: 0.4146\n",
      "Epoch 5/50\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 1.5215 - dense_6_loss: 1.5158 - dense_8_loss: 1.5732 - dense_6_accuracy: 0.4733 - dense_8_accuracy: 0.4654\n",
      "Epoch 00005: val_dense_6_accuracy improved from 0.43659 to 0.56951, saving model to ./models/05-0.5695.h5\n",
      "3276/3276 [==============================] - 32s 10ms/sample - loss: 1.5200 - dense_6_loss: 1.5080 - dense_8_loss: 1.5641 - dense_6_accuracy: 0.4741 - dense_8_accuracy: 0.4658 - val_loss: 1.4348 - val_dense_6_loss: 1.4311 - val_dense_8_loss: 1.4665 - val_dense_6_accuracy: 0.5695 - val_dense_8_accuracy: 0.5598\n",
      "Epoch 6/50\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 1.3068 - dense_6_loss: 1.3025 - dense_8_loss: 1.3453 - dense_6_accuracy: 0.5640 - dense_8_accuracy: 0.5450\n",
      "Epoch 00006: val_dense_6_accuracy improved from 0.56951 to 0.59390, saving model to ./models/06-0.5939.h5\n",
      "3276/3276 [==============================] - 31s 10ms/sample - loss: 1.3069 - dense_6_loss: 1.3037 - dense_8_loss: 1.3432 - dense_6_accuracy: 0.5641 - dense_8_accuracy: 0.5452 - val_loss: 1.2756 - val_dense_6_loss: 1.2716 - val_dense_8_loss: 1.2987 - val_dense_6_accuracy: 0.5939 - val_dense_8_accuracy: 0.5829\n",
      "Epoch 7/50\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 1.1630 - dense_6_loss: 1.1599 - dense_8_loss: 1.1903 - dense_6_accuracy: 0.6167 - dense_8_accuracy: 0.5983\n",
      "Epoch 00007: val_dense_6_accuracy improved from 0.59390 to 0.63171, saving model to ./models/07-0.6317.h5\n",
      "3276/3276 [==============================] - 32s 10ms/sample - loss: 1.1649 - dense_6_loss: 1.1700 - dense_8_loss: 1.2019 - dense_6_accuracy: 0.6160 - dense_8_accuracy: 0.5977 - val_loss: 1.1506 - val_dense_6_loss: 1.1506 - val_dense_8_loss: 1.1490 - val_dense_6_accuracy: 0.6317 - val_dense_8_accuracy: 0.6268\n",
      "Epoch 8/50\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 1.0700 - dense_6_loss: 1.0664 - dense_8_loss: 1.1026 - dense_6_accuracy: 0.6520 - dense_8_accuracy: 0.6330\n",
      "Epoch 00008: val_dense_6_accuracy improved from 0.63171 to 0.66098, saving model to ./models/08-0.6610.h5\n",
      "3276/3276 [==============================] - 31s 10ms/sample - loss: 1.0718 - dense_6_loss: 1.0754 - dense_8_loss: 1.1160 - dense_6_accuracy: 0.6520 - dense_8_accuracy: 0.6328 - val_loss: 1.0968 - val_dense_6_loss: 1.0968 - val_dense_8_loss: 1.1007 - val_dense_6_accuracy: 0.6610 - val_dense_8_accuracy: 0.6549\n",
      "Epoch 9/50\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.9628 - dense_6_loss: 0.9595 - dense_8_loss: 0.9927 - dense_6_accuracy: 0.6872 - dense_8_accuracy: 0.6670\n",
      "Epoch 00009: val_dense_6_accuracy did not improve from 0.66098\n",
      "3276/3276 [==============================] - 32s 10ms/sample - loss: 0.9625 - dense_6_loss: 0.9576 - dense_8_loss: 0.9917 - dense_6_accuracy: 0.6874 - dense_8_accuracy: 0.6670 - val_loss: 1.0494 - val_dense_6_loss: 1.0495 - val_dense_8_loss: 1.0467 - val_dense_6_accuracy: 0.6585 - val_dense_8_accuracy: 0.6598\n",
      "Epoch 10/50\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.8889 - dense_6_loss: 0.8864 - dense_8_loss: 0.9109 - dense_6_accuracy: 0.7148 - dense_8_accuracy: 0.7135\n",
      "Epoch 00010: val_dense_6_accuracy improved from 0.66098 to 0.68780, saving model to ./models/10-0.6878.h5\n",
      "3276/3276 [==============================] - 32s 10ms/sample - loss: 0.8899 - dense_6_loss: 0.8920 - dense_8_loss: 0.9160 - dense_6_accuracy: 0.7143 - dense_8_accuracy: 0.7131 - val_loss: 0.9965 - val_dense_6_loss: 0.9972 - val_dense_8_loss: 0.9967 - val_dense_6_accuracy: 0.6878 - val_dense_8_accuracy: 0.6866\n",
      "Epoch 11/50\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.8033 - dense_6_loss: 0.8010 - dense_8_loss: 0.8242 - dense_6_accuracy: 0.7362 - dense_8_accuracy: 0.7249\n",
      "Epoch 00011: val_dense_6_accuracy did not improve from 0.68780\n",
      "3276/3276 [==============================] - 32s 10ms/sample - loss: 0.8043 - dense_6_loss: 0.8059 - dense_8_loss: 0.8292 - dense_6_accuracy: 0.7350 - dense_8_accuracy: 0.7237 - val_loss: 1.0186 - val_dense_6_loss: 1.0178 - val_dense_8_loss: 1.0296 - val_dense_6_accuracy: 0.6756 - val_dense_8_accuracy: 0.6634\n",
      "Epoch 12/50\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.7501 - dense_6_loss: 0.7477 - dense_8_loss: 0.7716 - dense_6_accuracy: 0.7613 - dense_8_accuracy: 0.7531\n",
      "Epoch 00012: val_dense_6_accuracy improved from 0.68780 to 0.70122, saving model to ./models/12-0.7012.h5\n",
      "3276/3276 [==============================] - 31s 9ms/sample - loss: 0.7494 - dense_6_loss: 0.7434 - dense_8_loss: 0.7706 - dense_6_accuracy: 0.7616 - dense_8_accuracy: 0.7534 - val_loss: 0.9000 - val_dense_6_loss: 0.8993 - val_dense_8_loss: 0.9024 - val_dense_6_accuracy: 0.7012 - val_dense_8_accuracy: 0.7098\n",
      "Epoch 13/50\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.7308 - dense_6_loss: 0.7281 - dense_8_loss: 0.7550 - dense_6_accuracy: 0.7702 - dense_8_accuracy: 0.7564\n",
      "Epoch 00013: val_dense_6_accuracy did not improve from 0.70122\n",
      "3276/3276 [==============================] - 31s 9ms/sample - loss: 0.7300 - dense_6_loss: 0.7241 - dense_8_loss: 0.7499 - dense_6_accuracy: 0.7705 - dense_8_accuracy: 0.7570 - val_loss: 0.8908 - val_dense_6_loss: 0.8889 - val_dense_8_loss: 0.8949 - val_dense_6_accuracy: 0.6963 - val_dense_8_accuracy: 0.7037\n",
      "Epoch 14/50\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.6556 - dense_6_loss: 0.6537 - dense_8_loss: 0.6722 - dense_6_accuracy: 0.7865 - dense_8_accuracy: 0.7819\n",
      "Epoch 00014: val_dense_6_accuracy improved from 0.70122 to 0.71585, saving model to ./models/14-0.7159.h5\n",
      "3276/3276 [==============================] - 31s 9ms/sample - loss: 0.6562 - dense_6_loss: 0.6568 - dense_8_loss: 0.6767 - dense_6_accuracy: 0.7863 - dense_8_accuracy: 0.7817 - val_loss: 0.8718 - val_dense_6_loss: 0.8710 - val_dense_8_loss: 0.8722 - val_dense_6_accuracy: 0.7159 - val_dense_8_accuracy: 0.7134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.5982 - dense_6_loss: 0.5963 - dense_8_loss: 0.6156 - dense_6_accuracy: 0.8088 - dense_8_accuracy: 0.8033\n",
      "Epoch 00015: val_dense_6_accuracy did not improve from 0.71585\n",
      "3276/3276 [==============================] - 31s 9ms/sample - loss: 0.5980 - dense_6_loss: 0.5952 - dense_8_loss: 0.6151 - dense_6_accuracy: 0.8089 - dense_8_accuracy: 0.8034 - val_loss: 0.9124 - val_dense_6_loss: 0.9114 - val_dense_8_loss: 0.9316 - val_dense_6_accuracy: 0.7000 - val_dense_8_accuracy: 0.6939\n",
      "Epoch 16/50\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.5347 - dense_6_loss: 0.5333 - dense_8_loss: 0.5465 - dense_6_accuracy: 0.8229 - dense_8_accuracy: 0.8183\n",
      "Epoch 00016: val_dense_6_accuracy improved from 0.71585 to 0.71829, saving model to ./models/16-0.7183.h5\n",
      "3276/3276 [==============================] - 31s 9ms/sample - loss: 0.5339 - dense_6_loss: 0.5297 - dense_8_loss: 0.5418 - dense_6_accuracy: 0.8230 - dense_8_accuracy: 0.8184 - val_loss: 0.8556 - val_dense_6_loss: 0.8547 - val_dense_8_loss: 0.8619 - val_dense_6_accuracy: 0.7183 - val_dense_8_accuracy: 0.7146\n",
      "Epoch 17/50\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.5638 - dense_6_loss: 0.5614 - dense_8_loss: 0.5847 - dense_6_accuracy: 0.8425 - dense_8_accuracy: 0.8352\n",
      "Epoch 00017: val_dense_6_accuracy did not improve from 0.71829\n",
      "3276/3276 [==============================] - 31s 9ms/sample - loss: 0.5631 - dense_6_loss: 0.5580 - dense_8_loss: 0.5803 - dense_6_accuracy: 0.8428 - dense_8_accuracy: 0.8358 - val_loss: 0.8476 - val_dense_6_loss: 0.8457 - val_dense_8_loss: 0.8626 - val_dense_6_accuracy: 0.7159 - val_dense_8_accuracy: 0.7220\n",
      "Epoch 18/50\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.4800 - dense_6_loss: 0.4780 - dense_8_loss: 0.4977 - dense_6_accuracy: 0.8453 - dense_8_accuracy: 0.8392\n",
      "Epoch 00018: val_dense_6_accuracy improved from 0.71829 to 0.72927, saving model to ./models/18-0.7293.h5\n",
      "3276/3276 [==============================] - 31s 9ms/sample - loss: 0.4791 - dense_6_loss: 0.4734 - dense_8_loss: 0.4927 - dense_6_accuracy: 0.8455 - dense_8_accuracy: 0.8394 - val_loss: 0.8498 - val_dense_6_loss: 0.8462 - val_dense_8_loss: 0.8784 - val_dense_6_accuracy: 0.7293 - val_dense_8_accuracy: 0.7244\n",
      "Epoch 19/50\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.4243 - dense_6_loss: 0.4232 - dense_8_loss: 0.4345 - dense_6_accuracy: 0.8658 - dense_8_accuracy: 0.8655\n",
      "Epoch 00019: val_dense_6_accuracy improved from 0.72927 to 0.74512, saving model to ./models/19-0.7451.h5\n",
      "3276/3276 [==============================] - 31s 9ms/sample - loss: 0.4254 - dense_6_loss: 0.4290 - dense_8_loss: 0.4400 - dense_6_accuracy: 0.8654 - dense_8_accuracy: 0.8651 - val_loss: 0.7925 - val_dense_6_loss: 0.7904 - val_dense_8_loss: 0.7996 - val_dense_6_accuracy: 0.7451 - val_dense_8_accuracy: 0.7427\n",
      "Epoch 20/50\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.3906 - dense_6_loss: 0.3898 - dense_8_loss: 0.3985 - dense_6_accuracy: 0.8756 - dense_8_accuracy: 0.8741\n",
      "Epoch 00020: val_dense_6_accuracy did not improve from 0.74512\n",
      "3276/3276 [==============================] - 31s 9ms/sample - loss: 0.3901 - dense_6_loss: 0.3868 - dense_8_loss: 0.3964 - dense_6_accuracy: 0.8758 - dense_8_accuracy: 0.8742 - val_loss: 0.8252 - val_dense_6_loss: 0.8199 - val_dense_8_loss: 0.8513 - val_dense_6_accuracy: 0.7317 - val_dense_8_accuracy: 0.7256\n",
      "Epoch 21/50\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.3592 - dense_6_loss: 0.3581 - dense_8_loss: 0.3690 - dense_6_accuracy: 0.8845 - dense_8_accuracy: 0.8805\n",
      "Epoch 00021: val_dense_6_accuracy did not improve from 0.74512\n",
      "3276/3276 [==============================] - 31s 10ms/sample - loss: 0.3619 - dense_6_loss: 0.3723 - dense_8_loss: 0.3831 - dense_6_accuracy: 0.8837 - dense_8_accuracy: 0.8797 - val_loss: 0.8214 - val_dense_6_loss: 0.8186 - val_dense_8_loss: 0.8386 - val_dense_6_accuracy: 0.7329 - val_dense_8_accuracy: 0.7317\n",
      "Epoch 22/50\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.3494 - dense_6_loss: 0.3477 - dense_8_loss: 0.3647 - dense_6_accuracy: 0.8903 - dense_8_accuracy: 0.8888\n",
      "Epoch 00022: val_dense_6_accuracy did not improve from 0.74512\n",
      "3276/3276 [==============================] - 31s 9ms/sample - loss: 0.3515 - dense_6_loss: 0.3584 - dense_8_loss: 0.3775 - dense_6_accuracy: 0.8898 - dense_8_accuracy: 0.8883 - val_loss: 0.8265 - val_dense_6_loss: 0.8199 - val_dense_8_loss: 0.8621 - val_dense_6_accuracy: 0.7341 - val_dense_8_accuracy: 0.7256\n",
      "Epoch 23/50\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.3094 - dense_6_loss: 0.3083 - dense_8_loss: 0.3194 - dense_6_accuracy: 0.9047 - dense_8_accuracy: 0.8971\n",
      "Epoch 00023: val_dense_6_accuracy did not improve from 0.74512\n",
      "3276/3276 [==============================] - 31s 9ms/sample - loss: 0.3091 - dense_6_loss: 0.3069 - dense_8_loss: 0.3174 - dense_6_accuracy: 0.9051 - dense_8_accuracy: 0.8974 - val_loss: 0.8538 - val_dense_6_loss: 0.8487 - val_dense_8_loss: 0.8862 - val_dense_6_accuracy: 0.7280 - val_dense_8_accuracy: 0.7244\n",
      "Epoch 24/50\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.2937 - dense_6_loss: 0.2931 - dense_8_loss: 0.2999 - dense_6_accuracy: 0.9081 - dense_8_accuracy: 0.9050\n",
      "Epoch 00024: val_dense_6_accuracy did not improve from 0.74512\n",
      "3276/3276 [==============================] - 31s 10ms/sample - loss: 0.2941 - dense_6_loss: 0.2951 - dense_8_loss: 0.3029 - dense_6_accuracy: 0.9078 - dense_8_accuracy: 0.9045 - val_loss: 0.8227 - val_dense_6_loss: 0.8194 - val_dense_8_loss: 0.8386 - val_dense_6_accuracy: 0.7341 - val_dense_8_accuracy: 0.7378\n",
      "Epoch 25/50\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.2545 - dense_6_loss: 0.2532 - dense_8_loss: 0.2662 - dense_6_accuracy: 0.9200 - dense_8_accuracy: 0.9142\n",
      "Epoch 00025: val_dense_6_accuracy did not improve from 0.74512\n",
      "3276/3276 [==============================] - 31s 10ms/sample - loss: 0.2542 - dense_6_loss: 0.2519 - dense_8_loss: 0.2647 - dense_6_accuracy: 0.9200 - dense_8_accuracy: 0.9142 - val_loss: 0.8768 - val_dense_6_loss: 0.8710 - val_dense_8_loss: 0.9101 - val_dense_6_accuracy: 0.7195 - val_dense_8_accuracy: 0.7195\n",
      "Epoch 26/50\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.2329 - dense_6_loss: 0.2317 - dense_8_loss: 0.2443 - dense_6_accuracy: 0.9292 - dense_8_accuracy: 0.9252\n",
      "Epoch 00026: val_dense_6_accuracy improved from 0.74512 to 0.75000, saving model to ./models/26-0.7500.h5\n",
      "3276/3276 [==============================] - 32s 10ms/sample - loss: 0.2323 - dense_6_loss: 0.2284 - dense_8_loss: 0.2406 - dense_6_accuracy: 0.9295 - dense_8_accuracy: 0.9255 - val_loss: 0.8809 - val_dense_6_loss: 0.8738 - val_dense_8_loss: 0.9248 - val_dense_6_accuracy: 0.7500 - val_dense_8_accuracy: 0.7476\n",
      "Epoch 27/50\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.2028 - dense_6_loss: 0.2017 - dense_8_loss: 0.2128 - dense_6_accuracy: 0.9409 - dense_8_accuracy: 0.9363\n",
      "Epoch 00027: val_dense_6_accuracy did not improve from 0.75000\n",
      "3276/3276 [==============================] - 34s 10ms/sample - loss: 0.2028 - dense_6_loss: 0.2018 - dense_8_loss: 0.2133 - dense_6_accuracy: 0.9408 - dense_8_accuracy: 0.9362 - val_loss: 0.8197 - val_dense_6_loss: 0.8133 - val_dense_8_loss: 0.8585 - val_dense_6_accuracy: 0.7439 - val_dense_8_accuracy: 0.7390\n",
      "Epoch 28/50\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.2129 - dense_6_loss: 0.2119 - dense_8_loss: 0.2217 - dense_6_accuracy: 0.9347 - dense_8_accuracy: 0.9326\n",
      "Epoch 00028: val_dense_6_accuracy did not improve from 0.75000\n",
      "3276/3276 [==============================] - 33s 10ms/sample - loss: 0.2124 - dense_6_loss: 0.2094 - dense_8_loss: 0.2183 - dense_6_accuracy: 0.9347 - dense_8_accuracy: 0.9328 - val_loss: 0.9280 - val_dense_6_loss: 0.9214 - val_dense_8_loss: 0.9707 - val_dense_6_accuracy: 0.7341 - val_dense_8_accuracy: 0.7305\n",
      "Epoch 29/50\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.1873 - dense_6_loss: 0.1865 - dense_8_loss: 0.1945 - dense_6_accuracy: 0.9430 - dense_8_accuracy: 0.9427\n",
      "Epoch 00029: val_dense_6_accuracy improved from 0.75000 to 0.76341, saving model to ./models/29-0.7634.h5\n",
      "3276/3276 [==============================] - 35s 11ms/sample - loss: 0.1878 - dense_6_loss: 0.1889 - dense_8_loss: 0.1965 - dense_6_accuracy: 0.9426 - dense_8_accuracy: 0.9426 - val_loss: 0.8228 - val_dense_6_loss: 0.8180 - val_dense_8_loss: 0.8558 - val_dense_6_accuracy: 0.7634 - val_dense_8_accuracy: 0.7585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.1839 - dense_6_loss: 0.1834 - dense_8_loss: 0.1891 - dense_6_accuracy: 0.9436 - dense_8_accuracy: 0.9409\n",
      "Epoch 00030: val_dense_6_accuracy did not improve from 0.76341\n",
      "3276/3276 [==============================] - 32s 10ms/sample - loss: 0.1845 - dense_6_loss: 0.1862 - dense_8_loss: 0.1925 - dense_6_accuracy: 0.9435 - dense_8_accuracy: 0.9408 - val_loss: 0.9282 - val_dense_6_loss: 0.9236 - val_dense_8_loss: 0.9765 - val_dense_6_accuracy: 0.7244 - val_dense_8_accuracy: 0.7171\n",
      "Epoch 31/50\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.1746 - dense_6_loss: 0.1738 - dense_8_loss: 0.1819 - dense_6_accuracy: 0.9442 - dense_8_accuracy: 0.9412\n",
      "Epoch 00031: val_dense_6_accuracy did not improve from 0.76341\n",
      "3276/3276 [==============================] - 34s 10ms/sample - loss: 0.1749 - dense_6_loss: 0.1751 - dense_8_loss: 0.1850 - dense_6_accuracy: 0.9438 - dense_8_accuracy: 0.9408 - val_loss: 0.8787 - val_dense_6_loss: 0.8724 - val_dense_8_loss: 0.9318 - val_dense_6_accuracy: 0.7390 - val_dense_8_accuracy: 0.7451\n",
      "Epoch 32/50\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.1551 - dense_6_loss: 0.1543 - dense_8_loss: 0.1624 - dense_6_accuracy: 0.9516 - dense_8_accuracy: 0.9491\n",
      "Epoch 00032: val_dense_6_accuracy did not improve from 0.76341\n",
      "3276/3276 [==============================] - 35s 11ms/sample - loss: 0.1549 - dense_6_loss: 0.1532 - dense_8_loss: 0.1613 - dense_6_accuracy: 0.9515 - dense_8_accuracy: 0.9490 - val_loss: 0.9428 - val_dense_6_loss: 0.9364 - val_dense_8_loss: 1.0029 - val_dense_6_accuracy: 0.7244 - val_dense_8_accuracy: 0.7232\n",
      "Epoch 33/50\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.1451 - dense_6_loss: 0.1442 - dense_8_loss: 0.1533 - dense_6_accuracy: 0.9519 - dense_8_accuracy: 0.9504\n",
      "Epoch 00033: val_dense_6_accuracy did not improve from 0.76341\n",
      "3276/3276 [==============================] - 33s 10ms/sample - loss: 0.1461 - dense_6_loss: 0.1494 - dense_8_loss: 0.1591 - dense_6_accuracy: 0.9515 - dense_8_accuracy: 0.9496 - val_loss: 0.8882 - val_dense_6_loss: 0.8808 - val_dense_8_loss: 0.9343 - val_dense_6_accuracy: 0.7390 - val_dense_8_accuracy: 0.7476\n",
      "Epoch 34/50\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.1538 - dense_6_loss: 0.1530 - dense_8_loss: 0.1615 - dense_6_accuracy: 0.9488 - dense_8_accuracy: 0.9473\n",
      "Epoch 00034: val_dense_6_accuracy did not improve from 0.76341\n",
      "3276/3276 [==============================] - 32s 10ms/sample - loss: 0.1536 - dense_6_loss: 0.1521 - dense_8_loss: 0.1606 - dense_6_accuracy: 0.9490 - dense_8_accuracy: 0.9475 - val_loss: 0.9263 - val_dense_6_loss: 0.9149 - val_dense_8_loss: 0.9823 - val_dense_6_accuracy: 0.7451 - val_dense_8_accuracy: 0.7415\n",
      "Epoch 35/50\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.1364 - dense_6_loss: 0.1358 - dense_8_loss: 0.1422 - dense_6_accuracy: 0.9599 - dense_8_accuracy: 0.9577\n",
      "Epoch 00035: val_dense_6_accuracy did not improve from 0.76341\n",
      "3276/3276 [==============================] - 32s 10ms/sample - loss: 0.1360 - dense_6_loss: 0.1336 - dense_8_loss: 0.1399 - dense_6_accuracy: 0.9600 - dense_8_accuracy: 0.9579 - val_loss: 0.9018 - val_dense_6_loss: 0.8931 - val_dense_8_loss: 0.9445 - val_dense_6_accuracy: 0.7488 - val_dense_8_accuracy: 0.7537\n",
      "Epoch 36/50\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.1247 - dense_6_loss: 0.1240 - dense_8_loss: 0.1309 - dense_6_accuracy: 0.9599 - dense_8_accuracy: 0.9574\n",
      "Epoch 00036: val_dense_6_accuracy did not improve from 0.76341\n",
      "3276/3276 [==============================] - 34s 10ms/sample - loss: 0.1250 - dense_6_loss: 0.1254 - dense_8_loss: 0.1313 - dense_6_accuracy: 0.9597 - dense_8_accuracy: 0.9573 - val_loss: 0.9575 - val_dense_6_loss: 0.9486 - val_dense_8_loss: 1.0159 - val_dense_6_accuracy: 0.7622 - val_dense_8_accuracy: 0.7573\n",
      "Epoch 37/50\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.1356 - dense_6_loss: 0.1349 - dense_8_loss: 0.1425 - dense_6_accuracy: 0.9599 - dense_8_accuracy: 0.9562\n",
      "Epoch 00037: val_dense_6_accuracy did not improve from 0.76341\n",
      "3276/3276 [==============================] - 35s 11ms/sample - loss: 0.1353 - dense_6_loss: 0.1333 - dense_8_loss: 0.1409 - dense_6_accuracy: 0.9600 - dense_8_accuracy: 0.9563 - val_loss: 0.9574 - val_dense_6_loss: 0.9493 - val_dense_8_loss: 1.0056 - val_dense_6_accuracy: 0.7463 - val_dense_8_accuracy: 0.7402\n",
      "Epoch 38/50\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.0912 - dense_6_loss: 0.0909 - dense_8_loss: 0.0946 - dense_6_accuracy: 0.9724 - dense_8_accuracy: 0.9718\n",
      "Epoch 00038: val_dense_6_accuracy did not improve from 0.76341\n",
      "3276/3276 [==============================] - 33s 10ms/sample - loss: 0.0910 - dense_6_loss: 0.0897 - dense_8_loss: 0.0933 - dense_6_accuracy: 0.9725 - dense_8_accuracy: 0.9719 - val_loss: 0.9947 - val_dense_6_loss: 0.9853 - val_dense_8_loss: 1.0473 - val_dense_6_accuracy: 0.7549 - val_dense_8_accuracy: 0.7549\n",
      "Epoch 39/50\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.1164 - dense_6_loss: 0.1158 - dense_8_loss: 0.1214 - dense_6_accuracy: 0.9632 - dense_8_accuracy: 0.9586\n",
      "Epoch 00039: val_dense_6_accuracy did not improve from 0.76341\n",
      "3276/3276 [==============================] - 38s 12ms/sample - loss: 0.1167 - dense_6_loss: 0.1174 - dense_8_loss: 0.1234 - dense_6_accuracy: 0.9631 - dense_8_accuracy: 0.9585 - val_loss: 0.9649 - val_dense_6_loss: 0.9541 - val_dense_8_loss: 1.0299 - val_dense_6_accuracy: 0.7402 - val_dense_8_accuracy: 0.7415\n",
      "Epoch 40/50\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.1302 - dense_6_loss: 0.1295 - dense_8_loss: 0.1368 - dense_6_accuracy: 0.9605 - dense_8_accuracy: 0.9580\n",
      "Epoch 00040: val_dense_6_accuracy did not improve from 0.76341\n",
      "3276/3276 [==============================] - 35s 11ms/sample - loss: 0.1298 - dense_6_loss: 0.1275 - dense_8_loss: 0.1346 - dense_6_accuracy: 0.9606 - dense_8_accuracy: 0.9582 - val_loss: 0.9829 - val_dense_6_loss: 0.9716 - val_dense_8_loss: 1.0488 - val_dense_6_accuracy: 0.7512 - val_dense_8_accuracy: 0.7476\n",
      "Epoch 41/50\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.1088 - dense_6_loss: 0.1081 - dense_8_loss: 0.1151 - dense_6_accuracy: 0.9657 - dense_8_accuracy: 0.9648\n",
      "Epoch 00041: val_dense_6_accuracy did not improve from 0.76341\n",
      "3276/3276 [==============================] - 34s 11ms/sample - loss: 0.1084 - dense_6_loss: 0.1062 - dense_8_loss: 0.1132 - dense_6_accuracy: 0.9658 - dense_8_accuracy: 0.9649 - val_loss: 1.0125 - val_dense_6_loss: 0.9958 - val_dense_8_loss: 1.0935 - val_dense_6_accuracy: 0.7476 - val_dense_8_accuracy: 0.7415\n",
      "Epoch 42/50\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.0720 - dense_6_loss: 0.0716 - dense_8_loss: 0.0759 - dense_6_accuracy: 0.9801 - dense_8_accuracy: 0.9798\n",
      "Epoch 00042: val_dense_6_accuracy did not improve from 0.76341\n",
      "3276/3276 [==============================] - 32s 10ms/sample - loss: 0.0720 - dense_6_loss: 0.0716 - dense_8_loss: 0.0755 - dense_6_accuracy: 0.9799 - dense_8_accuracy: 0.9799 - val_loss: 0.9771 - val_dense_6_loss: 0.9678 - val_dense_8_loss: 1.0316 - val_dense_6_accuracy: 0.7524 - val_dense_8_accuracy: 0.7561\n",
      "Epoch 43/50\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.0636 - dense_6_loss: 0.0633 - dense_8_loss: 0.0663 - dense_6_accuracy: 0.9804 - dense_8_accuracy: 0.9776\n",
      "Epoch 00043: val_dense_6_accuracy did not improve from 0.76341\n",
      "3276/3276 [==============================] - 32s 10ms/sample - loss: 0.0635 - dense_6_loss: 0.0627 - dense_8_loss: 0.0658 - dense_6_accuracy: 0.9805 - dense_8_accuracy: 0.9777 - val_loss: 0.9893 - val_dense_6_loss: 0.9768 - val_dense_8_loss: 1.0741 - val_dense_6_accuracy: 0.7598 - val_dense_8_accuracy: 0.7573\n",
      "Epoch 44/50\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.0620 - dense_6_loss: 0.0615 - dense_8_loss: 0.0668 - dense_6_accuracy: 0.9828 - dense_8_accuracy: 0.9813\n",
      "Epoch 00044: val_dense_6_accuracy did not improve from 0.76341\n",
      "3276/3276 [==============================] - 31s 10ms/sample - loss: 0.0619 - dense_6_loss: 0.0607 - dense_8_loss: 0.0660 - dense_6_accuracy: 0.9829 - dense_8_accuracy: 0.9814 - val_loss: 1.0418 - val_dense_6_loss: 1.0281 - val_dense_8_loss: 1.1252 - val_dense_6_accuracy: 0.7463 - val_dense_8_accuracy: 0.7476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.0946 - dense_6_loss: 0.0934 - dense_8_loss: 0.1048 - dense_6_accuracy: 0.9688 - dense_8_accuracy: 0.9657\n",
      "Epoch 00045: val_dense_6_accuracy did not improve from 0.76341\n",
      "3276/3276 [==============================] - 34s 10ms/sample - loss: 0.0951 - dense_6_loss: 0.0962 - dense_8_loss: 0.1073 - dense_6_accuracy: 0.9686 - dense_8_accuracy: 0.9655 - val_loss: 0.9765 - val_dense_6_loss: 0.9622 - val_dense_8_loss: 1.0542 - val_dense_6_accuracy: 0.7512 - val_dense_8_accuracy: 0.7500\n",
      "Epoch 46/50\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.0989 - dense_6_loss: 0.0980 - dense_8_loss: 0.1066 - dense_6_accuracy: 0.9709 - dense_8_accuracy: 0.9669\n",
      "Epoch 00046: val_dense_6_accuracy did not improve from 0.76341\n",
      "3276/3276 [==============================] - 34s 10ms/sample - loss: 0.0991 - dense_6_loss: 0.0990 - dense_8_loss: 0.1081 - dense_6_accuracy: 0.9707 - dense_8_accuracy: 0.9667 - val_loss: 0.9580 - val_dense_6_loss: 0.9472 - val_dense_8_loss: 1.0198 - val_dense_6_accuracy: 0.7561 - val_dense_8_accuracy: 0.7537\n",
      "Epoch 47/50\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.0880 - dense_6_loss: 0.0875 - dense_8_loss: 0.0924 - dense_6_accuracy: 0.9752 - dense_8_accuracy: 0.9727\n",
      "Epoch 00047: val_dense_6_accuracy did not improve from 0.76341\n",
      "3276/3276 [==============================] - 32s 10ms/sample - loss: 0.0877 - dense_6_loss: 0.0860 - dense_8_loss: 0.0907 - dense_6_accuracy: 0.9753 - dense_8_accuracy: 0.9728 - val_loss: 1.0409 - val_dense_6_loss: 1.0298 - val_dense_8_loss: 1.1058 - val_dense_6_accuracy: 0.7463 - val_dense_8_accuracy: 0.7427\n",
      "Epoch 48/50\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.0764 - dense_6_loss: 0.0760 - dense_8_loss: 0.0806 - dense_6_accuracy: 0.9786 - dense_8_accuracy: 0.9773\n",
      "Epoch 00048: val_dense_6_accuracy did not improve from 0.76341\n",
      "3276/3276 [==============================] - 31s 10ms/sample - loss: 0.0763 - dense_6_loss: 0.0752 - dense_8_loss: 0.0800 - dense_6_accuracy: 0.9786 - dense_8_accuracy: 0.9774 - val_loss: 0.9829 - val_dense_6_loss: 0.9733 - val_dense_8_loss: 1.0338 - val_dense_6_accuracy: 0.7610 - val_dense_8_accuracy: 0.7573\n",
      "Epoch 49/50\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.0940 - dense_6_loss: 0.0934 - dense_8_loss: 0.1000 - dense_6_accuracy: 0.9718 - dense_8_accuracy: 0.9709\n",
      "Epoch 00049: val_dense_6_accuracy did not improve from 0.76341\n",
      "3276/3276 [==============================] - 32s 10ms/sample - loss: 0.0938 - dense_6_loss: 0.0918 - dense_8_loss: 0.0986 - dense_6_accuracy: 0.9719 - dense_8_accuracy: 0.9710 - val_loss: 0.9500 - val_dense_6_loss: 0.9380 - val_dense_8_loss: 1.0072 - val_dense_6_accuracy: 0.7378 - val_dense_8_accuracy: 0.7354\n",
      "Epoch 50/50\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.0593 - dense_6_loss: 0.0590 - dense_8_loss: 0.0624 - dense_6_accuracy: 0.9822 - dense_8_accuracy: 0.9813\n",
      "Epoch 00050: val_dense_6_accuracy improved from 0.76341 to 0.76463, saving model to ./models/50-0.7646.h5\n",
      "3276/3276 [==============================] - 32s 10ms/sample - loss: 0.0593 - dense_6_loss: 0.0589 - dense_8_loss: 0.0623 - dense_6_accuracy: 0.9823 - dense_8_accuracy: 0.9814 - val_loss: 0.9711 - val_dense_6_loss: 0.9595 - val_dense_8_loss: 1.0310 - val_dense_6_accuracy: 0.7646 - val_dense_8_accuracy: 0.7659\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam', metrics = ['accuracy'], loss = 'categorical_crossentropy', \n",
    "              loss_weights = [0.9, 0.1])\n",
    "history = model.fit([x1_train, x1_letter_train, x2_train, x2_letter_train], [y1_train, y2_train],\n",
    "                    validation_data=([x1_val, x1_letter_val, x2_val, x2_letter_val], [y1_val, y2_val]), \n",
    "                    batch_size=64, epochs=50, verbose=1, \n",
    "                    callbacks = [ModelCheckpoint('./models/{epoch:02d}-{val_dense_6_accuracy:.4f}.h5',\n",
    "                    monitor='val_dense_6_accuracy', verbose=1, save_best_only=True, mode='auto')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T08:22:53.849096Z",
     "start_time": "2020-08-18T08:22:51.853081Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "820/1 - 2s - loss: 0.8184 - dense_6_loss: 0.9595 - dense_8_loss: 1.0310 - dense_6_accuracy: 0.7646 - dense_8_accuracy: 0.7659\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9710885992864283, 0.95954156, 1.0309701, 0.76463413, 0.76585364]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate = model.evaluate([x1_val, x1_letter_val, x2_val, x2_letter_val], [y1_val, y2_val], \n",
    "                          batch_size=64, verbose=2)\n",
    "evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T08:20:11.234230Z",
     "start_time": "2020-08-18T08:20:11.231316Z"
    }
   },
   "outputs": [],
   "source": [
    "#from tensorflow.keras.models import load_model\n",
    "#best_model = load_model('./models/35-0.6695.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T08:21:26.982083Z",
     "start_time": "2020-08-18T08:20:11.239233Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 9 2 ... 6 1 0]\n",
      "[6 9 2 ... 6 1 0]\n"
     ]
    }
   ],
   "source": [
    "x1_test = test.drop(['id', 'letter'], axis=1).values\n",
    "x1_test = x1_test.reshape(-1, 28, 28, 1)\n",
    "x1_test = x1_test/255\n",
    "\n",
    "x2_test = test.drop(['id', 'letter'], axis=1).values\n",
    "x2_test = x2_test.reshape(-1, 28, 28)\n",
    "x2_test = x2_test/255\n",
    "\n",
    "x1_letter_test = test['letter'].values\n",
    "x1_letter_test = x1_letter_test[:, np.newaxis]\n",
    "en = OneHotEncoder()\n",
    "x1_letter_test = en.fit_transform(x1_letter_test).toarray()\n",
    "\n",
    "x2_letter_test = x1_letter_test.copy()\n",
    "\n",
    "y1_test, y2_test = model.predict([x1_test, x1_letter_test, x2_test, x2_letter_test])\n",
    "y_1 = np.argmax(y1_test, axis=1)\n",
    "y_2 = np.argmax(y2_test, axis=1)\n",
    "print(y_1)\n",
    "print(y_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T08:23:40.186633Z",
     "start_time": "2020-08-18T08:23:40.138504Z"
    }
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('data/submission.csv')\n",
    "submission['digit'] = y_1\n",
    "submission.to_csv('submission(val7646).csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

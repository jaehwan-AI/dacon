{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T07:17:30.192760Z",
     "start_time": "2020-08-18T07:17:26.719517Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, LSTM, concatenate, Dropout\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# seed\n",
    "import os\n",
    "seed = 123\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T07:17:31.613553Z",
     "start_time": "2020-08-18T07:17:30.192760Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T07:17:31.628923Z",
     "start_time": "2020-08-18T07:17:31.613553Z"
    }
   },
   "outputs": [],
   "source": [
    "image_generator = ImageDataGenerator(width_shift_range=0.1,\n",
    "                                     height_shift_range=0.1, \n",
    "                                     zoom_range=[0.8,1.2],\n",
    "                                     #brightness_range=[0.8,1.2], \n",
    "                                     shear_range=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T07:17:32.644350Z",
     "start_time": "2020-08-18T07:17:31.633908Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4096, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "x1 = train.drop(['id', 'digit', 'letter'], axis=1).values\n",
    "x1 = x1.reshape(-1, 28, 28, 1)\n",
    "x1 = x1/255\n",
    "x1_remake = []\n",
    "for i in range(x1.shape[0]):\n",
    "    num_aug = 0\n",
    "    tmp = x1[i]\n",
    "    tmp = tmp.reshape((1,) + tmp.shape)\n",
    "    for x_aug in image_generator.flow(tmp, batch_size = 1) :\n",
    "        if num_aug >= 1:\n",
    "            break\n",
    "        x1_remake.append(x_aug[0])\n",
    "        num_aug += 1\n",
    "x1_remake = np.array(x1_remake)\n",
    "\n",
    "x1_total = np.concatenate((x1, x1_remake), axis=0)\n",
    "print(x1_total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T07:17:32.660268Z",
     "start_time": "2020-08-18T07:17:32.646327Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4096, 10)\n"
     ]
    }
   ],
   "source": [
    "y1_data = train['digit']\n",
    "y1 = np.zeros((len(y1_data), len(y1_data.unique())))\n",
    "for i, digit in enumerate(y1_data):\n",
    "    y1[i, digit] = 1\n",
    "\n",
    "y1_remake = y1.copy()\n",
    "y1_total = np.concatenate((y1, y1_remake), axis=0)\n",
    "print(y1_total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T07:17:32.691183Z",
     "start_time": "2020-08-18T07:17:32.664251Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4096, 26)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1_let = train['letter'].values\n",
    "x1_let = x1_let[:, np.newaxis]\n",
    "en = OneHotEncoder()\n",
    "x1_let = en.fit_transform(x1_let).toarray()\n",
    "\n",
    "x1_remake_let = x1_let.copy()\n",
    "\n",
    "x1_letter_total = np.concatenate((x1_let, x1_remake_let), axis=0)\n",
    "x1_letter_total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T07:17:32.770799Z",
     "start_time": "2020-08-18T07:17:32.696115Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3276, 28, 28, 1)\n",
      "(820, 28, 28, 1)\n",
      "(3276, 10)\n",
      "(820, 10)\n",
      "(3276, 26)\n",
      "(820, 26)\n"
     ]
    }
   ],
   "source": [
    "x1_train, x1_val, y1_train, y1_val = train_test_split(x1_total, y1_total, test_size=0.2, shuffle=True, stratify=y1_total)\n",
    "\n",
    "print(x1_train.shape)\n",
    "print(x1_val.shape)\n",
    "print(y1_train.shape)\n",
    "print(y1_val.shape)\n",
    "\n",
    "x1_letter_train = x1_letter_total[:x1_train.shape[0],:]\n",
    "x1_letter_val = x1_letter_total[x1_train.shape[0]:,:]\n",
    "print(x1_letter_train.shape)\n",
    "print(x1_letter_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T07:17:32.785735Z",
     "start_time": "2020-08-18T07:17:32.772791Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3276, 28, 28)\n",
      "(820, 28, 28)\n",
      "(3276, 10)\n",
      "(820, 10)\n",
      "(3276, 26)\n",
      "(820, 26)\n"
     ]
    }
   ],
   "source": [
    "x2_train = np.reshape(x1_train, (x1_train.shape[0], x1_train.shape[1], x1_train.shape[2]))\n",
    "x2_val = np.reshape(x1_val, (x1_val.shape[0], x1_val.shape[1], x1_val.shape[2]))\n",
    "y2_train = y1_train.copy()\n",
    "y2_val = y1_val.copy()\n",
    "x2_letter_train = x1_letter_train.copy()\n",
    "x2_letter_val = x1_letter_val.copy()\n",
    "\n",
    "print(x2_train.shape)\n",
    "print(x2_val.shape)\n",
    "print(y2_train.shape)\n",
    "print(y2_val.shape)\n",
    "print(x2_letter_train.shape)\n",
    "print(x2_letter_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T07:17:34.660711Z",
     "start_time": "2020-08-18T07:17:32.787728Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 28, 28, 64)   320         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 28, 28, 64)   0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 14, 14, 64)   0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 14, 14, 64)   16448       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 14, 14, 64)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 28, 28)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 7, 7, 64)     0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 28, 512)      1107968     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 7, 7, 128)    32896       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 28, 512)      0           lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 7, 7, 128)    0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 28, 256)      787456      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 3, 3, 128)    0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 28, 256)      0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1152)         0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 26)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 128)          197120      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1178)         0           flatten[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 128)          0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 500)          589500      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 100)          12900       dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 26)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 500)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 126)          0           dense_2[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          50100       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 100)          12700       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 200)          0           dense_1[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 100)          20100       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 100)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 50)           5050        dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 50)           0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 50)           5050        dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 10)           510         dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 10)           510         dense_7[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,838,628\n",
      "Trainable params: 2,838,628\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input1 = Input(shape=(28,28,1))\n",
    "x1 = Conv2D(64, (2,2), activation='relu', padding='same')(input1)\n",
    "x1 = Dropout(0.2)(x1)\n",
    "x1 = MaxPooling2D((2,2))(x1)\n",
    "x1 = Conv2D(64, (2,2), activation='relu', padding='same')(x1)\n",
    "x1 = Dropout(0.2)(x1)\n",
    "x1 = MaxPooling2D((2,2))(x1)\n",
    "x1 = Conv2D(128, (2,2), activation='relu', padding='same')(x1)\n",
    "x1 = Dropout(0.2)(x1)\n",
    "x1 = MaxPooling2D((2,2))(x1)\n",
    "x1 = Flatten()(x1)\n",
    "\n",
    "input2 = Input(shape=(26,))\n",
    "merge1 = concatenate([x1, input2])\n",
    "\n",
    "x2 = Dense(500, activation='relu')(merge1)\n",
    "x2 = Dropout(0.2)(x2)\n",
    "x2 = Dense(100, activation='relu')(x2)\n",
    "\n",
    "input3 = Input(shape=(28,28))\n",
    "x3 = LSTM(512, activation='relu', return_sequences=True)(input3)\n",
    "x3 = Dropout(0.2)(x3)\n",
    "x3 = LSTM(256, activation='relu', return_sequences=True)(x3)\n",
    "x3 = Dropout(0.2)(x3)\n",
    "x3 = LSTM(128, activation='relu')(x3)\n",
    "x3 = Dropout(0.2)(x3)\n",
    "x3 = Dense(100, activation='relu')(x3)\n",
    "\n",
    "input4 = Input(shape=(26,))\n",
    "merge2 = concatenate([x3, input4])\n",
    "\n",
    "x4 = Dense(100, activation='relu')(merge2)\n",
    "\n",
    "merge = concatenate([x2, x4])\n",
    "\n",
    "x5 = Dense(100, activation='relu')(merge)\n",
    "x5 = Dropout(0.2)(x5)\n",
    "\n",
    "x6 = Dense(50, activation='relu')(x5)\n",
    "x6 = Dropout(0.2)(x6)\n",
    "output1 = Dense(10, activation='softmax')(x6)\n",
    "\n",
    "x7 = Dense(50, activation='relu')(x5)\n",
    "output2 = Dense(10, activation='softmax')(x7)\n",
    "\n",
    "model = Model(inputs = [input1, input2, input3, input4], outputs = [output1, output2])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T07:30:05.566602Z",
     "start_time": "2020-08-18T07:17:34.664653Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3276 samples, validate on 820 samples\n",
      "Epoch 1/50\n",
      "3276/3276 [==============================] - 23s 7ms/step - loss: 2.3026 - dense_6_loss: 2.3023 - dense_8_loss: 2.3036 - dense_6_acc: 0.1071 - dense_8_acc: 0.1029 - val_loss: 2.2964 - val_dense_6_loss: 2.2955 - val_dense_8_loss: 2.3002 - val_dense_6_acc: 0.1280 - val_dense_8_acc: 0.1000\n",
      "\n",
      "Epoch 00001: val_dense_6_acc improved from -inf to 0.12805, saving model to ./models/01-0.1280.h5\n",
      "Epoch 2/50\n",
      "3276/3276 [==============================] - 15s 5ms/step - loss: 2.2117 - dense_6_loss: 2.2041 - dense_8_loss: 2.2420 - dense_6_acc: 0.1749 - dense_8_acc: 0.1441 - val_loss: 2.1371 - val_dense_6_loss: 2.1281 - val_dense_8_loss: 2.1733 - val_dense_6_acc: 0.2232 - val_dense_8_acc: 0.1963\n",
      "\n",
      "Epoch 00002: val_dense_6_acc improved from 0.12805 to 0.22317, saving model to ./models/02-0.2232.h5\n",
      "Epoch 3/50\n",
      "3276/3276 [==============================] - 15s 5ms/step - loss: 2.0240 - dense_6_loss: 2.0212 - dense_8_loss: 2.0352 - dense_6_acc: 0.2564 - dense_8_acc: 0.2442 - val_loss: 1.9631 - val_dense_6_loss: 1.9586 - val_dense_8_loss: 1.9813 - val_dense_6_acc: 0.3232 - val_dense_8_acc: 0.3134\n",
      "\n",
      "Epoch 00003: val_dense_6_acc improved from 0.22317 to 0.32317, saving model to ./models/03-0.3232.h5\n",
      "Epoch 4/50\n",
      "3276/3276 [==============================] - 15s 5ms/step - loss: 1.7526 - dense_6_loss: 1.7587 - dense_8_loss: 1.7279 - dense_6_acc: 0.3828 - dense_8_acc: 0.3877 - val_loss: 1.6640 - val_dense_6_loss: 1.6563 - val_dense_8_loss: 1.6949 - val_dense_6_acc: 0.4512 - val_dense_8_acc: 0.4122\n",
      "\n",
      "Epoch 00004: val_dense_6_acc improved from 0.32317 to 0.45122, saving model to ./models/04-0.4512.h5\n",
      "Epoch 5/50\n",
      "3276/3276 [==============================] - 15s 5ms/step - loss: 1.4973 - dense_6_loss: 1.5045 - dense_8_loss: 1.4685 - dense_6_acc: 0.4884 - dense_8_acc: 0.4957 - val_loss: 1.5227 - val_dense_6_loss: 1.5236 - val_dense_8_loss: 1.5190 - val_dense_6_acc: 0.4902 - val_dense_8_acc: 0.4878\n",
      "\n",
      "Epoch 00005: val_dense_6_acc improved from 0.45122 to 0.49024, saving model to ./models/05-0.4902.h5\n",
      "Epoch 6/50\n",
      "3276/3276 [==============================] - 14s 4ms/step - loss: 1.3450 - dense_6_loss: 1.3531 - dense_8_loss: 1.3125 - dense_6_acc: 0.5446 - dense_8_acc: 0.5565 - val_loss: 1.4050 - val_dense_6_loss: 1.4082 - val_dense_8_loss: 1.3923 - val_dense_6_acc: 0.5451 - val_dense_8_acc: 0.5354\n",
      "\n",
      "Epoch 00006: val_dense_6_acc improved from 0.49024 to 0.54512, saving model to ./models/06-0.5451.h5\n",
      "Epoch 7/50\n",
      "3276/3276 [==============================] - 15s 4ms/step - loss: 1.2244 - dense_6_loss: 1.2313 - dense_8_loss: 1.1965 - dense_6_acc: 0.5824 - dense_8_acc: 0.5958 - val_loss: 1.4343 - val_dense_6_loss: 1.4408 - val_dense_8_loss: 1.4080 - val_dense_6_acc: 0.5488 - val_dense_8_acc: 0.5439\n",
      "\n",
      "Epoch 00007: val_dense_6_acc improved from 0.54512 to 0.54878, saving model to ./models/07-0.5488.h5\n",
      "Epoch 8/50\n",
      "3276/3276 [==============================] - 14s 4ms/step - loss: 1.1109 - dense_6_loss: 1.1199 - dense_8_loss: 1.0748 - dense_6_acc: 0.6233 - dense_8_acc: 0.6340 - val_loss: 1.2170 - val_dense_6_loss: 1.2171 - val_dense_8_loss: 1.2165 - val_dense_6_acc: 0.5902 - val_dense_8_acc: 0.5988\n",
      "\n",
      "Epoch 00008: val_dense_6_acc improved from 0.54878 to 0.59024, saving model to ./models/08-0.5902.h5\n",
      "Epoch 9/50\n",
      "3276/3276 [==============================] - 15s 4ms/step - loss: 1.0360 - dense_6_loss: 1.0452 - dense_8_loss: 0.9992 - dense_6_acc: 0.6548 - dense_8_acc: 0.6578 - val_loss: 1.1633 - val_dense_6_loss: 1.1656 - val_dense_8_loss: 1.1542 - val_dense_6_acc: 0.6305 - val_dense_8_acc: 0.6268\n",
      "\n",
      "Epoch 00009: val_dense_6_acc improved from 0.59024 to 0.63049, saving model to ./models/09-0.6305.h5\n",
      "Epoch 10/50\n",
      "3276/3276 [==============================] - 15s 5ms/step - loss: 0.9325 - dense_6_loss: 0.9386 - dense_8_loss: 0.9084 - dense_6_acc: 0.6847 - dense_8_acc: 0.6935 - val_loss: 1.1340 - val_dense_6_loss: 1.1378 - val_dense_8_loss: 1.1185 - val_dense_6_acc: 0.6354 - val_dense_8_acc: 0.6280\n",
      "\n",
      "Epoch 00010: val_dense_6_acc improved from 0.63049 to 0.63537, saving model to ./models/10-0.6354.h5\n",
      "Epoch 11/50\n",
      "3276/3276 [==============================] - 15s 5ms/step - loss: 0.8486 - dense_6_loss: 0.8574 - dense_8_loss: 0.8132 - dense_6_acc: 0.7085 - dense_8_acc: 0.7274 - val_loss: 1.0688 - val_dense_6_loss: 1.0716 - val_dense_8_loss: 1.0574 - val_dense_6_acc: 0.6427 - val_dense_8_acc: 0.6390\n",
      "\n",
      "Epoch 00011: val_dense_6_acc improved from 0.63537 to 0.64268, saving model to ./models/11-0.6427.h5\n",
      "Epoch 12/50\n",
      "3276/3276 [==============================] - 15s 4ms/step - loss: 0.7826 - dense_6_loss: 0.7898 - dense_8_loss: 0.7538 - dense_6_acc: 0.7399 - dense_8_acc: 0.7494 - val_loss: 1.0046 - val_dense_6_loss: 1.0063 - val_dense_8_loss: 0.9977 - val_dense_6_acc: 0.6707 - val_dense_8_acc: 0.6707\n",
      "\n",
      "Epoch 00012: val_dense_6_acc improved from 0.64268 to 0.67073, saving model to ./models/12-0.6707.h5\n",
      "Epoch 13/50\n",
      "3276/3276 [==============================] - 15s 4ms/step - loss: 0.7188 - dense_6_loss: 0.7263 - dense_8_loss: 0.6890 - dense_6_acc: 0.7628 - dense_8_acc: 0.7671 - val_loss: 0.9914 - val_dense_6_loss: 0.9942 - val_dense_8_loss: 0.9804 - val_dense_6_acc: 0.6720 - val_dense_8_acc: 0.6646\n",
      "\n",
      "Epoch 00013: val_dense_6_acc improved from 0.67073 to 0.67195, saving model to ./models/13-0.6720.h5\n",
      "Epoch 14/50\n",
      "3276/3276 [==============================] - 14s 4ms/step - loss: 0.6390 - dense_6_loss: 0.6454 - dense_8_loss: 0.6134 - dense_6_acc: 0.7830 - dense_8_acc: 0.7933 - val_loss: 1.0176 - val_dense_6_loss: 1.0201 - val_dense_8_loss: 1.0077 - val_dense_6_acc: 0.6512 - val_dense_8_acc: 0.6598\n",
      "\n",
      "Epoch 00014: val_dense_6_acc did not improve from 0.67195\n",
      "Epoch 15/50\n",
      "3276/3276 [==============================] - 14s 4ms/step - loss: 0.6250 - dense_6_loss: 0.6331 - dense_8_loss: 0.5929 - dense_6_acc: 0.7952 - dense_8_acc: 0.7973 - val_loss: 0.9559 - val_dense_6_loss: 0.9558 - val_dense_8_loss: 0.9561 - val_dense_6_acc: 0.6756 - val_dense_8_acc: 0.6707\n",
      "\n",
      "Epoch 00015: val_dense_6_acc improved from 0.67195 to 0.67561, saving model to ./models/15-0.6756.h5\n",
      "Epoch 16/50\n",
      "3276/3276 [==============================] - 14s 4ms/step - loss: 0.5698 - dense_6_loss: 0.5771 - dense_8_loss: 0.5408 - dense_6_acc: 0.8126 - dense_8_acc: 0.8214 - val_loss: 1.0214 - val_dense_6_loss: 1.0236 - val_dense_8_loss: 1.0129 - val_dense_6_acc: 0.6402 - val_dense_8_acc: 0.6415\n",
      "\n",
      "Epoch 00016: val_dense_6_acc did not improve from 0.67561\n",
      "Epoch 17/50\n",
      "3276/3276 [==============================] - 14s 4ms/step - loss: 0.4982 - dense_6_loss: 0.5054 - dense_8_loss: 0.4693 - dense_6_acc: 0.8407 - dense_8_acc: 0.8434 - val_loss: 0.9556 - val_dense_6_loss: 0.9565 - val_dense_8_loss: 0.9521 - val_dense_6_acc: 0.6671 - val_dense_8_acc: 0.6671\n",
      "\n",
      "Epoch 00017: val_dense_6_acc did not improve from 0.67561\n",
      "Epoch 18/50\n",
      "3276/3276 [==============================] - 14s 4ms/step - loss: 0.4611 - dense_6_loss: 0.4680 - dense_8_loss: 0.4331 - dense_6_acc: 0.8468 - dense_8_acc: 0.8520 - val_loss: 0.9071 - val_dense_6_loss: 0.9059 - val_dense_8_loss: 0.9122 - val_dense_6_acc: 0.7012 - val_dense_8_acc: 0.6976\n",
      "\n",
      "Epoch 00018: val_dense_6_acc improved from 0.67561 to 0.70122, saving model to ./models/18-0.7012.h5\n",
      "Epoch 19/50\n",
      "3276/3276 [==============================] - 15s 4ms/step - loss: 0.4048 - dense_6_loss: 0.4128 - dense_8_loss: 0.3725 - dense_6_acc: 0.8578 - dense_8_acc: 0.8721 - val_loss: 0.8652 - val_dense_6_loss: 0.8667 - val_dense_8_loss: 0.8591 - val_dense_6_acc: 0.7098 - val_dense_8_acc: 0.7037\n",
      "\n",
      "Epoch 00019: val_dense_6_acc improved from 0.70122 to 0.70976, saving model to ./models/19-0.7098.h5\n",
      "Epoch 20/50\n",
      "3276/3276 [==============================] - 15s 5ms/step - loss: 0.3455 - dense_6_loss: 0.3503 - dense_8_loss: 0.3263 - dense_6_acc: 0.8828 - dense_8_acc: 0.8892 - val_loss: 0.9095 - val_dense_6_loss: 0.9103 - val_dense_8_loss: 0.9062 - val_dense_6_acc: 0.7024 - val_dense_8_acc: 0.7024\n",
      "\n",
      "Epoch 00020: val_dense_6_acc did not improve from 0.70976\n",
      "Epoch 21/50\n",
      "3276/3276 [==============================] - 15s 4ms/step - loss: 0.3523 - dense_6_loss: 0.3572 - dense_8_loss: 0.3326 - dense_6_acc: 0.8816 - dense_8_acc: 0.8889 - val_loss: 0.9023 - val_dense_6_loss: 0.9023 - val_dense_8_loss: 0.9022 - val_dense_6_acc: 0.7171 - val_dense_8_acc: 0.7183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00021: val_dense_6_acc improved from 0.70976 to 0.71707, saving model to ./models/21-0.7171.h5\n",
      "Epoch 22/50\n",
      "3276/3276 [==============================] - 15s 5ms/step - loss: 0.2919 - dense_6_loss: 0.3001 - dense_8_loss: 0.2591 - dense_6_acc: 0.9023 - dense_8_acc: 0.9148 - val_loss: 0.8763 - val_dense_6_loss: 0.8768 - val_dense_8_loss: 0.8742 - val_dense_6_acc: 0.7061 - val_dense_8_acc: 0.7085\n",
      "\n",
      "Epoch 00022: val_dense_6_acc did not improve from 0.71707\n",
      "Epoch 23/50\n",
      "3276/3276 [==============================] - 15s 5ms/step - loss: 0.2865 - dense_6_loss: 0.2937 - dense_8_loss: 0.2576 - dense_6_acc: 0.9081 - dense_8_acc: 0.9179 - val_loss: 0.9722 - val_dense_6_loss: 0.9728 - val_dense_8_loss: 0.9698 - val_dense_6_acc: 0.6829 - val_dense_8_acc: 0.6866\n",
      "\n",
      "Epoch 00023: val_dense_6_acc did not improve from 0.71707\n",
      "Epoch 24/50\n",
      "3276/3276 [==============================] - 15s 5ms/step - loss: 0.2528 - dense_6_loss: 0.2576 - dense_8_loss: 0.2335 - dense_6_acc: 0.9194 - dense_8_acc: 0.9252 - val_loss: 0.9455 - val_dense_6_loss: 0.9485 - val_dense_8_loss: 0.9336 - val_dense_6_acc: 0.6768 - val_dense_8_acc: 0.6817\n",
      "\n",
      "Epoch 00024: val_dense_6_acc did not improve from 0.71707\n",
      "Epoch 25/50\n",
      "3276/3276 [==============================] - 15s 5ms/step - loss: 0.2184 - dense_6_loss: 0.2238 - dense_8_loss: 0.1969 - dense_6_acc: 0.9313 - dense_8_acc: 0.9353 - val_loss: 0.9730 - val_dense_6_loss: 0.9734 - val_dense_8_loss: 0.9718 - val_dense_6_acc: 0.6890 - val_dense_8_acc: 0.6902\n",
      "\n",
      "Epoch 00025: val_dense_6_acc did not improve from 0.71707\n",
      "Epoch 26/50\n",
      "3276/3276 [==============================] - 15s 5ms/step - loss: 0.2082 - dense_6_loss: 0.2133 - dense_8_loss: 0.1877 - dense_6_acc: 0.9328 - dense_8_acc: 0.9380 - val_loss: 0.9034 - val_dense_6_loss: 0.9060 - val_dense_8_loss: 0.8927 - val_dense_6_acc: 0.7073 - val_dense_8_acc: 0.7098\n",
      "\n",
      "Epoch 00026: val_dense_6_acc did not improve from 0.71707\n",
      "Epoch 27/50\n",
      "3276/3276 [==============================] - 15s 5ms/step - loss: 0.2016 - dense_6_loss: 0.2083 - dense_8_loss: 0.1748 - dense_6_acc: 0.9322 - dense_8_acc: 0.9414 - val_loss: 0.9263 - val_dense_6_loss: 0.9277 - val_dense_8_loss: 0.9208 - val_dense_6_acc: 0.7085 - val_dense_8_acc: 0.7037\n",
      "\n",
      "Epoch 00027: val_dense_6_acc did not improve from 0.71707\n",
      "Epoch 28/50\n",
      "3276/3276 [==============================] - 14s 4ms/step - loss: 0.1691 - dense_6_loss: 0.1737 - dense_8_loss: 0.1509 - dense_6_acc: 0.9435 - dense_8_acc: 0.9496 - val_loss: 0.9311 - val_dense_6_loss: 0.9328 - val_dense_8_loss: 0.9240 - val_dense_6_acc: 0.7183 - val_dense_8_acc: 0.7134\n",
      "\n",
      "Epoch 00028: val_dense_6_acc improved from 0.71707 to 0.71829, saving model to ./models/28-0.7183.h5\n",
      "Epoch 29/50\n",
      "3276/3276 [==============================] - 15s 4ms/step - loss: 0.1831 - dense_6_loss: 0.1900 - dense_8_loss: 0.1553 - dense_6_acc: 0.9393 - dense_8_acc: 0.9487 - val_loss: 1.0187 - val_dense_6_loss: 1.0222 - val_dense_8_loss: 1.0047 - val_dense_6_acc: 0.6963 - val_dense_8_acc: 0.7000\n",
      "\n",
      "Epoch 00029: val_dense_6_acc did not improve from 0.71829\n",
      "Epoch 30/50\n",
      "3276/3276 [==============================] - 15s 5ms/step - loss: 0.1732 - dense_6_loss: 0.1786 - dense_8_loss: 0.1518 - dense_6_acc: 0.9457 - dense_8_acc: 0.9509 - val_loss: 0.9514 - val_dense_6_loss: 0.9545 - val_dense_8_loss: 0.9390 - val_dense_6_acc: 0.7146 - val_dense_8_acc: 0.7134\n",
      "\n",
      "Epoch 00030: val_dense_6_acc did not improve from 0.71829\n",
      "Epoch 31/50\n",
      "3276/3276 [==============================] - 14s 4ms/step - loss: 0.1462 - dense_6_loss: 0.1492 - dense_8_loss: 0.1345 - dense_6_acc: 0.9530 - dense_8_acc: 0.9612 - val_loss: 1.0506 - val_dense_6_loss: 1.0541 - val_dense_8_loss: 1.0364 - val_dense_6_acc: 0.7134 - val_dense_8_acc: 0.7183\n",
      "\n",
      "Epoch 00031: val_dense_6_acc did not improve from 0.71829\n",
      "Epoch 32/50\n",
      "3276/3276 [==============================] - 15s 4ms/step - loss: 0.1697 - dense_6_loss: 0.1747 - dense_8_loss: 0.1498 - dense_6_acc: 0.9466 - dense_8_acc: 0.9484 - val_loss: 0.9908 - val_dense_6_loss: 0.9933 - val_dense_8_loss: 0.9808 - val_dense_6_acc: 0.7244 - val_dense_8_acc: 0.7183\n",
      "\n",
      "Epoch 00032: val_dense_6_acc improved from 0.71829 to 0.72439, saving model to ./models/32-0.7244.h5\n",
      "Epoch 33/50\n",
      "3276/3276 [==============================] - 14s 4ms/step - loss: 0.1271 - dense_6_loss: 0.1310 - dense_8_loss: 0.1116 - dense_6_acc: 0.9588 - dense_8_acc: 0.9625 - val_loss: 0.9587 - val_dense_6_loss: 0.9603 - val_dense_8_loss: 0.9522 - val_dense_6_acc: 0.6988 - val_dense_8_acc: 0.6927\n",
      "\n",
      "Epoch 00033: val_dense_6_acc did not improve from 0.72439\n",
      "Epoch 34/50\n",
      "3276/3276 [==============================] - 15s 4ms/step - loss: 0.1513 - dense_6_loss: 0.1545 - dense_8_loss: 0.1386 - dense_6_acc: 0.9496 - dense_8_acc: 0.9567 - val_loss: 0.9811 - val_dense_6_loss: 0.9836 - val_dense_8_loss: 0.9710 - val_dense_6_acc: 0.7232 - val_dense_8_acc: 0.7256\n",
      "\n",
      "Epoch 00034: val_dense_6_acc did not improve from 0.72439\n",
      "Epoch 35/50\n",
      "3276/3276 [==============================] - 15s 4ms/step - loss: 0.1265 - dense_6_loss: 0.1310 - dense_8_loss: 0.1085 - dense_6_acc: 0.9615 - dense_8_acc: 0.9655 - val_loss: 1.1279 - val_dense_6_loss: 1.1290 - val_dense_8_loss: 1.1231 - val_dense_6_acc: 0.6988 - val_dense_8_acc: 0.6963\n",
      "\n",
      "Epoch 00035: val_dense_6_acc did not improve from 0.72439\n",
      "Epoch 36/50\n",
      "3276/3276 [==============================] - 14s 4ms/step - loss: 0.1085 - dense_6_loss: 0.1124 - dense_8_loss: 0.0928 - dense_6_acc: 0.9689 - dense_8_acc: 0.9731 - val_loss: 0.9895 - val_dense_6_loss: 0.9912 - val_dense_8_loss: 0.9829 - val_dense_6_acc: 0.7207 - val_dense_8_acc: 0.7195\n",
      "\n",
      "Epoch 00036: val_dense_6_acc did not improve from 0.72439\n",
      "Epoch 37/50\n",
      "3276/3276 [==============================] - 14s 4ms/step - loss: 0.0985 - dense_6_loss: 0.1015 - dense_8_loss: 0.0864 - dense_6_acc: 0.9701 - dense_8_acc: 0.9719 - val_loss: 1.0584 - val_dense_6_loss: 1.0591 - val_dense_8_loss: 1.0555 - val_dense_6_acc: 0.7024 - val_dense_8_acc: 0.7085\n",
      "\n",
      "Epoch 00037: val_dense_6_acc did not improve from 0.72439\n",
      "Epoch 38/50\n",
      "3276/3276 [==============================] - 15s 4ms/step - loss: 0.0934 - dense_6_loss: 0.0969 - dense_8_loss: 0.0796 - dense_6_acc: 0.9716 - dense_8_acc: 0.9795 - val_loss: 1.0689 - val_dense_6_loss: 1.0694 - val_dense_8_loss: 1.0671 - val_dense_6_acc: 0.7268 - val_dense_8_acc: 0.7268\n",
      "\n",
      "Epoch 00038: val_dense_6_acc improved from 0.72439 to 0.72683, saving model to ./models/38-0.7268.h5\n",
      "Epoch 39/50\n",
      "3276/3276 [==============================] - 15s 5ms/step - loss: 0.1297 - dense_6_loss: 0.1335 - dense_8_loss: 0.1145 - dense_6_acc: 0.9585 - dense_8_acc: 0.9631 - val_loss: 1.0053 - val_dense_6_loss: 1.0059 - val_dense_8_loss: 1.0027 - val_dense_6_acc: 0.7073 - val_dense_8_acc: 0.7098\n",
      "\n",
      "Epoch 00039: val_dense_6_acc did not improve from 0.72683\n",
      "Epoch 40/50\n",
      "3276/3276 [==============================] - 14s 4ms/step - loss: 0.0919 - dense_6_loss: 0.0952 - dense_8_loss: 0.0787 - dense_6_acc: 0.9722 - dense_8_acc: 0.9759 - val_loss: 1.1097 - val_dense_6_loss: 1.1124 - val_dense_8_loss: 1.0991 - val_dense_6_acc: 0.7146 - val_dense_8_acc: 0.7134\n",
      "\n",
      "Epoch 00040: val_dense_6_acc did not improve from 0.72683\n",
      "Epoch 41/50\n",
      "3276/3276 [==============================] - 14s 4ms/step - loss: 0.1598 - dense_6_loss: 0.1620 - dense_8_loss: 0.1511 - dense_6_acc: 0.9515 - dense_8_acc: 0.9536 - val_loss: 1.0560 - val_dense_6_loss: 1.0587 - val_dense_8_loss: 1.0449 - val_dense_6_acc: 0.6939 - val_dense_8_acc: 0.6963\n",
      "\n",
      "Epoch 00041: val_dense_6_acc did not improve from 0.72683\n",
      "Epoch 42/50\n",
      "3276/3276 [==============================] - 15s 4ms/step - loss: 0.0701 - dense_6_loss: 0.0723 - dense_8_loss: 0.0609 - dense_6_acc: 0.9753 - dense_8_acc: 0.9802 - val_loss: 1.0322 - val_dense_6_loss: 1.0365 - val_dense_8_loss: 1.0152 - val_dense_6_acc: 0.7122 - val_dense_8_acc: 0.7183\n",
      "\n",
      "Epoch 00042: val_dense_6_acc did not improve from 0.72683\n",
      "Epoch 43/50\n",
      "3276/3276 [==============================] - 14s 4ms/step - loss: 0.0732 - dense_6_loss: 0.0756 - dense_8_loss: 0.0634 - dense_6_acc: 0.9765 - dense_8_acc: 0.9805 - val_loss: 1.1846 - val_dense_6_loss: 1.1922 - val_dense_8_loss: 1.1544 - val_dense_6_acc: 0.7110 - val_dense_8_acc: 0.7085\n",
      "\n",
      "Epoch 00043: val_dense_6_acc did not improve from 0.72683\n",
      "Epoch 44/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3276/3276 [==============================] - 14s 4ms/step - loss: 0.0793 - dense_6_loss: 0.0815 - dense_8_loss: 0.0707 - dense_6_acc: 0.9762 - dense_8_acc: 0.9789 - val_loss: 1.1060 - val_dense_6_loss: 1.1117 - val_dense_8_loss: 1.0829 - val_dense_6_acc: 0.7146 - val_dense_8_acc: 0.7171\n",
      "\n",
      "Epoch 00044: val_dense_6_acc did not improve from 0.72683\n",
      "Epoch 45/50\n",
      "3276/3276 [==============================] - 15s 4ms/step - loss: 0.0933 - dense_6_loss: 0.0963 - dense_8_loss: 0.0816 - dense_6_acc: 0.9750 - dense_8_acc: 0.9744 - val_loss: 1.1668 - val_dense_6_loss: 1.1714 - val_dense_8_loss: 1.1485 - val_dense_6_acc: 0.6768 - val_dense_8_acc: 0.6720\n",
      "\n",
      "Epoch 00045: val_dense_6_acc did not improve from 0.72683\n",
      "Epoch 46/50\n",
      "3276/3276 [==============================] - 15s 4ms/step - loss: 0.0984 - dense_6_loss: 0.1009 - dense_8_loss: 0.0882 - dense_6_acc: 0.9713 - dense_8_acc: 0.9716 - val_loss: 0.9817 - val_dense_6_loss: 0.9850 - val_dense_8_loss: 0.9687 - val_dense_6_acc: 0.7463 - val_dense_8_acc: 0.7476\n",
      "\n",
      "Epoch 00046: val_dense_6_acc improved from 0.72683 to 0.74634, saving model to ./models/46-0.7463.h5\n",
      "Epoch 47/50\n",
      "3276/3276 [==============================] - 15s 5ms/step - loss: 0.0676 - dense_6_loss: 0.0701 - dense_8_loss: 0.0577 - dense_6_acc: 0.9811 - dense_8_acc: 0.9844 - val_loss: 1.2224 - val_dense_6_loss: 1.2259 - val_dense_8_loss: 1.2085 - val_dense_6_acc: 0.6963 - val_dense_8_acc: 0.6902\n",
      "\n",
      "Epoch 00047: val_dense_6_acc did not improve from 0.74634\n",
      "Epoch 48/50\n",
      "3276/3276 [==============================] - 15s 5ms/step - loss: 0.0883 - dense_6_loss: 0.0909 - dense_8_loss: 0.0780 - dense_6_acc: 0.9750 - dense_8_acc: 0.9768 - val_loss: 1.0823 - val_dense_6_loss: 1.0850 - val_dense_8_loss: 1.0715 - val_dense_6_acc: 0.7098 - val_dense_8_acc: 0.7085\n",
      "\n",
      "Epoch 00048: val_dense_6_acc did not improve from 0.74634\n",
      "Epoch 49/50\n",
      "3276/3276 [==============================] - 15s 4ms/step - loss: 0.1019 - dense_6_loss: 0.1044 - dense_8_loss: 0.0919 - dense_6_acc: 0.9713 - dense_8_acc: 0.9725 - val_loss: 1.0712 - val_dense_6_loss: 1.0769 - val_dense_8_loss: 1.0485 - val_dense_6_acc: 0.7134 - val_dense_8_acc: 0.7085\n",
      "\n",
      "Epoch 00049: val_dense_6_acc did not improve from 0.74634\n",
      "Epoch 50/50\n",
      "3276/3276 [==============================] - 15s 5ms/step - loss: 0.0703 - dense_6_loss: 0.0727 - dense_8_loss: 0.0608 - dense_6_acc: 0.9808 - dense_8_acc: 0.9811 - val_loss: 1.1018 - val_dense_6_loss: 1.1056 - val_dense_8_loss: 1.0864 - val_dense_6_acc: 0.7256 - val_dense_8_acc: 0.7195\n",
      "\n",
      "Epoch 00050: val_dense_6_acc did not improve from 0.74634\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam', metrics = ['accuracy'], loss = 'categorical_crossentropy', \n",
    "              loss_weights = [0.8, 0.2])\n",
    "history = model.fit([x1_train, x1_letter_train, x2_train, x2_letter_train], [y1_train, y2_train],\n",
    "                    validation_data=([x1_val, x1_letter_val, x2_val, x2_letter_val], [y1_val, y2_val]), \n",
    "                    batch_size=64, epochs=50, verbose=1, \n",
    "                    callbacks = [ModelCheckpoint('./models/{epoch:02d}-{val_dense_6_acc:.4f}.h5',\n",
    "                    monitor='val_dense_6_acc', verbose=1, save_best_only=True, mode='auto')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T07:36:49.152762Z",
     "start_time": "2020-08-18T07:36:38.084416Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "best_model = load_model('./models/46-0.7463.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T07:38:02.128331Z",
     "start_time": "2020-08-18T07:36:49.152762Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 5 2 ... 6 9 0]\n",
      "[6 0 2 ... 6 9 0]\n"
     ]
    }
   ],
   "source": [
    "x1_test = test.drop(['id', 'letter'], axis=1).values\n",
    "x1_test = x1_test.reshape(-1, 28, 28, 1)\n",
    "x1_test = x1_test/255\n",
    "\n",
    "x2_test = test.drop(['id', 'letter'], axis=1).values\n",
    "x2_test = x2_test.reshape(-1, 28, 28)\n",
    "x2_test = x2_test/255\n",
    "\n",
    "x1_letter_test = test['letter'].values\n",
    "x1_letter_test = x1_letter_test[:, np.newaxis]\n",
    "en = OneHotEncoder()\n",
    "x1_letter_test = en.fit_transform(x1_letter_test).toarray()\n",
    "\n",
    "x2_letter_test = x1_letter_test.copy()\n",
    "\n",
    "y1_test, y2_test = best_model.predict([x1_test, x1_letter_test, x2_test, x2_letter_test])\n",
    "y_1 = np.argmax(y1_test, axis=1)\n",
    "y_2 = np.argmax(y2_test, axis=1)\n",
    "print(y_1)\n",
    "print(y_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T07:38:02.146496Z",
     "start_time": "2020-08-18T07:38:02.130830Z"
    }
   },
   "outputs": [],
   "source": [
    "#submission = pd.read_csv('data/submission.csv')\n",
    "#submission['digit'] = y_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T07:38:02.194415Z",
     "start_time": "2020-08-18T07:38:02.146496Z"
    }
   },
   "outputs": [],
   "source": [
    "#submission.to_csv('data/submission(val7463).csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T07:30:05.646912Z",
     "start_time": "2020-08-18T07:30:05.631287Z"
    }
   },
   "outputs": [],
   "source": [
    "#submission['digit'] = y_2\n",
    "#submission.to_csv('data/submission2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

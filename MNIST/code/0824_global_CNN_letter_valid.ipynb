{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-24T02:44:16.818592Z",
     "start_time": "2020-08-24T02:44:13.720534Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.layers import concatenate, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, AveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# seed\n",
    "import os\n",
    "seed = 123\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-24T02:44:18.459590Z",
     "start_time": "2020-08-24T02:44:16.818592Z"
    }
   },
   "outputs": [],
   "source": [
    "train = np.load('data/train.npy', allow_pickle = 'True')\n",
    "test = np.load('data/test.npy', allow_pickle = 'True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-24T02:44:18.570400Z",
     "start_time": "2020-08-24T02:44:18.459590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2048, 28, 28, 1)\n",
      "(2048, 26)\n",
      "(2048, 10)\n"
     ]
    }
   ],
   "source": [
    "x = train[:,2:]\n",
    "x = np.reshape(x, (-1, 28, 28, 1))\n",
    "x = x/255\n",
    "\n",
    "y_letter = train[:,1]\n",
    "y_letter = np.reshape(y_letter, (-1, 1))\n",
    "en = OneHotEncoder()\n",
    "y_letter = en.fit_transform(y_letter).toarray()\n",
    "\n",
    "y = train[:,0]\n",
    "y = np.reshape(y, (-1, 1))\n",
    "en = OneHotEncoder()\n",
    "y = en.fit_transform(y).toarray()\n",
    "\n",
    "print(x.shape)\n",
    "print(y_letter.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-24T02:44:18.602307Z",
     "start_time": "2020-08-24T02:44:18.575379Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 28, 28, 1)\n",
      "(48, 28, 28, 1)\n",
      "(2000, 26)\n",
      "(48, 26)\n",
      "(2000, 10)\n",
      "(48, 10)\n"
     ]
    }
   ],
   "source": [
    "valid_size = 48\n",
    "valid_x = x[-valid_size:]\n",
    "x = x[:-48]\n",
    "\n",
    "valid_y_letter = y_letter[-valid_size:]\n",
    "y_letter = y_letter[:-48]\n",
    "\n",
    "valid_y = y[-valid_size:]\n",
    "y = y[:-48]\n",
    "\n",
    "print(x.shape)\n",
    "print(valid_x.shape)\n",
    "print(y_letter.shape)\n",
    "print(valid_y_letter.shape)\n",
    "print(y.shape)\n",
    "print(valid_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-24T02:44:18.618233Z",
     "start_time": "2020-08-24T02:44:18.606248Z"
    }
   },
   "outputs": [],
   "source": [
    "image_generator = ImageDataGenerator(width_shift_range=0.1,\n",
    "                                     height_shift_range=0.1, \n",
    "                                     zoom_range=[0.8,1.2],\n",
    "                                     shear_range=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-24T02:44:21.224360Z",
     "start_time": "2020-08-24T02:44:18.621272Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "x_total = x.copy()\n",
    "def augment(x):\n",
    "    aug_list = []\n",
    "    for i in range(x.shape[0]):\n",
    "        num_aug = 0\n",
    "        tmp = x[i]\n",
    "        tmp = tmp.reshape((1,) + tmp.shape)\n",
    "        for x_aug in image_generator.flow(tmp, batch_size = 1) :\n",
    "            if num_aug >= 1:\n",
    "                break\n",
    "            aug_list.append(x_aug[0])\n",
    "            num_aug += 1\n",
    "    aug_list = np.array(aug_list)\n",
    "    return aug_list\n",
    "\n",
    "n = 2\n",
    "for i in range(n):\n",
    "    arr = augment(x)\n",
    "    x_total = np.concatenate((x_total, arr), axis=0)\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "print(x_total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-24T02:44:21.240297Z",
     "start_time": "2020-08-24T02:44:21.227348Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 10)\n"
     ]
    }
   ],
   "source": [
    "y_total = y.copy()\n",
    "for i in range(n):\n",
    "    arr = y.copy()\n",
    "    y_total = np.concatenate((y_total, arr), axis=0)\n",
    "\n",
    "print(y_total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-24T02:44:21.256227Z",
     "start_time": "2020-08-24T02:44:21.243281Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 26)\n"
     ]
    }
   ],
   "source": [
    "y_letter_total = y_letter.copy()\n",
    "for i in range(n):\n",
    "    arr = y_letter.copy()\n",
    "    y_letter_total = np.concatenate((y_letter_total, arr), axis=0)\n",
    "    \n",
    "print(y_letter_total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-24T02:44:21.335550Z",
     "start_time": "2020-08-24T02:44:21.260250Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4800, 28, 28, 1)\n",
      "(1200, 28, 28, 1)\n",
      "(4800, 10)\n",
      "(1200, 10)\n",
      "(4800, 26)\n",
      "(1200, 26)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_total, y_total, test_size=0.2, shuffle=True)#, stratify=y_total)\n",
    "y_letter_train = y_letter_total[:x_train.shape[0],:]\n",
    "y_letter_val = y_letter_total[x_train.shape[0]:,:]\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)\n",
    "print(y_letter_train.shape)\n",
    "print(y_letter_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-24T02:44:21.584805Z",
     "start_time": "2020-08-24T02:44:21.337549Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 28, 28, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 64)        16448     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 64)        16448     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 7, 7, 128)         32896     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 7, 7, 64)          32832     \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 26)                1690      \n",
      "=================================================================\n",
      "Total params: 137,882\n",
      "Trainable params: 137,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input1 = Input(shape=(28,28,1))\n",
    "x1 = Conv2D(64, (3,3), activation='relu', padding='same')(input1)\n",
    "x1 = Conv2D(64, (3,3), activation='relu', padding='same')(x1)\n",
    "#x1 = Dropout(0.3)(x1)\n",
    "x1 = MaxPooling2D((2,2))(x1)\n",
    "x1 = Conv2D(64, (2,2), activation='relu', padding='same')(x1)\n",
    "x1 = Conv2D(64, (2,2), activation='relu', padding='same')(x1)\n",
    "#x1 = Dropout(0.3)(x1)\n",
    "x1 = MaxPooling2D((2,2))(x1)\n",
    "x1 = Conv2D(128, (2,2), activation='relu', padding='same')(x1)\n",
    "x1 = Conv2D(64, (2,2), activation='relu', padding='same')(x1)\n",
    "#x1 = Dropout(0.3)(x1)\n",
    "x1 = GlobalAveragePooling2D()(x1)\n",
    "outputs = Dense(26, activation='softmax')(x1)\n",
    "\n",
    "model = Model(inputs = input1, outputs = outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-24T02:47:15.821560Z",
     "start_time": "2020-08-24T02:44:21.586803Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800 samples, validate on 1200 samples\n",
      "Epoch 1/100\n",
      "4800/4800 [==============================] - 5s 1ms/step - loss: 3.2576 - acc: 0.0331 - val_loss: 3.2551 - val_acc: 0.0442\n",
      "Epoch 2/100\n",
      "4800/4800 [==============================] - 2s 365us/step - loss: 3.2554 - acc: 0.0402 - val_loss: 3.2542 - val_acc: 0.0458\n",
      "Epoch 3/100\n",
      "4800/4800 [==============================] - 2s 376us/step - loss: 3.2544 - acc: 0.0435 - val_loss: 3.2540 - val_acc: 0.0458\n",
      "Epoch 4/100\n",
      "4800/4800 [==============================] - 2s 381us/step - loss: 3.2536 - acc: 0.0435 - val_loss: 3.2536 - val_acc: 0.0458\n",
      "Epoch 5/100\n",
      "4800/4800 [==============================] - 2s 357us/step - loss: 3.2535 - acc: 0.0396 - val_loss: 3.2536 - val_acc: 0.0458\n",
      "Epoch 6/100\n",
      "4800/4800 [==============================] - 2s 364us/step - loss: 3.2539 - acc: 0.0427 - val_loss: 3.2539 - val_acc: 0.0442\n",
      "Epoch 7/100\n",
      "4800/4800 [==============================] - 2s 378us/step - loss: 3.2532 - acc: 0.0423 - val_loss: 3.2536 - val_acc: 0.0442\n",
      "Epoch 8/100\n",
      "4800/4800 [==============================] - 2s 371us/step - loss: 3.2531 - acc: 0.0419 - val_loss: 3.2539 - val_acc: 0.0450\n",
      "Epoch 9/100\n",
      "4800/4800 [==============================] - 2s 374us/step - loss: 3.2533 - acc: 0.0404 - val_loss: 3.2538 - val_acc: 0.0442\n",
      "Epoch 10/100\n",
      "4800/4800 [==============================] - 2s 381us/step - loss: 3.2531 - acc: 0.0440 - val_loss: 3.2541 - val_acc: 0.0442\n",
      "Epoch 11/100\n",
      "4800/4800 [==============================] - 2s 368us/step - loss: 3.2531 - acc: 0.0427 - val_loss: 3.2540 - val_acc: 0.0442\n",
      "Epoch 12/100\n",
      "4800/4800 [==============================] - 2s 374us/step - loss: 3.2529 - acc: 0.0421 - val_loss: 3.2541 - val_acc: 0.0442\n",
      "Epoch 13/100\n",
      "4800/4800 [==============================] - 2s 374us/step - loss: 3.2530 - acc: 0.0435 - val_loss: 3.2539 - val_acc: 0.0450\n",
      "Epoch 14/100\n",
      "4800/4800 [==============================] - 2s 378us/step - loss: 3.2530 - acc: 0.0412 - val_loss: 3.2542 - val_acc: 0.0442\n",
      "Epoch 15/100\n",
      "4800/4800 [==============================] - 2s 374us/step - loss: 3.2530 - acc: 0.0433 - val_loss: 3.2538 - val_acc: 0.0458\n",
      "Epoch 16/100\n",
      "4800/4800 [==============================] - 2s 374us/step - loss: 3.2531 - acc: 0.0450 - val_loss: 3.2540 - val_acc: 0.0442\n",
      "Epoch 17/100\n",
      "4800/4800 [==============================] - 2s 371us/step - loss: 3.2533 - acc: 0.0402 - val_loss: 3.2540 - val_acc: 0.0442\n",
      "Epoch 18/100\n",
      "4800/4800 [==============================] - 2s 371us/step - loss: 3.2528 - acc: 0.0440 - val_loss: 3.2539 - val_acc: 0.0442\n",
      "Epoch 19/100\n",
      "4800/4800 [==============================] - 2s 374us/step - loss: 3.2530 - acc: 0.0446 - val_loss: 3.2541 - val_acc: 0.0442\n",
      "Epoch 20/100\n",
      "4800/4800 [==============================] - 2s 378us/step - loss: 3.2527 - acc: 0.0404 - val_loss: 3.2541 - val_acc: 0.0483\n",
      "Epoch 21/100\n",
      "4800/4800 [==============================] - 2s 368us/step - loss: 3.2529 - acc: 0.0435 - val_loss: 3.2539 - val_acc: 0.0450\n",
      "Epoch 22/100\n",
      "4800/4800 [==============================] - 2s 368us/step - loss: 3.2528 - acc: 0.0375 - val_loss: 3.2539 - val_acc: 0.0442\n",
      "Epoch 23/100\n",
      "4800/4800 [==============================] - 2s 381us/step - loss: 3.2530 - acc: 0.0402 - val_loss: 3.2540 - val_acc: 0.0375\n",
      "Epoch 24/100\n",
      "4800/4800 [==============================] - 2s 371us/step - loss: 3.2527 - acc: 0.0398 - val_loss: 3.2542 - val_acc: 0.0442\n",
      "Epoch 25/100\n",
      "4800/4800 [==============================] - 2s 368us/step - loss: 3.2528 - acc: 0.0410 - val_loss: 3.2540 - val_acc: 0.0375\n",
      "Epoch 26/100\n",
      "4800/4800 [==============================] - 2s 368us/step - loss: 3.2527 - acc: 0.0435 - val_loss: 3.2542 - val_acc: 0.0442\n",
      "Epoch 27/100\n",
      "4800/4800 [==============================] - 2s 361us/step - loss: 3.2528 - acc: 0.0435 - val_loss: 3.2541 - val_acc: 0.0442\n",
      "Epoch 28/100\n",
      "4800/4800 [==============================] - 2s 368us/step - loss: 3.2529 - acc: 0.0427 - val_loss: 3.2541 - val_acc: 0.0442\n",
      "Epoch 29/100\n",
      "4800/4800 [==============================] - 2s 368us/step - loss: 3.2529 - acc: 0.0394 - val_loss: 3.2540 - val_acc: 0.0450\n",
      "Epoch 30/100\n",
      "4800/4800 [==============================] - 2s 365us/step - loss: 3.2525 - acc: 0.0435 - val_loss: 3.2552 - val_acc: 0.0450\n",
      "Epoch 31/100\n",
      "4800/4800 [==============================] - 2s 374us/step - loss: 3.2527 - acc: 0.0423 - val_loss: 3.2540 - val_acc: 0.0458\n",
      "Epoch 32/100\n",
      "4800/4800 [==============================] - 2s 368us/step - loss: 3.2526 - acc: 0.0427 - val_loss: 3.2540 - val_acc: 0.0450\n",
      "Epoch 33/100\n",
      "4800/4800 [==============================] - 2s 381us/step - loss: 3.2525 - acc: 0.0423 - val_loss: 3.2541 - val_acc: 0.0350\n",
      "Epoch 34/100\n",
      "4800/4800 [==============================] - 2s 371us/step - loss: 3.2521 - acc: 0.0440 - val_loss: 3.2540 - val_acc: 0.0517\n",
      "Epoch 35/100\n",
      "4800/4800 [==============================] - 2s 378us/step - loss: 3.2513 - acc: 0.0433 - val_loss: 3.2558 - val_acc: 0.0392\n",
      "Epoch 36/100\n",
      "4800/4800 [==============================] - 2s 365us/step - loss: 3.2508 - acc: 0.0460 - val_loss: 3.2543 - val_acc: 0.0475\n",
      "Epoch 37/100\n",
      "4800/4800 [==============================] - 2s 361us/step - loss: 3.2507 - acc: 0.0446 - val_loss: 3.2543 - val_acc: 0.0500\n",
      "Epoch 38/100\n",
      "4800/4800 [==============================] - 2s 355us/step - loss: 3.2501 - acc: 0.0467 - val_loss: 3.2554 - val_acc: 0.0425\n",
      "Epoch 39/100\n",
      "4800/4800 [==============================] - 2s 358us/step - loss: 3.2477 - acc: 0.0498 - val_loss: 3.2563 - val_acc: 0.0458\n",
      "Epoch 40/100\n",
      "4800/4800 [==============================] - 2s 374us/step - loss: 3.2465 - acc: 0.0469 - val_loss: 3.2584 - val_acc: 0.0425\n",
      "Epoch 41/100\n",
      "4800/4800 [==============================] - 2s 368us/step - loss: 3.2438 - acc: 0.0508 - val_loss: 3.2684 - val_acc: 0.0433\n",
      "Epoch 42/100\n",
      "4800/4800 [==============================] - 2s 368us/step - loss: 3.2422 - acc: 0.0496 - val_loss: 3.2597 - val_acc: 0.0433\n",
      "Epoch 43/100\n",
      "4800/4800 [==============================] - 2s 365us/step - loss: 3.2390 - acc: 0.0527 - val_loss: 3.2717 - val_acc: 0.0375\n",
      "Epoch 44/100\n",
      "4800/4800 [==============================] - 2s 374us/step - loss: 3.2370 - acc: 0.0517 - val_loss: 3.2762 - val_acc: 0.0450\n",
      "Epoch 45/100\n",
      "4800/4800 [==============================] - 2s 355us/step - loss: 3.2341 - acc: 0.0563 - val_loss: 3.2675 - val_acc: 0.0400\n",
      "Epoch 46/100\n",
      "4800/4800 [==============================] - 2s 378us/step - loss: 3.2300 - acc: 0.0531 - val_loss: 3.2773 - val_acc: 0.0400\n",
      "Epoch 47/100\n",
      "4800/4800 [==============================] - 2s 371us/step - loss: 3.2269 - acc: 0.0592 - val_loss: 3.2830 - val_acc: 0.0392\n",
      "Epoch 48/100\n",
      "4800/4800 [==============================] - 2s 365us/step - loss: 3.2206 - acc: 0.0617 - val_loss: 3.2925 - val_acc: 0.0417\n",
      "Epoch 49/100\n",
      "4800/4800 [==============================] - 2s 368us/step - loss: 3.2162 - acc: 0.0571 - val_loss: 3.3004 - val_acc: 0.0425\n",
      "Epoch 50/100\n",
      "4800/4800 [==============================] - 2s 345us/step - loss: 3.2116 - acc: 0.0685 - val_loss: 3.3039 - val_acc: 0.0333\n",
      "Epoch 51/100\n",
      "4800/4800 [==============================] - 2s 352us/step - loss: 3.1953 - acc: 0.0750 - val_loss: 3.3337 - val_acc: 0.0342\n",
      "Epoch 52/100\n",
      "4800/4800 [==============================] - 2s 340us/step - loss: 3.1790 - acc: 0.0752 - val_loss: 3.3476 - val_acc: 0.0333\n",
      "Epoch 53/100\n",
      "4800/4800 [==============================] - 2s 359us/step - loss: 3.1591 - acc: 0.0840 - val_loss: 3.3463 - val_acc: 0.0392\n",
      "Epoch 54/100\n",
      "4800/4800 [==============================] - 2s 345us/step - loss: 3.1323 - acc: 0.0921 - val_loss: 3.3877 - val_acc: 0.0292\n",
      "Epoch 55/100\n",
      "4800/4800 [==============================] - 2s 354us/step - loss: 3.1010 - acc: 0.1008 - val_loss: 3.3835 - val_acc: 0.0408\n",
      "Epoch 56/100\n",
      "4800/4800 [==============================] - 2s 353us/step - loss: 3.0589 - acc: 0.1179 - val_loss: 3.4250 - val_acc: 0.0367\n",
      "Epoch 57/100\n",
      "4800/4800 [==============================] - 2s 361us/step - loss: 2.9881 - acc: 0.1385 - val_loss: 3.4784 - val_acc: 0.0333\n",
      "Epoch 58/100\n",
      "4800/4800 [==============================] - 2s 351us/step - loss: 2.9074 - acc: 0.1571 - val_loss: 3.5605 - val_acc: 0.0358\n",
      "Epoch 59/100\n",
      "4800/4800 [==============================] - 2s 346us/step - loss: 2.7852 - acc: 0.2006 - val_loss: 3.6464 - val_acc: 0.0400\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4800/4800 [==============================] - 2s 378us/step - loss: 2.7017 - acc: 0.2217 - val_loss: 3.7879 - val_acc: 0.0458\n",
      "Epoch 61/100\n",
      "4800/4800 [==============================] - 2s 371us/step - loss: 2.5364 - acc: 0.2646 - val_loss: 3.8993 - val_acc: 0.0325\n",
      "Epoch 62/100\n",
      "4800/4800 [==============================] - 2s 374us/step - loss: 2.3871 - acc: 0.3015 - val_loss: 4.1148 - val_acc: 0.0367\n",
      "Epoch 63/100\n",
      "4800/4800 [==============================] - 2s 371us/step - loss: 2.2013 - acc: 0.3598 - val_loss: 4.3100 - val_acc: 0.0367\n",
      "Epoch 64/100\n",
      "4800/4800 [==============================] - 2s 374us/step - loss: 2.0028 - acc: 0.4217 - val_loss: 4.5673 - val_acc: 0.0333\n",
      "Epoch 65/100\n",
      "4800/4800 [==============================] - 2s 381us/step - loss: 1.8105 - acc: 0.4658 - val_loss: 4.9356 - val_acc: 0.0350\n",
      "Epoch 66/100\n",
      "4800/4800 [==============================] - 2s 371us/step - loss: 1.5981 - acc: 0.5354 - val_loss: 5.2252 - val_acc: 0.0425\n",
      "Epoch 67/100\n",
      "4800/4800 [==============================] - 2s 362us/step - loss: 1.3963 - acc: 0.5896 - val_loss: 5.7016 - val_acc: 0.0375\n",
      "Epoch 68/100\n",
      "4800/4800 [==============================] - 2s 358us/step - loss: 1.2227 - acc: 0.6458 - val_loss: 6.1001 - val_acc: 0.0300\n",
      "Epoch 69/100\n",
      "4800/4800 [==============================] - 2s 365us/step - loss: 1.0671 - acc: 0.6879 - val_loss: 6.3117 - val_acc: 0.0333\n",
      "Epoch 70/100\n",
      "4800/4800 [==============================] - 2s 361us/step - loss: 0.8884 - acc: 0.7377 - val_loss: 7.0074 - val_acc: 0.0350\n",
      "Epoch 71/100\n",
      "4800/4800 [==============================] - 2s 371us/step - loss: 0.7282 - acc: 0.7975 - val_loss: 7.5030 - val_acc: 0.0375\n",
      "Epoch 72/100\n",
      "4800/4800 [==============================] - 2s 371us/step - loss: 0.6333 - acc: 0.8181 - val_loss: 7.8368 - val_acc: 0.0408\n",
      "Epoch 73/100\n",
      "4800/4800 [==============================] - 2s 368us/step - loss: 0.4749 - acc: 0.8700 - val_loss: 8.2800 - val_acc: 0.0350\n",
      "Epoch 74/100\n",
      "4800/4800 [==============================] - 2s 368us/step - loss: 0.3707 - acc: 0.9048 - val_loss: 8.7702 - val_acc: 0.0358\n",
      "Epoch 75/100\n",
      "4800/4800 [==============================] - 2s 365us/step - loss: 0.2831 - acc: 0.9302 - val_loss: 9.3377 - val_acc: 0.0350\n",
      "Epoch 76/100\n",
      "4800/4800 [==============================] - 2s 358us/step - loss: 0.2205 - acc: 0.9521 - val_loss: 9.7996 - val_acc: 0.0375\n",
      "Epoch 77/100\n",
      "4800/4800 [==============================] - 2s 367us/step - loss: 0.1726 - acc: 0.9650 - val_loss: 10.0933 - val_acc: 0.0383\n",
      "Epoch 78/100\n",
      "4800/4800 [==============================] - 2s 349us/step - loss: 0.1511 - acc: 0.9700 - val_loss: 10.3857 - val_acc: 0.0475\n",
      "Epoch 79/100\n",
      "4800/4800 [==============================] - 2s 358us/step - loss: 0.0904 - acc: 0.9883 - val_loss: 10.6913 - val_acc: 0.0400\n",
      "Epoch 80/100\n",
      "4800/4800 [==============================] - 2s 358us/step - loss: 0.0482 - acc: 0.9960 - val_loss: 10.8922 - val_acc: 0.0433\n",
      "Epoch 81/100\n",
      "4800/4800 [==============================] - 2s 365us/step - loss: 0.0298 - acc: 0.9992 - val_loss: 11.2036 - val_acc: 0.0400\n",
      "Epoch 82/100\n",
      "4800/4800 [==============================] - 2s 365us/step - loss: 0.0183 - acc: 1.0000 - val_loss: 11.4168 - val_acc: 0.0408\n",
      "Epoch 83/100\n",
      "4800/4800 [==============================] - 2s 358us/step - loss: 0.0133 - acc: 1.0000 - val_loss: 11.5719 - val_acc: 0.0400\n",
      "Epoch 84/100\n",
      "4800/4800 [==============================] - 2s 368us/step - loss: 0.0106 - acc: 1.0000 - val_loss: 11.7122 - val_acc: 0.0400\n",
      "Epoch 85/100\n",
      "4800/4800 [==============================] - 2s 361us/step - loss: 0.0087 - acc: 1.0000 - val_loss: 11.8108 - val_acc: 0.0408\n",
      "Epoch 86/100\n",
      "4800/4800 [==============================] - 2s 371us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 11.8911 - val_acc: 0.0400\n",
      "Epoch 87/100\n",
      "4800/4800 [==============================] - 2s 358us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 11.9752 - val_acc: 0.0392\n",
      "Epoch 88/100\n",
      "4800/4800 [==============================] - 2s 358us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 12.0461 - val_acc: 0.0433\n",
      "Epoch 89/100\n",
      "4800/4800 [==============================] - 2s 365us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 12.1239 - val_acc: 0.0417\n",
      "Epoch 90/100\n",
      "4800/4800 [==============================] - 2s 365us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 12.1823 - val_acc: 0.0392\n",
      "Epoch 91/100\n",
      "4800/4800 [==============================] - 2s 365us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 12.2272 - val_acc: 0.0425\n",
      "Epoch 92/100\n",
      "4800/4800 [==============================] - 2s 371us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 12.2880 - val_acc: 0.0408\n",
      "Epoch 93/100\n",
      "4800/4800 [==============================] - 2s 374us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 12.3286 - val_acc: 0.0383\n",
      "Epoch 94/100\n",
      "4800/4800 [==============================] - 2s 355us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 12.3790 - val_acc: 0.0392\n",
      "Epoch 95/100\n",
      "4800/4800 [==============================] - 2s 338us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 12.4233 - val_acc: 0.0383\n",
      "Epoch 96/100\n",
      "4800/4800 [==============================] - 2s 358us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 12.4568 - val_acc: 0.0400\n",
      "Epoch 97/100\n",
      " 448/4800 [=>............................] - ETA: 1s - loss: 0.0021 - acc: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-c41b2dc494e3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m history = model.fit(x_train, y_letter_train,\n\u001b[0;32m      8\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_letter_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m                     batch_size=64, epochs=100, verbose=1, callbacks = [cp])\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1346\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m           validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1350\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    251\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 253\u001b[1;33m         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m           \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2895\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_arrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_symbols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m     \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2899\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1449\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[1;32m-> 1451\u001b[1;33m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[0;32m   1452\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam', metrics = ['accuracy'], loss = 'categorical_crossentropy')\n",
    "\n",
    "#es = EarlyStopping(monitor='val_loss', patience=20, mode='min', verbose=1)\n",
    "cp = ModelCheckpoint('./models/{epoch:02d}-{val_acc:.4f}.h5', monitor='val_loss',\n",
    "                     save_best_only=True, mode='min')\n",
    "\n",
    "history = model.fit(x_train, y_letter_train,\n",
    "                    validation_data=(x_val, y_letter_val), \n",
    "                    batch_size=64, epochs=100, verbose=1, callbacks = [cp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-24T02:47:15.827493Z",
     "start_time": "2020-08-24T02:44:13.735Z"
    }
   },
   "outputs": [],
   "source": [
    "#from tensorflow.keras.models import load_model\n",
    "#best_model = load_model('models/DenseNet121.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-24T02:47:15.829524Z",
     "start_time": "2020-08-24T02:44:13.736Z"
    }
   },
   "outputs": [],
   "source": [
    "#evaluate = best_model.evaluate(valid_x, valid_y_letter)\n",
    "#evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-24T02:47:15.830481Z",
     "start_time": "2020-08-24T02:44:13.737Z"
    }
   },
   "outputs": [],
   "source": [
    "#submission = pd.read_csv('data/val.csv')\n",
    "#submission['digit'] = np.argmax(best_model.predict([x_test, x_letter_test]), axis=1)\n",
    "#submission.to_csv('data/val(CNN).csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T06:58:35.829084Z",
     "start_time": "2020-08-21T06:58:33.128826Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.layers import concatenate, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# seed\n",
    "import os\n",
    "seed = 123\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T06:58:37.469969Z",
     "start_time": "2020-08-21T06:58:35.829084Z"
    }
   },
   "outputs": [],
   "source": [
    "train = np.load('data/train.npy', allow_pickle = 'True')\n",
    "test = np.load('data/test.npy', allow_pickle = 'True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T06:58:37.497167Z",
     "start_time": "2020-08-21T06:58:37.469969Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2048, 28, 28, 1)\n",
      "(2048, 26)\n",
      "(2048, 10)\n"
     ]
    }
   ],
   "source": [
    "x = train[:,2:]\n",
    "x = np.reshape(x, (-1, 28, 28, 1))\n",
    "\n",
    "x_letter = train[:,1]\n",
    "x_letter = np.reshape(x_letter, (-1, 1))\n",
    "en = OneHotEncoder()\n",
    "x_letter = en.fit_transform(x_letter).toarray()\n",
    "\n",
    "y = train[:,0]\n",
    "y = np.reshape(y, (-1, 1))\n",
    "en = OneHotEncoder()\n",
    "y = en.fit_transform(y).toarray()\n",
    "\n",
    "print(x.shape)\n",
    "print(x_letter.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T06:58:37.516920Z",
     "start_time": "2020-08-21T06:58:37.501242Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 28, 28, 1)\n",
      "(48, 28, 28, 1)\n",
      "(2000, 26)\n",
      "(48, 26)\n",
      "(2000, 10)\n",
      "(48, 10)\n"
     ]
    }
   ],
   "source": [
    "valid_size = 48\n",
    "valid_x = x[-valid_size:]\n",
    "x = x[:-48]\n",
    "\n",
    "valid_x_letter = x_letter[-valid_size:]\n",
    "x_letter = x_letter[:-48]\n",
    "\n",
    "valid_y = y[-valid_size:]\n",
    "y = y[:-48]\n",
    "\n",
    "print(x.shape)\n",
    "print(valid_x.shape)\n",
    "print(x_letter.shape)\n",
    "print(valid_x_letter.shape)\n",
    "print(y.shape)\n",
    "print(valid_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T06:58:37.529222Z",
     "start_time": "2020-08-21T06:58:37.516920Z"
    }
   },
   "outputs": [],
   "source": [
    "image_generator = ImageDataGenerator(width_shift_range=0.1,\n",
    "                                     height_shift_range=0.1, \n",
    "                                     zoom_range=[0.8,1.2],\n",
    "                                     shear_range=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T06:58:39.793112Z",
     "start_time": "2020-08-21T06:58:37.532273Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "x_total = x.copy()\n",
    "def augment(x):\n",
    "    aug_list = []\n",
    "    for i in range(x.shape[0]):\n",
    "        num_aug = 0\n",
    "        tmp = x[i]\n",
    "        tmp = tmp.reshape((1,) + tmp.shape)\n",
    "        for x_aug in image_generator.flow(tmp, batch_size = 1) :\n",
    "            if num_aug >= 1:\n",
    "                break\n",
    "            aug_list.append(x_aug[0])\n",
    "            num_aug += 1\n",
    "    aug_list = np.array(aug_list)\n",
    "    return aug_list\n",
    "\n",
    "n = 2\n",
    "for i in range(n):\n",
    "    arr = augment(x)\n",
    "    x_total = np.concatenate((x_total, arr), axis=0)\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "print(x_total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T06:58:39.826108Z",
     "start_time": "2020-08-21T06:58:39.798366Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 10)\n"
     ]
    }
   ],
   "source": [
    "y_total = y.copy()\n",
    "for i in range(n):\n",
    "    arr = y.copy()\n",
    "    y_total = np.concatenate((y_total, arr), axis=0)\n",
    "\n",
    "print(y_total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T06:58:39.849447Z",
     "start_time": "2020-08-21T06:58:39.832563Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 26)\n"
     ]
    }
   ],
   "source": [
    "x_letter_total = x_letter.copy()\n",
    "for i in range(n):\n",
    "    arr = x_letter.copy()\n",
    "    x_letter_total = np.concatenate((x_letter_total, arr), axis=0)\n",
    "    \n",
    "print(x_letter_total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T06:58:39.888893Z",
     "start_time": "2020-08-21T06:58:39.849447Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4800, 28, 28, 1)\n",
      "(1200, 28, 28, 1)\n",
      "(4800, 10)\n",
      "(1200, 10)\n",
      "(4800, 26)\n",
      "(1200, 26)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_total, y_total, test_size=0.2, shuffle=True)#, stratify=y_total)\n",
    "x_letter_train = x_letter_total[:x_train.shape[0],:]\n",
    "x_letter_val = x_letter_total[x_train.shape[0]:,:]\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)\n",
    "print(x_letter_train.shape)\n",
    "print(x_letter_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T06:58:40.192451Z",
     "start_time": "2020-08-21T06:58:39.890884Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 28, 28, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 64)        16448     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 64)        16448     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 7, 7, 128)         32896     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 7, 7, 64)          32832     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 136,842\n",
      "Trainable params: 136,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input1 = Input(shape=(28,28,1))\n",
    "x1 = Conv2D(64, (3,3), activation='relu', padding='same')(input1)\n",
    "x1 = Conv2D(64, (3,3), activation='relu', padding='same')(x1)\n",
    "x1 = Dropout(0.3)(x1)\n",
    "x1 = MaxPooling2D((2,2))(x1)\n",
    "x1 = Conv2D(64, (2,2), activation='relu', padding='same')(x1)\n",
    "x1 = Conv2D(64, (2,2), activation='relu', padding='same')(x1)\n",
    "x1 = Dropout(0.3)(x1)\n",
    "x1 = MaxPooling2D((2,2))(x1)\n",
    "x1 = Conv2D(128, (2,2), activation='relu', padding='same')(x1)\n",
    "x1 = Conv2D(64, (2,2), activation='relu', padding='same')(x1)\n",
    "x1 = Dropout(0.3)(x1)\n",
    "x1 = GlobalAveragePooling2D()(x1)\n",
    "outputs = Dense(10, activation='softmax')(x1)\n",
    "#x1 = MaxPooling2D((2,2))(x1)\n",
    "#x1 = Flatten()(x1)\n",
    "\n",
    "#input2 = Input(shape=(26,))\n",
    "#x2 = Dense(50, activation='relu')(input2)\n",
    "#x2 = Dropout(0.3)(x2)\n",
    "\n",
    "#merge = concatenate([x1, input2])\n",
    "\n",
    "#x2 = Dense(500, activation='relu')(merge)\n",
    "#x2 = Dropout(0.3)(x2)\n",
    "#x2 = Dense(100, activation='relu')(x1)\n",
    "#x2 = Dropout(0.3)(x2)\n",
    "#x2 = Dense(50, activation='relu')(x2)\n",
    "#x2 = Dropout(0.3)(x2)\n",
    "#outputs = Dense(10, activation='softmax')(x2)\n",
    "\n",
    "model = Model(inputs = input1, outputs = outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T07:01:47.001025Z",
     "start_time": "2020-08-21T06:58:40.193589Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800 samples, validate on 1200 samples\n",
      "Epoch 1/100\n",
      "4800/4800 [==============================] - 5s 1ms/step - loss: 2.4457 - acc: 0.1146 - val_loss: 2.2965 - val_acc: 0.1425\n",
      "Epoch 2/100\n",
      "4800/4800 [==============================] - 2s 374us/step - loss: 2.2861 - acc: 0.1271 - val_loss: 2.2817 - val_acc: 0.1583\n",
      "Epoch 3/100\n",
      "4800/4800 [==============================] - 2s 376us/step - loss: 2.2670 - acc: 0.1512 - val_loss: 2.2762 - val_acc: 0.1567\n",
      "Epoch 4/100\n",
      "4800/4800 [==============================] - 2s 376us/step - loss: 2.2276 - acc: 0.1771 - val_loss: 2.1975 - val_acc: 0.2017\n",
      "Epoch 5/100\n",
      "4800/4800 [==============================] - 2s 377us/step - loss: 2.1567 - acc: 0.2096 - val_loss: 2.1435 - val_acc: 0.2517\n",
      "Epoch 6/100\n",
      "4800/4800 [==============================] - 2s 380us/step - loss: 2.0458 - acc: 0.2585 - val_loss: 1.9981 - val_acc: 0.3042\n",
      "Epoch 7/100\n",
      "4800/4800 [==============================] - 2s 377us/step - loss: 1.8323 - acc: 0.3542 - val_loss: 1.7769 - val_acc: 0.4175\n",
      "Epoch 8/100\n",
      "4800/4800 [==============================] - 2s 371us/step - loss: 1.6337 - acc: 0.4248 - val_loss: 1.6173 - val_acc: 0.4792\n",
      "Epoch 9/100\n",
      "4800/4800 [==============================] - 2s 368us/step - loss: 1.4730 - acc: 0.4879 - val_loss: 1.5956 - val_acc: 0.5100\n",
      "Epoch 10/100\n",
      "4800/4800 [==============================] - 2s 371us/step - loss: 1.3611 - acc: 0.5358 - val_loss: 1.4149 - val_acc: 0.5692\n",
      "Epoch 11/100\n",
      "4800/4800 [==============================] - 2s 376us/step - loss: 1.2263 - acc: 0.5825 - val_loss: 1.3023 - val_acc: 0.5767\n",
      "Epoch 12/100\n",
      "4800/4800 [==============================] - 2s 370us/step - loss: 1.1504 - acc: 0.6025 - val_loss: 1.2219 - val_acc: 0.6083\n",
      "Epoch 13/100\n",
      "4800/4800 [==============================] - 2s 368us/step - loss: 1.0755 - acc: 0.6227 - val_loss: 1.2036 - val_acc: 0.6200\n",
      "Epoch 14/100\n",
      "4800/4800 [==============================] - 2s 370us/step - loss: 0.9993 - acc: 0.6560 - val_loss: 1.1775 - val_acc: 0.6400\n",
      "Epoch 15/100\n",
      "4800/4800 [==============================] - 2s 377us/step - loss: 0.9305 - acc: 0.6817 - val_loss: 1.0804 - val_acc: 0.6725\n",
      "Epoch 16/100\n",
      "4800/4800 [==============================] - 2s 367us/step - loss: 0.8937 - acc: 0.6910 - val_loss: 0.9722 - val_acc: 0.6958\n",
      "Epoch 17/100\n",
      "4800/4800 [==============================] - 2s 371us/step - loss: 0.8488 - acc: 0.7019 - val_loss: 1.0193 - val_acc: 0.6767\n",
      "Epoch 18/100\n",
      "4800/4800 [==============================] - 2s 368us/step - loss: 0.7816 - acc: 0.7327 - val_loss: 0.8576 - val_acc: 0.7233\n",
      "Epoch 19/100\n",
      "4800/4800 [==============================] - 2s 366us/step - loss: 0.7405 - acc: 0.7423 - val_loss: 0.9059 - val_acc: 0.7067\n",
      "Epoch 20/100\n",
      "4800/4800 [==============================] - 2s 375us/step - loss: 0.7055 - acc: 0.7544 - val_loss: 0.8134 - val_acc: 0.7350\n",
      "Epoch 21/100\n",
      "4800/4800 [==============================] - 2s 366us/step - loss: 0.6575 - acc: 0.7717 - val_loss: 0.8150 - val_acc: 0.7500\n",
      "Epoch 22/100\n",
      "4800/4800 [==============================] - 2s 380us/step - loss: 0.6187 - acc: 0.7848 - val_loss: 0.7843 - val_acc: 0.7483\n",
      "Epoch 23/100\n",
      "4800/4800 [==============================] - 2s 377us/step - loss: 0.6048 - acc: 0.7908 - val_loss: 0.8062 - val_acc: 0.7517\n",
      "Epoch 24/100\n",
      "4800/4800 [==============================] - 2s 380us/step - loss: 0.5670 - acc: 0.8000 - val_loss: 0.7512 - val_acc: 0.7517\n",
      "Epoch 25/100\n",
      "4800/4800 [==============================] - 2s 377us/step - loss: 0.5531 - acc: 0.8079 - val_loss: 0.7500 - val_acc: 0.7508\n",
      "Epoch 26/100\n",
      "4800/4800 [==============================] - 2s 381us/step - loss: 0.4966 - acc: 0.8256 - val_loss: 0.7051 - val_acc: 0.7808\n",
      "Epoch 27/100\n",
      "4800/4800 [==============================] - 2s 371us/step - loss: 0.4927 - acc: 0.8294 - val_loss: 0.6900 - val_acc: 0.7683\n",
      "Epoch 28/100\n",
      "4800/4800 [==============================] - 2s 378us/step - loss: 0.4763 - acc: 0.8304 - val_loss: 0.6668 - val_acc: 0.7783\n",
      "Epoch 29/100\n",
      "4800/4800 [==============================] - 2s 378us/step - loss: 0.4625 - acc: 0.8392 - val_loss: 0.7236 - val_acc: 0.7525\n",
      "Epoch 30/100\n",
      "4800/4800 [==============================] - 2s 381us/step - loss: 0.4360 - acc: 0.8563 - val_loss: 0.6574 - val_acc: 0.7775\n",
      "Epoch 31/100\n",
      "4800/4800 [==============================] - 2s 384us/step - loss: 0.3955 - acc: 0.8652 - val_loss: 0.6203 - val_acc: 0.7975\n",
      "Epoch 32/100\n",
      "4800/4800 [==============================] - 2s 374us/step - loss: 0.4108 - acc: 0.8567 - val_loss: 0.6060 - val_acc: 0.7833\n",
      "Epoch 33/100\n",
      "4800/4800 [==============================] - 2s 380us/step - loss: 0.3863 - acc: 0.8635 - val_loss: 0.6726 - val_acc: 0.7817\n",
      "Epoch 34/100\n",
      "4800/4800 [==============================] - 2s 378us/step - loss: 0.3517 - acc: 0.8754 - val_loss: 0.6582 - val_acc: 0.7783\n",
      "Epoch 35/100\n",
      "4800/4800 [==============================] - 2s 378us/step - loss: 0.3292 - acc: 0.8808 - val_loss: 0.6033 - val_acc: 0.7942\n",
      "Epoch 36/100\n",
      "4800/4800 [==============================] - 2s 374us/step - loss: 0.3177 - acc: 0.8888 - val_loss: 0.5716 - val_acc: 0.8067\n",
      "Epoch 37/100\n",
      "4800/4800 [==============================] - 2s 372us/step - loss: 0.2708 - acc: 0.9090 - val_loss: 0.5352 - val_acc: 0.8242\n",
      "Epoch 38/100\n",
      "4800/4800 [==============================] - 2s 374us/step - loss: 0.2843 - acc: 0.9008 - val_loss: 0.5608 - val_acc: 0.8117\n",
      "Epoch 39/100\n",
      "4800/4800 [==============================] - 2s 374us/step - loss: 0.2660 - acc: 0.9050 - val_loss: 0.5329 - val_acc: 0.8250\n",
      "Epoch 40/100\n",
      "4800/4800 [==============================] - 2s 379us/step - loss: 0.2524 - acc: 0.9108 - val_loss: 0.5613 - val_acc: 0.8033\n",
      "Epoch 41/100\n",
      "4800/4800 [==============================] - 2s 366us/step - loss: 0.2512 - acc: 0.9156 - val_loss: 0.5210 - val_acc: 0.8167\n",
      "Epoch 42/100\n",
      "4800/4800 [==============================] - 2s 371us/step - loss: 0.2265 - acc: 0.9240 - val_loss: 0.5003 - val_acc: 0.8317\n",
      "Epoch 43/100\n",
      "4800/4800 [==============================] - 2s 374us/step - loss: 0.2453 - acc: 0.9087 - val_loss: 0.5406 - val_acc: 0.8233\n",
      "Epoch 44/100\n",
      "4800/4800 [==============================] - 2s 370us/step - loss: 0.2172 - acc: 0.9281 - val_loss: 0.4875 - val_acc: 0.8325\n",
      "Epoch 45/100\n",
      "4800/4800 [==============================] - 2s 362us/step - loss: 0.2083 - acc: 0.9294 - val_loss: 0.4984 - val_acc: 0.8325\n",
      "Epoch 46/100\n",
      "4800/4800 [==============================] - 2s 387us/step - loss: 0.2102 - acc: 0.9267 - val_loss: 0.5149 - val_acc: 0.8225\n",
      "Epoch 47/100\n",
      "4800/4800 [==============================] - 2s 361us/step - loss: 0.2378 - acc: 0.9185 - val_loss: 0.4892 - val_acc: 0.8442\n",
      "Epoch 48/100\n",
      "4800/4800 [==============================] - 2s 368us/step - loss: 0.2003 - acc: 0.9342 - val_loss: 0.5000 - val_acc: 0.8358\n",
      "Epoch 49/100\n",
      "4800/4800 [==============================] - 2s 371us/step - loss: 0.2126 - acc: 0.9256 - val_loss: 0.4622 - val_acc: 0.8383\n",
      "Epoch 50/100\n",
      "4800/4800 [==============================] - 2s 372us/step - loss: 0.2014 - acc: 0.9279 - val_loss: 0.4991 - val_acc: 0.8267\n",
      "Epoch 51/100\n",
      "4800/4800 [==============================] - 2s 372us/step - loss: 0.1850 - acc: 0.9333 - val_loss: 0.4797 - val_acc: 0.8400\n",
      "Epoch 52/100\n",
      "4800/4800 [==============================] - 2s 372us/step - loss: 0.1838 - acc: 0.9365 - val_loss: 0.4468 - val_acc: 0.8500\n",
      "Epoch 53/100\n",
      "4800/4800 [==============================] - 2s 378us/step - loss: 0.1726 - acc: 0.9408 - val_loss: 0.4617 - val_acc: 0.8433\n",
      "Epoch 54/100\n",
      "4800/4800 [==============================] - 2s 376us/step - loss: 0.1593 - acc: 0.9444 - val_loss: 0.4616 - val_acc: 0.8408\n",
      "Epoch 55/100\n",
      "4800/4800 [==============================] - 2s 376us/step - loss: 0.1717 - acc: 0.9373 - val_loss: 0.5342 - val_acc: 0.8208\n",
      "Epoch 56/100\n",
      "4800/4800 [==============================] - 2s 375us/step - loss: 0.1608 - acc: 0.9460 - val_loss: 0.4600 - val_acc: 0.8342\n",
      "Epoch 57/100\n",
      "4800/4800 [==============================] - 2s 375us/step - loss: 0.1566 - acc: 0.9448 - val_loss: 0.5326 - val_acc: 0.8292\n",
      "Epoch 58/100\n",
      "4800/4800 [==============================] - 2s 374us/step - loss: 0.1558 - acc: 0.9454 - val_loss: 0.4267 - val_acc: 0.8567\n",
      "Epoch 59/100\n",
      "4800/4800 [==============================] - 2s 369us/step - loss: 0.1378 - acc: 0.9510 - val_loss: 0.4552 - val_acc: 0.8425\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4800/4800 [==============================] - 2s 370us/step - loss: 0.1317 - acc: 0.9554 - val_loss: 0.4499 - val_acc: 0.8575\n",
      "Epoch 61/100\n",
      "4800/4800 [==============================] - 2s 371us/step - loss: 0.1401 - acc: 0.9481 - val_loss: 0.4397 - val_acc: 0.8458\n",
      "Epoch 62/100\n",
      "4800/4800 [==============================] - 2s 366us/step - loss: 0.1519 - acc: 0.9498 - val_loss: 0.4363 - val_acc: 0.8408\n",
      "Epoch 63/100\n",
      "4800/4800 [==============================] - 2s 371us/step - loss: 0.1386 - acc: 0.9540 - val_loss: 0.4279 - val_acc: 0.8608\n",
      "Epoch 64/100\n",
      "4800/4800 [==============================] - 2s 371us/step - loss: 0.1251 - acc: 0.9550 - val_loss: 0.4547 - val_acc: 0.8475\n",
      "Epoch 65/100\n",
      "4800/4800 [==============================] - 2s 373us/step - loss: 0.1313 - acc: 0.9546 - val_loss: 0.4571 - val_acc: 0.8492\n",
      "Epoch 66/100\n",
      "4800/4800 [==============================] - 2s 376us/step - loss: 0.1275 - acc: 0.9562 - val_loss: 0.4362 - val_acc: 0.8575\n",
      "Epoch 67/100\n",
      "4800/4800 [==============================] - 2s 368us/step - loss: 0.1284 - acc: 0.9519 - val_loss: 0.4290 - val_acc: 0.8550\n",
      "Epoch 68/100\n",
      "4800/4800 [==============================] - 2s 368us/step - loss: 0.1168 - acc: 0.9585 - val_loss: 0.4090 - val_acc: 0.8608\n",
      "Epoch 69/100\n",
      "4800/4800 [==============================] - 2s 374us/step - loss: 0.1158 - acc: 0.9619 - val_loss: 0.4223 - val_acc: 0.8675\n",
      "Epoch 70/100\n",
      "4800/4800 [==============================] - 2s 370us/step - loss: 0.1374 - acc: 0.9517 - val_loss: 0.4495 - val_acc: 0.8458\n",
      "Epoch 71/100\n",
      "4800/4800 [==============================] - 2s 373us/step - loss: 0.1173 - acc: 0.9583 - val_loss: 0.4671 - val_acc: 0.8383\n",
      "Epoch 72/100\n",
      "4800/4800 [==============================] - 2s 374us/step - loss: 0.1628 - acc: 0.9458 - val_loss: 0.5596 - val_acc: 0.8192\n",
      "Epoch 73/100\n",
      "4800/4800 [==============================] - 2s 375us/step - loss: 0.1250 - acc: 0.9587 - val_loss: 0.5120 - val_acc: 0.8358\n",
      "Epoch 74/100\n",
      "4800/4800 [==============================] - 2s 369us/step - loss: 0.1251 - acc: 0.9579 - val_loss: 0.4699 - val_acc: 0.8433\n",
      "Epoch 75/100\n",
      "4800/4800 [==============================] - 2s 369us/step - loss: 0.1223 - acc: 0.9565 - val_loss: 0.4514 - val_acc: 0.8433\n",
      "Epoch 76/100\n",
      "4800/4800 [==============================] - 2s 368us/step - loss: 0.1035 - acc: 0.9642 - val_loss: 0.4997 - val_acc: 0.8317\n",
      "Epoch 77/100\n",
      "4800/4800 [==============================] - 2s 373us/step - loss: 0.1106 - acc: 0.9615 - val_loss: 0.4317 - val_acc: 0.8500\n",
      "Epoch 78/100\n",
      "4800/4800 [==============================] - 2s 376us/step - loss: 0.0946 - acc: 0.9679 - val_loss: 0.4580 - val_acc: 0.8483\n",
      "Epoch 79/100\n",
      "4800/4800 [==============================] - 2s 369us/step - loss: 0.1010 - acc: 0.9633 - val_loss: 0.3747 - val_acc: 0.8683\n",
      "Epoch 80/100\n",
      "4800/4800 [==============================] - 2s 367us/step - loss: 0.1211 - acc: 0.9581 - val_loss: 0.4256 - val_acc: 0.8633\n",
      "Epoch 81/100\n",
      "4800/4800 [==============================] - 2s 371us/step - loss: 0.0960 - acc: 0.9712 - val_loss: 0.4516 - val_acc: 0.8558\n",
      "Epoch 82/100\n",
      "4800/4800 [==============================] - 2s 366us/step - loss: 0.1096 - acc: 0.9631 - val_loss: 0.3937 - val_acc: 0.8658\n",
      "Epoch 83/100\n",
      "4800/4800 [==============================] - 2s 370us/step - loss: 0.1198 - acc: 0.9571 - val_loss: 0.5260 - val_acc: 0.8417\n",
      "Epoch 84/100\n",
      "4800/4800 [==============================] - 2s 368us/step - loss: 0.1127 - acc: 0.9596 - val_loss: 0.4465 - val_acc: 0.8550\n",
      "Epoch 85/100\n",
      "4800/4800 [==============================] - 2s 370us/step - loss: 0.0967 - acc: 0.9669 - val_loss: 0.4205 - val_acc: 0.8600\n",
      "Epoch 86/100\n",
      "4800/4800 [==============================] - 2s 368us/step - loss: 0.1170 - acc: 0.9629 - val_loss: 0.4102 - val_acc: 0.8592\n",
      "Epoch 87/100\n",
      "4800/4800 [==============================] - 2s 368us/step - loss: 0.0904 - acc: 0.9677 - val_loss: 0.4567 - val_acc: 0.8517\n",
      "Epoch 88/100\n",
      "4800/4800 [==============================] - 2s 370us/step - loss: 0.1017 - acc: 0.9669 - val_loss: 0.4216 - val_acc: 0.8500\n",
      "Epoch 89/100\n",
      "4800/4800 [==============================] - 2s 374us/step - loss: 0.1185 - acc: 0.9608 - val_loss: 0.4311 - val_acc: 0.8633\n",
      "Epoch 90/100\n",
      "4800/4800 [==============================] - 2s 371us/step - loss: 0.1005 - acc: 0.9638 - val_loss: 0.4612 - val_acc: 0.8583\n",
      "Epoch 91/100\n",
      "4800/4800 [==============================] - 2s 375us/step - loss: 0.0914 - acc: 0.9700 - val_loss: 0.4774 - val_acc: 0.8500\n",
      "Epoch 92/100\n",
      "4800/4800 [==============================] - 2s 369us/step - loss: 0.0803 - acc: 0.9735 - val_loss: 0.4861 - val_acc: 0.8367\n",
      "Epoch 93/100\n",
      "4800/4800 [==============================] - 2s 368us/step - loss: 0.1136 - acc: 0.9615 - val_loss: 0.4225 - val_acc: 0.8700\n",
      "Epoch 94/100\n",
      "4800/4800 [==============================] - 2s 374us/step - loss: 0.0851 - acc: 0.9710 - val_loss: 0.4357 - val_acc: 0.8467\n",
      "Epoch 95/100\n",
      "4800/4800 [==============================] - 2s 366us/step - loss: 0.0879 - acc: 0.9708 - val_loss: 0.4883 - val_acc: 0.8400\n",
      "Epoch 96/100\n",
      "4800/4800 [==============================] - 2s 368us/step - loss: 0.0833 - acc: 0.9756 - val_loss: 0.4504 - val_acc: 0.8492\n",
      "Epoch 97/100\n",
      "4800/4800 [==============================] - 2s 374us/step - loss: 0.0825 - acc: 0.9710 - val_loss: 0.4794 - val_acc: 0.8367\n",
      "Epoch 98/100\n",
      "4800/4800 [==============================] - 2s 368us/step - loss: 0.1129 - acc: 0.9617 - val_loss: 0.4603 - val_acc: 0.8525\n",
      "Epoch 99/100\n",
      "4800/4800 [==============================] - 2s 373us/step - loss: 0.1073 - acc: 0.9617 - val_loss: 0.4452 - val_acc: 0.8508\n",
      "Epoch 100/100\n",
      "4800/4800 [==============================] - 2s 365us/step - loss: 0.0939 - acc: 0.9665 - val_loss: 0.4019 - val_acc: 0.8625\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam', metrics = ['accuracy'], loss = 'categorical_crossentropy')\n",
    "\n",
    "#es = EarlyStopping(monitor='val_loss', patience=20, mode='min', verbose=1)\n",
    "cp = ModelCheckpoint('./models/{epoch:02d}-{val_acc:.4f}.h5', monitor='val_loss',\n",
    "                     save_best_only=True, mode='min')\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    validation_data=(x_val, y_val), \n",
    "                    batch_size=64, epochs=100, verbose=1, callbacks = [cp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T07:02:30.641612Z",
     "start_time": "2020-08-21T07:02:27.774270Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "best_model = load_model('models/noskipCNN_drop_global.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T07:02:30.891479Z",
     "start_time": "2020-08-21T07:02:30.641612Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4532715529203415, 0.875]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate = best_model.evaluate(valid_x, valid_y)\n",
    "evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T07:01:50.486003Z",
     "start_time": "2020-08-21T07:01:50.473059Z"
    }
   },
   "outputs": [],
   "source": [
    "#submission = pd.read_csv('data/val.csv')\n",
    "#submission['digit'] = np.argmax(best_model.predict([x_test, x_letter_test]), axis=1)\n",
    "#submission.to_csv('data/val(CNN).csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T05:10:57.952761Z",
     "start_time": "2020-08-18T05:10:55.407036Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, LSTM, concatenate, Dropout\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# seed\n",
    "import os\n",
    "seed = 123\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T05:10:59.033910Z",
     "start_time": "2020-08-18T05:10:57.953764Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T05:10:59.038834Z",
     "start_time": "2020-08-18T05:10:59.035832Z"
    }
   },
   "outputs": [],
   "source": [
    "image_generator = ImageDataGenerator(width_shift_range=0.2,\n",
    "                                     height_shift_range=0.2, \n",
    "                                     zoom_range=[0.75,1.25])\n",
    "                                     #brightness_range=[0.75,1.25], \n",
    "                                     #shear_range=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T05:10:59.814567Z",
     "start_time": "2020-08-18T05:10:59.040835Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4096, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "x = train.drop(['id', 'digit', 'letter'], axis=1).values\n",
    "x = x.reshape(-1, 28, 28, 1)\n",
    "x = x/255\n",
    "x_remake = []\n",
    "for i in range(x.shape[0]):\n",
    "    num_aug = 0\n",
    "    tmp = x[i]\n",
    "    tmp = tmp.reshape((1,) + tmp.shape)\n",
    "    for x_aug in image_generator.flow(tmp, batch_size = 1) :\n",
    "        if num_aug >= 1:\n",
    "            break\n",
    "        x_remake.append(x_aug[0])\n",
    "        num_aug += 1\n",
    "x_remake = np.array(x_remake)\n",
    "\n",
    "x_total = np.concatenate((x, x_remake), axis=0)\n",
    "print(x_total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T05:10:59.822557Z",
     "start_time": "2020-08-18T05:10:59.816469Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4096, 10)\n"
     ]
    }
   ],
   "source": [
    "y_data = train['digit']\n",
    "y = np.zeros((len(y_data), len(y_data.unique())))\n",
    "for i, digit in enumerate(y_data):\n",
    "    y[i, digit] = 1\n",
    "\n",
    "y_remake = y.copy()\n",
    "y_total = np.concatenate((y, y_remake), axis=0)\n",
    "print(y_total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T05:10:59.839550Z",
     "start_time": "2020-08-18T05:10:59.824566Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4096, 26)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_let = train['letter'].values\n",
    "x_let = x_let[:, np.newaxis]\n",
    "en = OneHotEncoder()\n",
    "x_let = en.fit_transform(x_let).toarray()\n",
    "\n",
    "x_remake_let = x_let.copy()\n",
    "\n",
    "x_letter_total = np.concatenate((x_let, x_remake_let), axis=0)\n",
    "x_letter_total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T05:10:59.912494Z",
     "start_time": "2020-08-18T05:10:59.842470Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3276, 28, 28, 1)\n",
      "(820, 28, 28, 1)\n",
      "(3276, 10)\n",
      "(820, 10)\n",
      "(3276, 26)\n",
      "(820, 26)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_total, y_total, test_size=0.2, shuffle=True, stratify=y_total)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)\n",
    "\n",
    "x_letter_train = x_letter_total[:x_train.shape[0],:]\n",
    "x_letter_val = x_letter_total[x_train.shape[0]:,:]\n",
    "print(x_letter_train.shape)\n",
    "print(x_letter_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T05:11:00.131470Z",
     "start_time": "2020-08-18T05:10:59.914468Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input1 (InputLayer)             [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 28, 28, 64)   640         input1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 28, 28, 64)   0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 14, 14, 64)   0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 14, 14, 64)   16448       pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 14, 14, 64)   0           conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool2 (MaxPooling2D)            (None, 7, 7, 64)     0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3 (Conv2D)                  (None, 7, 7, 128)    32896       pool2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 7, 7, 128)    0           conv3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (MaxPooling2D)            (None, 3, 3, 128)    0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flat1 (Flatten)                 (None, 1152)         0           pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input2 (InputLayer)             [(None, 26)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "merge (Concatenate)             (None, 1178)         0           flat1[0][0]                      \n",
      "                                                                 input2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "hidden1 (Dense)                 (None, 500)          589500      merge[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 500)          0           hidden1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "hidden2 (Dense)                 (None, 100)          50100       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 100)          0           hidden2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "hidden3 (Dense)                 (None, 50)           5050        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 10)           510         hidden3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 695,144\n",
      "Trainable params: 695,144\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input1 = Input(shape=(28,28,1), name='input1')\n",
    "x1 = Conv2D(64, (3,3), activation='relu', padding='same', name='conv1')(input1)\n",
    "x1 = Dropout(0.3)(x1)\n",
    "x1 = MaxPooling2D((2,2), name='pool1')(x1)\n",
    "x1 = Conv2D(64, (2,2), activation='relu', padding='same', name='conv2')(x1)\n",
    "x1 = Dropout(0.3)(x1)\n",
    "x1 = MaxPooling2D((2,2), name='pool2')(x1)\n",
    "x1 = Conv2D(128, (2,2), activation='relu', padding='same', name='conv3')(x1)\n",
    "x1 = Dropout(0.3)(x1)\n",
    "x1 = MaxPooling2D((2,2), name='pool3')(x1)\n",
    "x1 = Flatten(name='flat1')(x1)\n",
    "\n",
    "input2 = Input(shape=(26,), name='input2')\n",
    "merge = concatenate([x1, input2], name='merge')\n",
    "\n",
    "x2 = Dense(500, activation='relu', name='hidden1')(merge)\n",
    "x2 = Dropout(0.3)(x2)\n",
    "x2 = Dense(100, activation='relu', name='hidden2')(x2)\n",
    "x2 = Dropout(0.3)(x2)\n",
    "x2 = Dense(50, activation='relu', name='hidden3')(x2)\n",
    "outputs = Dense(10, activation='softmax', name='output')(x2)\n",
    "\n",
    "model = Model(inputs = [input1, input2], outputs = outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T05:19:54.745878Z",
     "start_time": "2020-08-18T05:11:00.132468Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3276 samples, validate on 820 samples\n",
      "Epoch 1/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 2.2996 - accuracy: 0.1127\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.12683, saving model to ./models/01-0.1268.h5\n",
      "3276/3276 [==============================] - 7s 2ms/sample - loss: 2.2997 - accuracy: 0.1129 - val_loss: 2.2784 - val_accuracy: 0.1268\n",
      "Epoch 2/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 2.2124 - accuracy: 0.1661\n",
      "Epoch 00002: val_accuracy improved from 0.12683 to 0.25854, saving model to ./models/02-0.2585.h5\n",
      "3276/3276 [==============================] - 6s 2ms/sample - loss: 2.2122 - accuracy: 0.1661 - val_loss: 2.1824 - val_accuracy: 0.2585\n",
      "Epoch 3/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 2.0364 - accuracy: 0.2613\n",
      "Epoch 00003: val_accuracy improved from 0.25854 to 0.33659, saving model to ./models/03-0.3366.h5\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 2.0359 - accuracy: 0.2616 - val_loss: 1.9917 - val_accuracy: 0.3366\n",
      "Epoch 4/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 1.8510 - accuracy: 0.3410\n",
      "Epoch 00004: val_accuracy did not improve from 0.33659\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 1.8520 - accuracy: 0.3400 - val_loss: 1.9877 - val_accuracy: 0.3341\n",
      "Epoch 5/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 1.6639 - accuracy: 0.4145\n",
      "Epoch 00005: val_accuracy improved from 0.33659 to 0.44512, saving model to ./models/05-0.4451.h5\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 1.6636 - accuracy: 0.4148 - val_loss: 1.7526 - val_accuracy: 0.4451\n",
      "Epoch 6/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 1.5037 - accuracy: 0.4752\n",
      "Epoch 00006: val_accuracy improved from 0.44512 to 0.47073, saving model to ./models/06-0.4707.h5\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 1.5053 - accuracy: 0.4744 - val_loss: 1.6840 - val_accuracy: 0.4707\n",
      "Epoch 7/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 1.3634 - accuracy: 0.5401\n",
      "Epoch 00007: val_accuracy improved from 0.47073 to 0.51341, saving model to ./models/07-0.5134.h5\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 1.3650 - accuracy: 0.5397 - val_loss: 1.4984 - val_accuracy: 0.5134\n",
      "Epoch 8/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 1.2942 - accuracy: 0.5582\n",
      "Epoch 00008: val_accuracy improved from 0.51341 to 0.53902, saving model to ./models/08-0.5390.h5\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 1.2964 - accuracy: 0.5577 - val_loss: 1.5067 - val_accuracy: 0.5390\n",
      "Epoch 9/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 1.1797 - accuracy: 0.5999 ETA: 1s\n",
      "Epoch 00009: val_accuracy improved from 0.53902 to 0.56220, saving model to ./models/09-0.5622.h5\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 1.1806 - accuracy: 0.5995 - val_loss: 1.4225 - val_accuracy: 0.5622\n",
      "Epoch 10/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 1.1134 - accuracy: 0.6109\n",
      "Epoch 00010: val_accuracy did not improve from 0.56220\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 1.1134 - accuracy: 0.6111 - val_loss: 1.4700 - val_accuracy: 0.5476\n",
      "Epoch 11/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 1.0412 - accuracy: 0.6440\n",
      "Epoch 00011: val_accuracy did not improve from 0.56220\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 1.0401 - accuracy: 0.6444 - val_loss: 1.3850 - val_accuracy: 0.5585\n",
      "Epoch 12/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 1.0004 - accuracy: 0.6602\n",
      "Epoch 00012: val_accuracy improved from 0.56220 to 0.57683, saving model to ./models/12-0.5768.h5\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.9987 - accuracy: 0.6612 - val_loss: 1.2979 - val_accuracy: 0.5768\n",
      "Epoch 13/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.8937 - accuracy: 0.7028\n",
      "Epoch 00013: val_accuracy improved from 0.57683 to 0.58049, saving model to ./models/13-0.5805.h5\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.8941 - accuracy: 0.7030 - val_loss: 1.3118 - val_accuracy: 0.5805\n",
      "Epoch 14/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.8473 - accuracy: 0.7093\n",
      "Epoch 00014: val_accuracy did not improve from 0.58049\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.8474 - accuracy: 0.7094 - val_loss: 1.3284 - val_accuracy: 0.5695\n",
      "Epoch 15/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.7901 - accuracy: 0.7325\n",
      "Epoch 00015: val_accuracy improved from 0.58049 to 0.60854, saving model to ./models/15-0.6085.h5\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.7898 - accuracy: 0.7326 - val_loss: 1.2177 - val_accuracy: 0.6085\n",
      "Epoch 16/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.7676 - accuracy: 0.7377\n",
      "Epoch 00016: val_accuracy did not improve from 0.60854\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.7692 - accuracy: 0.7372 - val_loss: 1.2214 - val_accuracy: 0.6073\n",
      "Epoch 17/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.6883 - accuracy: 0.7613\n",
      "Epoch 00017: val_accuracy improved from 0.60854 to 0.61463, saving model to ./models/17-0.6146.h5\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.6882 - accuracy: 0.7613 - val_loss: 1.1780 - val_accuracy: 0.6146\n",
      "Epoch 18/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.6636 - accuracy: 0.7742\n",
      "Epoch 00018: val_accuracy improved from 0.61463 to 0.63537, saving model to ./models/18-0.6354.h5\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.6637 - accuracy: 0.7741 - val_loss: 1.1359 - val_accuracy: 0.6354\n",
      "Epoch 19/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.6168 - accuracy: 0.7828\n",
      "Epoch 00019: val_accuracy did not improve from 0.63537\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.6171 - accuracy: 0.7827 - val_loss: 1.1211 - val_accuracy: 0.6317\n",
      "Epoch 20/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.5798 - accuracy: 0.8061\n",
      "Epoch 00020: val_accuracy did not improve from 0.63537\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.5805 - accuracy: 0.8059 - val_loss: 1.1311 - val_accuracy: 0.6317\n",
      "Epoch 21/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.5078 - accuracy: 0.8278\n",
      "Epoch 00021: val_accuracy did not improve from 0.63537\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.5080 - accuracy: 0.8272 - val_loss: 1.0799 - val_accuracy: 0.6329\n",
      "Epoch 22/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.4925 - accuracy: 0.8373\n",
      "Epoch 00022: val_accuracy improved from 0.63537 to 0.63780, saving model to ./models/22-0.6378.h5\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.4938 - accuracy: 0.8370 - val_loss: 1.1178 - val_accuracy: 0.6378\n",
      "Epoch 23/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.4677 - accuracy: 0.8315\n",
      "Epoch 00023: val_accuracy did not improve from 0.63780\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.4675 - accuracy: 0.8318 - val_loss: 1.1552 - val_accuracy: 0.6244\n",
      "Epoch 24/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.3883 - accuracy: 0.8652\n",
      "Epoch 00024: val_accuracy did not improve from 0.63780\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.3887 - accuracy: 0.8651 - val_loss: 1.0760 - val_accuracy: 0.6378\n",
      "Epoch 25/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.4004 - accuracy: 0.8631\n",
      "Epoch 00025: val_accuracy did not improve from 0.63780\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.4017 - accuracy: 0.8629 - val_loss: 1.0534 - val_accuracy: 0.6354\n",
      "Epoch 26/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.3771 - accuracy: 0.8775\n",
      "Epoch 00026: val_accuracy did not improve from 0.63780\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.3762 - accuracy: 0.8779 - val_loss: 1.0769 - val_accuracy: 0.6232\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.3449 - accuracy: 0.8827\n",
      "Epoch 00027: val_accuracy improved from 0.63780 to 0.64268, saving model to ./models/27-0.6427.h5\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.3442 - accuracy: 0.8828 - val_loss: 1.1029 - val_accuracy: 0.6427\n",
      "Epoch 28/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.3233 - accuracy: 0.8909\n",
      "Epoch 00028: val_accuracy improved from 0.64268 to 0.64756, saving model to ./models/28-0.6476.h5\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.3236 - accuracy: 0.8907 - val_loss: 1.0965 - val_accuracy: 0.6476\n",
      "Epoch 29/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.3088 - accuracy: 0.8876\n",
      "Epoch 00029: val_accuracy did not improve from 0.64756\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.3083 - accuracy: 0.8877 - val_loss: 1.0949 - val_accuracy: 0.6427\n",
      "Epoch 30/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.2929 - accuracy: 0.9023\n",
      "Epoch 00030: val_accuracy did not improve from 0.64756\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.2940 - accuracy: 0.9014 - val_loss: 1.1434 - val_accuracy: 0.6159\n",
      "Epoch 31/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.2683 - accuracy: 0.9087\n",
      "Epoch 00031: val_accuracy did not improve from 0.64756\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.2677 - accuracy: 0.9090 - val_loss: 1.0769 - val_accuracy: 0.6244\n",
      "Epoch 32/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.2678 - accuracy: 0.9176\n",
      "Epoch 00032: val_accuracy did not improve from 0.64756\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.2676 - accuracy: 0.9176 - val_loss: 1.0889 - val_accuracy: 0.6476\n",
      "Epoch 33/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.2619 - accuracy: 0.9112\n",
      "Epoch 00033: val_accuracy did not improve from 0.64756\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.2636 - accuracy: 0.9106 - val_loss: 1.0828 - val_accuracy: 0.6390\n",
      "Epoch 34/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.2816 - accuracy: 0.9062\n",
      "Epoch 00034: val_accuracy improved from 0.64756 to 0.65488, saving model to ./models/34-0.6549.h5\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.2821 - accuracy: 0.9057 - val_loss: 1.0733 - val_accuracy: 0.6549\n",
      "Epoch 35/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.2352 - accuracy: 0.9225\n",
      "Epoch 00035: val_accuracy did not improve from 0.65488\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.2347 - accuracy: 0.9228 - val_loss: 1.0612 - val_accuracy: 0.6512\n",
      "Epoch 36/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.2077 - accuracy: 0.9301\n",
      "Epoch 00036: val_accuracy did not improve from 0.65488\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.2073 - accuracy: 0.9304 - val_loss: 1.1289 - val_accuracy: 0.6341\n",
      "Epoch 37/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.1886 - accuracy: 0.9381\n",
      "Epoch 00037: val_accuracy did not improve from 0.65488\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.1896 - accuracy: 0.9377 - val_loss: 1.1521 - val_accuracy: 0.6232\n",
      "Epoch 38/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.1946 - accuracy: 0.9305\n",
      "Epoch 00038: val_accuracy did not improve from 0.65488\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.1946 - accuracy: 0.9307 - val_loss: 1.0927 - val_accuracy: 0.6524\n",
      "Epoch 39/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.1740 - accuracy: 0.9433\n",
      "Epoch 00039: val_accuracy did not improve from 0.65488\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.1737 - accuracy: 0.9435 - val_loss: 1.1069 - val_accuracy: 0.6537\n",
      "Epoch 40/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.1790 - accuracy: 0.9479\n",
      "Epoch 00040: val_accuracy did not improve from 0.65488\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.1787 - accuracy: 0.9481 - val_loss: 1.0968 - val_accuracy: 0.6427\n",
      "Epoch 41/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.1518 - accuracy: 0.9494\n",
      "Epoch 00041: val_accuracy did not improve from 0.65488\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.1540 - accuracy: 0.9490 - val_loss: 1.1375 - val_accuracy: 0.6402\n",
      "Epoch 42/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.1882 - accuracy: 0.9406\n",
      "Epoch 00042: val_accuracy did not improve from 0.65488\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.1876 - accuracy: 0.9408 - val_loss: 1.0996 - val_accuracy: 0.6512\n",
      "Epoch 43/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.1591 - accuracy: 0.9488\n",
      "Epoch 00043: val_accuracy did not improve from 0.65488\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.1586 - accuracy: 0.9490 - val_loss: 1.1403 - val_accuracy: 0.6439\n",
      "Epoch 44/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.1336 - accuracy: 0.9593\n",
      "Epoch 00044: val_accuracy improved from 0.65488 to 0.65610, saving model to ./models/44-0.6561.h5\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.1348 - accuracy: 0.9591 - val_loss: 1.0950 - val_accuracy: 0.6561\n",
      "Epoch 45/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.1613 - accuracy: 0.9485\n",
      "Epoch 00045: val_accuracy did not improve from 0.65610\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.1616 - accuracy: 0.9484 - val_loss: 1.1048 - val_accuracy: 0.6451\n",
      "Epoch 46/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.1519 - accuracy: 0.9528\n",
      "Epoch 00046: val_accuracy did not improve from 0.65610\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.1523 - accuracy: 0.9527 - val_loss: 1.1208 - val_accuracy: 0.6476\n",
      "Epoch 47/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.1520 - accuracy: 0.9510\n",
      "Epoch 00047: val_accuracy did not improve from 0.65610\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.1515 - accuracy: 0.9512 - val_loss: 1.1050 - val_accuracy: 0.6439\n",
      "Epoch 48/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.1187 - accuracy: 0.9614\n",
      "Epoch 00048: val_accuracy did not improve from 0.65610\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.1184 - accuracy: 0.9615 - val_loss: 1.1353 - val_accuracy: 0.6561\n",
      "Epoch 49/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.1068 - accuracy: 0.9691\n",
      "Epoch 00049: val_accuracy did not improve from 0.65610\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.1064 - accuracy: 0.9692 - val_loss: 1.1421 - val_accuracy: 0.6524\n",
      "Epoch 50/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.1297 - accuracy: 0.9559\n",
      "Epoch 00050: val_accuracy did not improve from 0.65610\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.1295 - accuracy: 0.9557 - val_loss: 1.1381 - val_accuracy: 0.6463\n",
      "Epoch 51/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.1352 - accuracy: 0.9531\n",
      "Epoch 00051: val_accuracy improved from 0.65610 to 0.66098, saving model to ./models/51-0.6610.h5\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.1355 - accuracy: 0.9527 - val_loss: 1.0913 - val_accuracy: 0.6610\n",
      "Epoch 52/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.1235 - accuracy: 0.9599\n",
      "Epoch 00052: val_accuracy did not improve from 0.66098\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.1233 - accuracy: 0.9600 - val_loss: 1.1674 - val_accuracy: 0.6537\n",
      "Epoch 53/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.1359 - accuracy: 0.9547\n",
      "Epoch 00053: val_accuracy did not improve from 0.66098\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.1354 - accuracy: 0.9548 - val_loss: 1.1334 - val_accuracy: 0.6512\n",
      "Epoch 54/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.1218 - accuracy: 0.9611\n",
      "Epoch 00054: val_accuracy did not improve from 0.66098\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.1218 - accuracy: 0.9609 - val_loss: 1.1547 - val_accuracy: 0.6427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.1216 - accuracy: 0.9596\n",
      "Epoch 00055: val_accuracy improved from 0.66098 to 0.66829, saving model to ./models/55-0.6683.h5\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.1220 - accuracy: 0.9594 - val_loss: 1.1125 - val_accuracy: 0.6683\n",
      "Epoch 56/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.0914 - accuracy: 0.9715\n",
      "Epoch 00056: val_accuracy improved from 0.66829 to 0.67073, saving model to ./models/56-0.6707.h5\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.0911 - accuracy: 0.9716 - val_loss: 1.1200 - val_accuracy: 0.6707\n",
      "Epoch 57/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.1014 - accuracy: 0.9724\n",
      "Epoch 00057: val_accuracy did not improve from 0.67073\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.1011 - accuracy: 0.9725 - val_loss: 1.1059 - val_accuracy: 0.6671\n",
      "Epoch 58/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.0841 - accuracy: 0.9706 ETA: 1s - loss:\n",
      "Epoch 00058: val_accuracy did not improve from 0.67073\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.0843 - accuracy: 0.9704 - val_loss: 1.1243 - val_accuracy: 0.6524\n",
      "Epoch 59/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.0953 - accuracy: 0.9703\n",
      "Epoch 00059: val_accuracy did not improve from 0.67073\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.0958 - accuracy: 0.9701 - val_loss: 1.0944 - val_accuracy: 0.6634\n",
      "Epoch 60/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.1258 - accuracy: 0.9577\n",
      "Epoch 00060: val_accuracy did not improve from 0.67073\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.1257 - accuracy: 0.9576 - val_loss: 1.1261 - val_accuracy: 0.6524\n",
      "Epoch 61/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.1166 - accuracy: 0.9632\n",
      "Epoch 00061: val_accuracy did not improve from 0.67073\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.1164 - accuracy: 0.9634 - val_loss: 1.1303 - val_accuracy: 0.6549\n",
      "Epoch 62/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.0937 - accuracy: 0.9684\n",
      "Epoch 00062: val_accuracy did not improve from 0.67073\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.0936 - accuracy: 0.9686 - val_loss: 1.1681 - val_accuracy: 0.6537\n",
      "Epoch 63/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.0865 - accuracy: 0.9727\n",
      "Epoch 00063: val_accuracy did not improve from 0.67073\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.0862 - accuracy: 0.9728 - val_loss: 1.1629 - val_accuracy: 0.6585\n",
      "Epoch 64/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.0858 - accuracy: 0.9724\n",
      "Epoch 00064: val_accuracy did not improve from 0.67073\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.0861 - accuracy: 0.9722 - val_loss: 1.1581 - val_accuracy: 0.6488\n",
      "Epoch 65/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.0859 - accuracy: 0.9730\n",
      "Epoch 00065: val_accuracy did not improve from 0.67073\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.0856 - accuracy: 0.9731 - val_loss: 1.2120 - val_accuracy: 0.6561\n",
      "Epoch 66/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.0835 - accuracy: 0.9737\n",
      "Epoch 00066: val_accuracy did not improve from 0.67073\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.0841 - accuracy: 0.9731 - val_loss: 1.1190 - val_accuracy: 0.6524\n",
      "Epoch 67/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.1118 - accuracy: 0.9645\n",
      "Epoch 00067: val_accuracy did not improve from 0.67073\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.1116 - accuracy: 0.9646 - val_loss: 1.1712 - val_accuracy: 0.6415\n",
      "Epoch 68/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.0782 - accuracy: 0.9737\n",
      "Epoch 00068: val_accuracy did not improve from 0.67073\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.0780 - accuracy: 0.9737 - val_loss: 1.2045 - val_accuracy: 0.6329\n",
      "Epoch 69/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.0742 - accuracy: 0.9776\n",
      "Epoch 00069: val_accuracy did not improve from 0.67073\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.0740 - accuracy: 0.9777 - val_loss: 1.2123 - val_accuracy: 0.6549\n",
      "Epoch 70/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.0916 - accuracy: 0.9733\n",
      "Epoch 00070: val_accuracy did not improve from 0.67073\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.0921 - accuracy: 0.9731 - val_loss: 1.1805 - val_accuracy: 0.6354\n",
      "Epoch 71/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.0896 - accuracy: 0.9706\n",
      "Epoch 00071: val_accuracy did not improve from 0.67073\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.0893 - accuracy: 0.9707 - val_loss: 1.2242 - val_accuracy: 0.6390\n",
      "Epoch 72/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.0814 - accuracy: 0.9743\n",
      "Epoch 00072: val_accuracy did not improve from 0.67073\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.0811 - accuracy: 0.9744 - val_loss: 1.1584 - val_accuracy: 0.6549\n",
      "Epoch 73/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.0764 - accuracy: 0.9752\n",
      "Epoch 00073: val_accuracy did not improve from 0.67073\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.0762 - accuracy: 0.9753 - val_loss: 1.1715 - val_accuracy: 0.6488\n",
      "Epoch 74/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.0901 - accuracy: 0.9718\n",
      "Epoch 00074: val_accuracy did not improve from 0.67073\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.0903 - accuracy: 0.9716 - val_loss: 1.1762 - val_accuracy: 0.6598\n",
      "Epoch 75/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.1009 - accuracy: 0.9666\n",
      "Epoch 00075: val_accuracy did not improve from 0.67073\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.1006 - accuracy: 0.9667 - val_loss: 1.1363 - val_accuracy: 0.6585\n",
      "Epoch 76/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.0678 - accuracy: 0.9737\n",
      "Epoch 00076: val_accuracy did not improve from 0.67073\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.0676 - accuracy: 0.9737 - val_loss: 1.2302 - val_accuracy: 0.6451\n",
      "Epoch 77/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.0866 - accuracy: 0.9743\n",
      "Epoch 00077: val_accuracy did not improve from 0.67073\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.0863 - accuracy: 0.9744 - val_loss: 1.1684 - val_accuracy: 0.6390\n",
      "Epoch 78/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.0588 - accuracy: 0.9822\n",
      "Epoch 00078: val_accuracy did not improve from 0.67073\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.0587 - accuracy: 0.9823 - val_loss: 1.2046 - val_accuracy: 0.6524\n",
      "Epoch 79/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.0885 - accuracy: 0.9730\n",
      "Epoch 00079: val_accuracy did not improve from 0.67073\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.0882 - accuracy: 0.9731 - val_loss: 1.2681 - val_accuracy: 0.6341\n",
      "Epoch 80/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.0737 - accuracy: 0.9776\n",
      "Epoch 00080: val_accuracy did not improve from 0.67073\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.0734 - accuracy: 0.9777 - val_loss: 1.2486 - val_accuracy: 0.6488\n",
      "Epoch 81/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.0615 - accuracy: 0.9789\n",
      "Epoch 00081: val_accuracy did not improve from 0.67073\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.0614 - accuracy: 0.9789 - val_loss: 1.1972 - val_accuracy: 0.6671\n",
      "Epoch 82/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.0599 - accuracy: 0.9807\n",
      "Epoch 00082: val_accuracy did not improve from 0.67073\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.0599 - accuracy: 0.9808 - val_loss: 1.2269 - val_accuracy: 0.6415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.0628 - accuracy: 0.9798\n",
      "Epoch 00083: val_accuracy did not improve from 0.67073\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.0627 - accuracy: 0.9799 - val_loss: 1.2488 - val_accuracy: 0.6500\n",
      "Epoch 84/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.0705 - accuracy: 0.9773\n",
      "Epoch 00084: val_accuracy did not improve from 0.67073\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.0703 - accuracy: 0.9774 - val_loss: 1.1931 - val_accuracy: 0.6488\n",
      "Epoch 85/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.1021 - accuracy: 0.9675\n",
      "Epoch 00085: val_accuracy did not improve from 0.67073\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.1020 - accuracy: 0.9676 - val_loss: 1.2218 - val_accuracy: 0.6561\n",
      "Epoch 86/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.0802 - accuracy: 0.9764\n",
      "Epoch 00086: val_accuracy did not improve from 0.67073\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.0802 - accuracy: 0.9765 - val_loss: 1.1880 - val_accuracy: 0.6439\n",
      "Epoch 87/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.0502 - accuracy: 0.9831\n",
      "Epoch 00087: val_accuracy did not improve from 0.67073\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.0500 - accuracy: 0.9832 - val_loss: 1.2256 - val_accuracy: 0.6476\n",
      "Epoch 88/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.0712 - accuracy: 0.9782\n",
      "Epoch 00088: val_accuracy did not improve from 0.67073\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.0710 - accuracy: 0.9783 - val_loss: 1.2490 - val_accuracy: 0.6390\n",
      "Epoch 89/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.0801 - accuracy: 0.9749\n",
      "Epoch 00089: val_accuracy did not improve from 0.67073\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.0798 - accuracy: 0.9750 - val_loss: 1.2844 - val_accuracy: 0.6390\n",
      "Epoch 90/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.0803 - accuracy: 0.9740\n",
      "Epoch 00090: val_accuracy did not improve from 0.67073\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.0800 - accuracy: 0.9741 - val_loss: 1.2641 - val_accuracy: 0.6427\n",
      "Epoch 91/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.0781 - accuracy: 0.9749\n",
      "Epoch 00091: val_accuracy did not improve from 0.67073\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.0778 - accuracy: 0.9750 - val_loss: 1.2051 - val_accuracy: 0.6476\n",
      "Epoch 92/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.0723 - accuracy: 0.9764\n",
      "Epoch 00092: val_accuracy did not improve from 0.67073\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.0721 - accuracy: 0.9765 - val_loss: 1.2402 - val_accuracy: 0.6476\n",
      "Epoch 93/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.0743 - accuracy: 0.9767\n",
      "Epoch 00093: val_accuracy did not improve from 0.67073\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.0741 - accuracy: 0.9768 - val_loss: 1.2701 - val_accuracy: 0.6439\n",
      "Epoch 94/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.0684 - accuracy: 0.9795\n",
      "Epoch 00094: val_accuracy did not improve from 0.67073\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.0683 - accuracy: 0.9795 - val_loss: 1.2246 - val_accuracy: 0.6585\n",
      "Epoch 95/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.0659 - accuracy: 0.9786\n",
      "Epoch 00095: val_accuracy did not improve from 0.67073\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.0658 - accuracy: 0.9786 - val_loss: 1.2751 - val_accuracy: 0.6354\n",
      "Epoch 96/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.0698 - accuracy: 0.9770\n",
      "Epoch 00096: val_accuracy did not improve from 0.67073\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.0696 - accuracy: 0.9771 - val_loss: 1.2905 - val_accuracy: 0.6561\n",
      "Epoch 97/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.0754 - accuracy: 0.9776\n",
      "Epoch 00097: val_accuracy did not improve from 0.67073\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.0756 - accuracy: 0.9774 - val_loss: 1.2574 - val_accuracy: 0.6378\n",
      "Epoch 98/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.0901 - accuracy: 0.9746\n",
      "Epoch 00098: val_accuracy did not improve from 0.67073\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.0904 - accuracy: 0.9744 - val_loss: 1.2397 - val_accuracy: 0.6500\n",
      "Epoch 99/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.0838 - accuracy: 0.9755\n",
      "Epoch 00099: val_accuracy did not improve from 0.67073\n",
      "3276/3276 [==============================] - 6s 2ms/sample - loss: 0.0837 - accuracy: 0.9756 - val_loss: 1.2744 - val_accuracy: 0.6524\n",
      "Epoch 100/100\n",
      "3264/3276 [============================>.] - ETA: 0s - loss: 0.0650 - accuracy: 0.9816\n",
      "Epoch 00100: val_accuracy did not improve from 0.67073\n",
      "3276/3276 [==============================] - 5s 2ms/sample - loss: 0.0647 - accuracy: 0.9817 - val_loss: 1.2145 - val_accuracy: 0.6610\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam', metrics = ['accuracy'], loss = 'categorical_crossentropy')\n",
    "history = model.fit([x_train, x_letter_train], y_train, validation_data=([x_val, x_letter_val], y_val), \n",
    "                    batch_size=64, epochs=100, verbose=1, \n",
    "                    callbacks = [ModelCheckpoint('./models/{epoch:02d}-{val_accuracy:.4f}.h5',\n",
    "                    monitor='val_accuracy', verbose=1, save_best_only=True, mode='auto')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T05:19:54.877227Z",
     "start_time": "2020-08-18T05:19:54.746872Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20480, 28, 28, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = test.drop(['id', 'letter'], axis=1).values\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test/255\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T05:19:54.882229Z",
     "start_time": "2020-08-18T05:19:54.878228Z"
    }
   },
   "outputs": [],
   "source": [
    "#prediction = np.argmax(model.predict(x_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T05:19:54.892306Z",
     "start_time": "2020-08-18T05:19:54.884229Z"
    }
   },
   "outputs": [],
   "source": [
    "#submission = pd.read_csv('data/submission.csv')\n",
    "#submission['digit'] = np.argmax(model.predict(x_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T05:19:54.898228Z",
     "start_time": "2020-08-18T05:19:54.894228Z"
    }
   },
   "outputs": [],
   "source": [
    "#submission.to_csv('data/submission1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T04:35:10.737240Z",
     "start_time": "2020-08-18T04:35:07.963154Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, LSTM, concatenate, Dropout, BatchNormalization, Activation\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# seed\n",
    "#import os\n",
    "#seed = 123\n",
    "#os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "#np.random.seed(seed)\n",
    "#tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T04:35:11.702756Z",
     "start_time": "2020-08-18T04:35:10.738201Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T04:35:11.723479Z",
     "start_time": "2020-08-18T04:35:11.704754Z"
    }
   },
   "outputs": [],
   "source": [
    "x = train.drop(['id', 'digit', 'letter'], axis=1).values\n",
    "x = x.reshape(-1, 28, 28, 1)\n",
    "x = x/255\n",
    "\n",
    "y_data = train['digit']\n",
    "y = np.zeros((len(y_data), len(y_data.unique())))\n",
    "for i, digit in enumerate(y_data):\n",
    "    y[i, digit] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T04:35:11.733358Z",
     "start_time": "2020-08-18T04:35:11.725371Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048, 26)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_letter = train['letter'].values\n",
    "x_letter = x_letter[:, np.newaxis]\n",
    "en = OneHotEncoder()\n",
    "x_letter = en.fit_transform(x_letter).toarray()\n",
    "x_letter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T04:35:11.778350Z",
     "start_time": "2020-08-18T04:35:11.735350Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1638, 28, 28, 1)\n",
      "(410, 28, 28, 1)\n",
      "(1638, 10)\n",
      "(410, 10)\n",
      "(1638, 26)\n",
      "(410, 26)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, shuffle=True, stratify=y)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)\n",
    "\n",
    "x_letter_train = x_letter[:x_train.shape[0],:]\n",
    "x_letter_val = x_letter[x_train.shape[0]:,:]\n",
    "print(x_letter_train.shape)\n",
    "print(x_letter_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T04:35:11.955383Z",
     "start_time": "2020-08-18T04:35:11.779361Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 28, 28, 64)   640         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 28, 28, 64)   0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 14, 14, 64)   0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 14, 14, 64)   16448       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 14, 14, 64)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 7, 7, 64)     0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 7, 7, 128)    32896       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 7, 7, 128)    0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 3, 3, 128)    0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1152)         0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 26)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1178)         0           flatten[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 500)          589500      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 500)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          50100       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 100)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 50)           5050        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           510         dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 695,144\n",
      "Trainable params: 695,144\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input1 = Input(shape=(28,28,1))\n",
    "x1 = Conv2D(64, (3,3), padding='same', activation='elu')(input1)\n",
    "#x1 = BatchNormalization()(x1)\n",
    "#x1 = Activation('elu')(x1)\n",
    "x1 = Dropout(0.3)(x1)\n",
    "x1 = MaxPooling2D((2,2))(x1)\n",
    "x1 = Conv2D(64, (2,2), padding='same', activation='elu')(x1)\n",
    "#x1 = BatchNormalization()(x1)\n",
    "#x1 = Activation('elu')(x1)\n",
    "x1 = Dropout(0.3)(x1)\n",
    "x1 = MaxPooling2D((2,2))(x1)\n",
    "x1 = Conv2D(128, (2,2), padding='same', activation='elu')(x1)\n",
    "#x1 = BatchNormalization()(x1)\n",
    "#x1 = Activation('elu')(x1)\n",
    "x1 = Dropout(0.3)(x1)\n",
    "x1 = MaxPooling2D((2,2))(x1)\n",
    "x1 = Flatten()(x1)\n",
    "\n",
    "input2 = Input(shape=(26,))\n",
    "merge = concatenate([x1, input2])\n",
    "\n",
    "x2 = Dense(500, activation='relu')(merge)\n",
    "x2 = Dropout(0.3)(x2)\n",
    "x2 = Dense(100, activation='relu')(x2)\n",
    "x2 = Dropout(0.3)(x2)\n",
    "x2 = Dense(50, activation='relu')(x2)\n",
    "outputs = Dense(10, activation='softmax')(x2)\n",
    "\n",
    "model = Model(inputs = [input1, input2], outputs = outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T04:39:54.235916Z",
     "start_time": "2020-08-18T04:35:11.957440Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1638 samples, validate on 410 samples\n",
      "Epoch 1/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 2.3052 - accuracy: 0.0994\n",
      "Epoch 00001: val_loss improved from inf to 2.29296, saving model to ./models/01-2.2930.h5\n",
      "1638/1638 [==============================] - 4s 2ms/sample - loss: 2.3049 - accuracy: 0.1001 - val_loss: 2.2930 - val_accuracy: 0.1537\n",
      "Epoch 2/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 2.2784 - accuracy: 0.1350\n",
      "Epoch 00002: val_loss improved from 2.29296 to 2.23539, saving model to ./models/02-2.2354.h5\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 2.2788 - accuracy: 0.1337 - val_loss: 2.2354 - val_accuracy: 0.1390\n",
      "Epoch 3/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 2.1789 - accuracy: 0.1869\n",
      "Epoch 00003: val_loss improved from 2.23539 to 2.15975, saving model to ./models/03-2.1598.h5\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 2.1782 - accuracy: 0.1874 - val_loss: 2.1598 - val_accuracy: 0.2732\n",
      "Epoch 4/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 1.9916 - accuracy: 0.2681\n",
      "Epoch 00004: val_loss improved from 2.15975 to 1.96847, saving model to ./models/04-1.9685.h5\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 1.9859 - accuracy: 0.2711 - val_loss: 1.9685 - val_accuracy: 0.3390\n",
      "Epoch 5/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 1.7933 - accuracy: 0.3600\n",
      "Epoch 00005: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 1.7903 - accuracy: 0.3608 - val_loss: 2.0350 - val_accuracy: 0.2707\n",
      "Epoch 6/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 1.7062 - accuracy: 0.3869\n",
      "Epoch 00006: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 1.7049 - accuracy: 0.3864 - val_loss: 2.9602 - val_accuracy: 0.2073\n",
      "Epoch 7/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 1.5373 - accuracy: 0.4531\n",
      "Epoch 00007: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 1.5389 - accuracy: 0.4536 - val_loss: 5.5165 - val_accuracy: 0.1073\n",
      "Epoch 8/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 1.4260 - accuracy: 0.5100\n",
      "Epoch 00008: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 1.4289 - accuracy: 0.5085 - val_loss: 6.0246 - val_accuracy: 0.1366\n",
      "Epoch 9/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 1.3077 - accuracy: 0.5487\n",
      "Epoch 00009: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 1.3064 - accuracy: 0.5501 - val_loss: 10.1489 - val_accuracy: 0.1000\n",
      "Epoch 10/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 1.1906 - accuracy: 0.5906\n",
      "Epoch 00010: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 1.1861 - accuracy: 0.5928 - val_loss: 9.4071 - val_accuracy: 0.1195\n",
      "Epoch 11/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 1.0364 - accuracy: 0.6481\n",
      "Epoch 00011: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 1.0334 - accuracy: 0.6477 - val_loss: 4.8460 - val_accuracy: 0.2610\n",
      "Epoch 12/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.9648 - accuracy: 0.6800\n",
      "Epoch 00012: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.9594 - accuracy: 0.6825 - val_loss: 13.0793 - val_accuracy: 0.1000\n",
      "Epoch 13/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.9865 - accuracy: 0.6662\n",
      "Epoch 00013: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.9861 - accuracy: 0.6661 - val_loss: 8.4901 - val_accuracy: 0.1512\n",
      "Epoch 14/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.8172 - accuracy: 0.7169\n",
      "Epoch 00014: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.8204 - accuracy: 0.7155 - val_loss: 8.9123 - val_accuracy: 0.1780\n",
      "Epoch 15/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.7678 - accuracy: 0.7337\n",
      "Epoch 00015: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.7680 - accuracy: 0.7320 - val_loss: 7.2204 - val_accuracy: 0.2439\n",
      "Epoch 16/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.7020 - accuracy: 0.7594\n",
      "Epoch 00016: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.7029 - accuracy: 0.7582 - val_loss: 11.5280 - val_accuracy: 0.1707\n",
      "Epoch 17/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.6622 - accuracy: 0.7719\n",
      "Epoch 00017: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.6615 - accuracy: 0.7711 - val_loss: 7.8982 - val_accuracy: 0.2317\n",
      "Epoch 18/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.6859 - accuracy: 0.7638\n",
      "Epoch 00018: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.6928 - accuracy: 0.7625 - val_loss: 3.9637 - val_accuracy: 0.3561\n",
      "Epoch 19/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.5898 - accuracy: 0.7937\n",
      "Epoch 00019: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.5884 - accuracy: 0.7937 - val_loss: 4.3706 - val_accuracy: 0.3585\n",
      "Epoch 20/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.5503 - accuracy: 0.8100\n",
      "Epoch 00020: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.5508 - accuracy: 0.8095 - val_loss: 6.3477 - val_accuracy: 0.3000\n",
      "Epoch 21/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.5416 - accuracy: 0.8075\n",
      "Epoch 00021: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.5433 - accuracy: 0.8065 - val_loss: 5.7960 - val_accuracy: 0.2976\n",
      "Epoch 22/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.5396 - accuracy: 0.8056\n",
      "Epoch 00022: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.5509 - accuracy: 0.8010 - val_loss: 5.3390 - val_accuracy: 0.3512\n",
      "Epoch 23/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.4547 - accuracy: 0.8500\n",
      "Epoch 00023: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.4627 - accuracy: 0.8474 - val_loss: 7.1527 - val_accuracy: 0.3220\n",
      "Epoch 24/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.4558 - accuracy: 0.8394\n",
      "Epoch 00024: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.4557 - accuracy: 0.8400 - val_loss: 4.8973 - val_accuracy: 0.3707\n",
      "Epoch 25/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.4241 - accuracy: 0.8550\n",
      "Epoch 00025: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.4267 - accuracy: 0.8553 - val_loss: 5.5346 - val_accuracy: 0.3220\n",
      "Epoch 26/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.3868 - accuracy: 0.8525\n",
      "Epoch 00026: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.3956 - accuracy: 0.8498 - val_loss: 5.3427 - val_accuracy: 0.3683\n",
      "Epoch 27/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.3711 - accuracy: 0.8731\n",
      "Epoch 00027: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.3722 - accuracy: 0.8736 - val_loss: 6.9012 - val_accuracy: 0.3049\n",
      "Epoch 28/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.3444 - accuracy: 0.8875\n",
      "Epoch 00028: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.3473 - accuracy: 0.8864 - val_loss: 7.6667 - val_accuracy: 0.2585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.3457 - accuracy: 0.8788\n",
      "Epoch 00029: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.3418 - accuracy: 0.8797 - val_loss: 5.3572 - val_accuracy: 0.3341\n",
      "Epoch 30/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.2922 - accuracy: 0.9038\n",
      "Epoch 00030: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.2965 - accuracy: 0.9017 - val_loss: 6.4877 - val_accuracy: 0.3463\n",
      "Epoch 31/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.2889 - accuracy: 0.8950\n",
      "Epoch 00031: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.2945 - accuracy: 0.8926 - val_loss: 5.5663 - val_accuracy: 0.3293\n",
      "Epoch 32/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.2812 - accuracy: 0.9019\n",
      "Epoch 00032: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.2878 - accuracy: 0.9011 - val_loss: 6.6269 - val_accuracy: 0.3439\n",
      "Epoch 33/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.2898 - accuracy: 0.9000\n",
      "Epoch 00033: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.2850 - accuracy: 0.9023 - val_loss: 7.9085 - val_accuracy: 0.2463\n",
      "Epoch 34/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.2505 - accuracy: 0.9194\n",
      "Epoch 00034: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.2515 - accuracy: 0.9194 - val_loss: 6.1861 - val_accuracy: 0.3634\n",
      "Epoch 35/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.2302 - accuracy: 0.9244\n",
      "Epoch 00035: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.2287 - accuracy: 0.9249 - val_loss: 5.7128 - val_accuracy: 0.3293\n",
      "Epoch 36/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.2515 - accuracy: 0.9125\n",
      "Epoch 00036: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.2540 - accuracy: 0.9115 - val_loss: 4.7225 - val_accuracy: 0.3902\n",
      "Epoch 37/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.2098 - accuracy: 0.9250\n",
      "Epoch 00037: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.2127 - accuracy: 0.9249 - val_loss: 4.6059 - val_accuracy: 0.4268\n",
      "Epoch 38/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.2268 - accuracy: 0.9225\n",
      "Epoch 00038: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.2261 - accuracy: 0.9237 - val_loss: 4.3563 - val_accuracy: 0.4366\n",
      "Epoch 39/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.1838 - accuracy: 0.9394\n",
      "Epoch 00039: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.1890 - accuracy: 0.9371 - val_loss: 5.0359 - val_accuracy: 0.3878\n",
      "Epoch 40/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.1680 - accuracy: 0.9425\n",
      "Epoch 00040: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.1678 - accuracy: 0.9426 - val_loss: 7.4598 - val_accuracy: 0.3415\n",
      "Epoch 41/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.1819 - accuracy: 0.9419\n",
      "Epoch 00041: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.1817 - accuracy: 0.9420 - val_loss: 6.0247 - val_accuracy: 0.3951\n",
      "Epoch 42/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.1801 - accuracy: 0.9419\n",
      "Epoch 00042: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.1804 - accuracy: 0.9420 - val_loss: 7.5971 - val_accuracy: 0.3268\n",
      "Epoch 43/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.1630 - accuracy: 0.9419\n",
      "Epoch 00043: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.1636 - accuracy: 0.9414 - val_loss: 5.8973 - val_accuracy: 0.3512\n",
      "Epoch 44/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.1719 - accuracy: 0.9444\n",
      "Epoch 00044: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.1751 - accuracy: 0.9444 - val_loss: 5.2342 - val_accuracy: 0.3707\n",
      "Epoch 45/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.1588 - accuracy: 0.9488\n",
      "Epoch 00045: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.1562 - accuracy: 0.9499 - val_loss: 4.4794 - val_accuracy: 0.4195\n",
      "Epoch 46/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.1455 - accuracy: 0.9531\n",
      "Epoch 00046: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.1465 - accuracy: 0.9524 - val_loss: 5.9395 - val_accuracy: 0.3561\n",
      "Epoch 47/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.1189 - accuracy: 0.9600\n",
      "Epoch 00047: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.1182 - accuracy: 0.9603 - val_loss: 6.0780 - val_accuracy: 0.3659\n",
      "Epoch 48/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.1394 - accuracy: 0.9556\n",
      "Epoch 00048: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.1373 - accuracy: 0.9567 - val_loss: 7.2082 - val_accuracy: 0.3049\n",
      "Epoch 49/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.1253 - accuracy: 0.9581\n",
      "Epoch 00049: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.1256 - accuracy: 0.9585 - val_loss: 6.3838 - val_accuracy: 0.3634\n",
      "Epoch 50/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.1158 - accuracy: 0.9650\n",
      "Epoch 00050: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.1139 - accuracy: 0.9658 - val_loss: 5.4519 - val_accuracy: 0.3854\n",
      "Epoch 51/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.1488 - accuracy: 0.9538\n",
      "Epoch 00051: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.1469 - accuracy: 0.9542 - val_loss: 5.9235 - val_accuracy: 0.3366\n",
      "Epoch 52/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.1005 - accuracy: 0.9675\n",
      "Epoch 00052: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.0988 - accuracy: 0.9683 - val_loss: 6.4854 - val_accuracy: 0.3537\n",
      "Epoch 53/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.1063 - accuracy: 0.9644\n",
      "Epoch 00053: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.1080 - accuracy: 0.9646 - val_loss: 5.3577 - val_accuracy: 0.3951\n",
      "Epoch 54/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.1146 - accuracy: 0.9581\n",
      "Epoch 00054: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.1135 - accuracy: 0.9591 - val_loss: 5.9701 - val_accuracy: 0.3902\n",
      "Epoch 55/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.1256 - accuracy: 0.9600\n",
      "Epoch 00055: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.1237 - accuracy: 0.9609 - val_loss: 6.5650 - val_accuracy: 0.3317\n",
      "Epoch 56/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.1043 - accuracy: 0.9656\n",
      "Epoch 00056: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.1039 - accuracy: 0.9658 - val_loss: 9.6769 - val_accuracy: 0.2927\n",
      "Epoch 57/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.1446 - accuracy: 0.9519\n",
      "Epoch 00057: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.1417 - accuracy: 0.9530 - val_loss: 6.7705 - val_accuracy: 0.3585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.1345 - accuracy: 0.9563\n",
      "Epoch 00058: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.1329 - accuracy: 0.9567 - val_loss: 6.2168 - val_accuracy: 0.3659\n",
      "Epoch 59/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.0939 - accuracy: 0.9719\n",
      "Epoch 00059: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.0940 - accuracy: 0.9719 - val_loss: 7.4361 - val_accuracy: 0.3268\n",
      "Epoch 60/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.1133 - accuracy: 0.9663\n",
      "Epoch 00060: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.1123 - accuracy: 0.9664 - val_loss: 7.3889 - val_accuracy: 0.3585\n",
      "Epoch 61/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.0818 - accuracy: 0.9769\n",
      "Epoch 00061: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.0837 - accuracy: 0.9756 - val_loss: 8.5564 - val_accuracy: 0.3366\n",
      "Epoch 62/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.1032 - accuracy: 0.9663\n",
      "Epoch 00062: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.1054 - accuracy: 0.9646 - val_loss: 6.5174 - val_accuracy: 0.3854\n",
      "Epoch 63/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.1069 - accuracy: 0.9638\n",
      "Epoch 00063: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.1084 - accuracy: 0.9628 - val_loss: 6.0030 - val_accuracy: 0.3732\n",
      "Epoch 64/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.0827 - accuracy: 0.9737\n",
      "Epoch 00064: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.0836 - accuracy: 0.9737 - val_loss: 6.7387 - val_accuracy: 0.3049\n",
      "Epoch 65/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.0920 - accuracy: 0.9706\n",
      "Epoch 00065: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.0921 - accuracy: 0.9707 - val_loss: 6.5305 - val_accuracy: 0.3659\n",
      "Epoch 66/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.0902 - accuracy: 0.9688\n",
      "Epoch 00066: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.0893 - accuracy: 0.9695 - val_loss: 6.3966 - val_accuracy: 0.3463\n",
      "Epoch 67/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.0895 - accuracy: 0.9706\n",
      "Epoch 00067: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.0909 - accuracy: 0.9701 - val_loss: 6.0224 - val_accuracy: 0.3976\n",
      "Epoch 68/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.0478 - accuracy: 0.9862\n",
      "Epoch 00068: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.0481 - accuracy: 0.9860 - val_loss: 6.7110 - val_accuracy: 0.3634\n",
      "Epoch 69/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.0604 - accuracy: 0.9781\n",
      "Epoch 00069: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.0592 - accuracy: 0.9786 - val_loss: 5.8875 - val_accuracy: 0.4122\n",
      "Epoch 70/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.0544 - accuracy: 0.9825\n",
      "Epoch 00070: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.0558 - accuracy: 0.9823 - val_loss: 6.5082 - val_accuracy: 0.3756\n",
      "Epoch 71/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.0731 - accuracy: 0.9737\n",
      "Epoch 00071: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.0725 - accuracy: 0.9737 - val_loss: 8.8639 - val_accuracy: 0.3024\n",
      "Epoch 72/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.0905 - accuracy: 0.9694\n",
      "Epoch 00072: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.0898 - accuracy: 0.9695 - val_loss: 7.0485 - val_accuracy: 0.3537\n",
      "Epoch 73/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.0763 - accuracy: 0.9731\n",
      "Epoch 00073: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.0776 - accuracy: 0.9731 - val_loss: 5.3260 - val_accuracy: 0.4098\n",
      "Epoch 74/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.0653 - accuracy: 0.9794\n",
      "Epoch 00074: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.0666 - accuracy: 0.9786 - val_loss: 6.1002 - val_accuracy: 0.3951\n",
      "Epoch 75/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.0694 - accuracy: 0.9806\n",
      "Epoch 00075: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.0681 - accuracy: 0.9811 - val_loss: 5.2648 - val_accuracy: 0.4220\n",
      "Epoch 76/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.0700 - accuracy: 0.9750\n",
      "Epoch 00076: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.0689 - accuracy: 0.9756 - val_loss: 5.8488 - val_accuracy: 0.4024\n",
      "Epoch 77/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.0542 - accuracy: 0.9831\n",
      "Epoch 00077: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.0534 - accuracy: 0.9835 - val_loss: 4.8439 - val_accuracy: 0.4537\n",
      "Epoch 78/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.0748 - accuracy: 0.9812\n",
      "Epoch 00078: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.0794 - accuracy: 0.9805 - val_loss: 6.2278 - val_accuracy: 0.3902\n",
      "Epoch 79/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.0788 - accuracy: 0.9725\n",
      "Epoch 00079: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.0788 - accuracy: 0.9725 - val_loss: 4.9501 - val_accuracy: 0.4195\n",
      "Epoch 80/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.0613 - accuracy: 0.9819\n",
      "Epoch 00080: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.0603 - accuracy: 0.9823 - val_loss: 4.8925 - val_accuracy: 0.4463\n",
      "Epoch 81/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.0641 - accuracy: 0.9800\n",
      "Epoch 00081: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.0645 - accuracy: 0.9799 - val_loss: 6.5277 - val_accuracy: 0.3951\n",
      "Epoch 82/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.0835 - accuracy: 0.9706\n",
      "Epoch 00082: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.0837 - accuracy: 0.9707 - val_loss: 5.1198 - val_accuracy: 0.4000\n",
      "Epoch 83/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.0738 - accuracy: 0.9737\n",
      "Epoch 00083: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.0738 - accuracy: 0.9737 - val_loss: 7.0806 - val_accuracy: 0.3537\n",
      "Epoch 84/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.0934 - accuracy: 0.9644\n",
      "Epoch 00084: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.0980 - accuracy: 0.9634 - val_loss: 5.0814 - val_accuracy: 0.4122\n",
      "Epoch 85/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.0501 - accuracy: 0.9831\n",
      "Epoch 00085: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.0492 - accuracy: 0.9835 - val_loss: 5.5700 - val_accuracy: 0.3902\n",
      "Epoch 86/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.0683 - accuracy: 0.9787\n",
      "Epoch 00086: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.0670 - accuracy: 0.9792 - val_loss: 5.2925 - val_accuracy: 0.4146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.0766 - accuracy: 0.9781\n",
      "Epoch 00087: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.0771 - accuracy: 0.9774 - val_loss: 6.2950 - val_accuracy: 0.4073\n",
      "Epoch 88/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.0762 - accuracy: 0.9787\n",
      "Epoch 00088: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.0750 - accuracy: 0.9792 - val_loss: 5.4437 - val_accuracy: 0.3707\n",
      "Epoch 89/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.0496 - accuracy: 0.9812\n",
      "Epoch 00089: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.0489 - accuracy: 0.9817 - val_loss: 5.8887 - val_accuracy: 0.3902\n",
      "Epoch 90/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.0559 - accuracy: 0.9812\n",
      "Epoch 00090: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.0550 - accuracy: 0.9817 - val_loss: 5.9387 - val_accuracy: 0.3732\n",
      "Epoch 91/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.0756 - accuracy: 0.9794\n",
      "Epoch 00091: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.0742 - accuracy: 0.9799 - val_loss: 5.6862 - val_accuracy: 0.4293\n",
      "Epoch 92/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.0943 - accuracy: 0.9700\n",
      "Epoch 00092: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.0936 - accuracy: 0.9701 - val_loss: 6.0521 - val_accuracy: 0.3341\n",
      "Epoch 93/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.0882 - accuracy: 0.9744\n",
      "Epoch 00093: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.0867 - accuracy: 0.9750 - val_loss: 4.1000 - val_accuracy: 0.4098\n",
      "Epoch 94/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.0772 - accuracy: 0.9731\n",
      "Epoch 00094: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.0764 - accuracy: 0.9731 - val_loss: 3.9089 - val_accuracy: 0.4439\n",
      "Epoch 95/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.0458 - accuracy: 0.9844\n",
      "Epoch 00095: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.0453 - accuracy: 0.9847 - val_loss: 3.5404 - val_accuracy: 0.4415\n",
      "Epoch 96/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.0531 - accuracy: 0.9806\n",
      "Epoch 00096: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.0519 - accuracy: 0.9811 - val_loss: 3.8475 - val_accuracy: 0.4024\n",
      "Epoch 97/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.0316 - accuracy: 0.9887\n",
      "Epoch 00097: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.0318 - accuracy: 0.9884 - val_loss: 3.9211 - val_accuracy: 0.4220\n",
      "Epoch 98/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.0425 - accuracy: 0.9850\n",
      "Epoch 00098: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.0426 - accuracy: 0.9847 - val_loss: 3.9456 - val_accuracy: 0.4366\n",
      "Epoch 99/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.0334 - accuracy: 0.9881\n",
      "Epoch 00099: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.0328 - accuracy: 0.9884 - val_loss: 4.0160 - val_accuracy: 0.4098\n",
      "Epoch 100/100\n",
      "1600/1638 [============================>.] - ETA: 0s - loss: 0.0567 - accuracy: 0.9831\n",
      "Epoch 00100: val_loss did not improve from 1.96847\n",
      "1638/1638 [==============================] - 3s 2ms/sample - loss: 0.0555 - accuracy: 0.9835 - val_loss: 5.4654 - val_accuracy: 0.3902\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam', metrics = ['accuracy'], loss = 'categorical_crossentropy')\n",
    "history = model.fit([x_train, x_letter_train], y_train, validation_data=([x_val, x_letter_val], y_val), \n",
    "                    batch_size=64, epochs=100, verbose=1, \n",
    "                    callbacks = [ModelCheckpoint('./models/{epoch:02d}-{val_accuracy:.4f}.h5',\n",
    "                    monitor='val_loss', verbose=1, save_best_only=True, mode='auto')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T04:39:54.374997Z",
     "start_time": "2020-08-18T04:39:54.236913Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20480, 26)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = test.drop(['id', 'letter'], axis=1).values\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test/255\n",
    "\n",
    "x_letter_test = test['letter'].values\n",
    "x_letter_test = x_letter_test[:, np.newaxis]\n",
    "en = OneHotEncoder()\n",
    "x_letter_test = en.fit_transform(x_letter_test).toarray()\n",
    "x_letter_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T04:39:54.379007Z",
     "start_time": "2020-08-18T04:39:54.375999Z"
    }
   },
   "outputs": [],
   "source": [
    "#submission = pd.read_csv('data/submission.csv')\n",
    "#submission['digit'] = np.argmax(model.predict([x_test, x_letter_test]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T04:39:54.384999Z",
     "start_time": "2020-08-18T04:39:54.380999Z"
    }
   },
   "outputs": [],
   "source": [
    "#submission.to_csv('data/submission1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
